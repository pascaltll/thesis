train_Изъяты лексемы с частотой выше 100 - distilbert-base-multilingual.csv
test_Изъяты лексемы с частотой выше 100 - distilbert-base-multilingual.csv
Epoch 1, Loss: 0.746689396245139
Epoch 2, Loss: 0.6739511319569179
Epoch 3, Loss: 0.668454280921391
Epoch 4, Loss: 0.6593767063958305
Epoch 5, Loss: 0.651129526751382
Epoch 6, Loss: 0.6473492639405387
Epoch 1, Loss: 0.8815604618617466
Epoch 2, Loss: 0.6981270057814462
Epoch 3, Loss: 0.6853969522884914
Epoch 4, Loss: 0.6824338521276202
Epoch 5, Loss: 0.6716120413371495
Epoch 6, Loss: 0.6707928095545087
Epoch 1, Loss: 0.9435557126998901
Epoch 2, Loss: 0.6741278171539307
Epoch 3, Loss: 0.6726497837475368
Epoch 4, Loss: 0.6693926879337856
Epoch 5, Loss: 0.6647588270051139
Epoch 6, Loss: 0.6621877465929303
Epoch 1, Loss: 0.8799973555973598
Epoch 2, Loss: 0.6951883179800851
Epoch 3, Loss: 0.678725676877158
Epoch 4, Loss: 0.6672571131161281
Epoch 5, Loss: 0.6664878811155047
Epoch 6, Loss: 0.6676132678985596
Epoch 1, Loss: 0.9034113713673183
Epoch 2, Loss: 0.6907053419521877
Epoch 3, Loss: 0.673088686806815
Epoch 4, Loss: 0.6754195264407566
Epoch 5, Loss: 0.669740446976253
Epoch 6, Loss: 0.667532103402274
Epoch 1, Loss: 0.8212932688849313
Epoch 2, Loss: 0.6878150616373334
Epoch 3, Loss: 0.6701338716915676
Epoch 4, Loss: 0.6737136585371835
Epoch 5, Loss: 0.6603756291525704
Epoch 6, Loss: 0.6662257058279855
