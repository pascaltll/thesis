train_Изъяты лексемы с частотой выше 49 - distilbert-base-multilingual.csv
test_Изъяты лексемы с частотой выше 49 - distilbert-base-multilingual.csv
Epoch 1, Loss: 0.9018372222781181
Epoch 2, Loss: 0.6675648838281631
Epoch 3, Loss: 0.6795339956879616
Epoch 4, Loss: 0.6500460430979729
Epoch 5, Loss: 0.6384764090180397
Epoch 6, Loss: 0.6651749387383461
Epoch 1, Loss: 0.9510043412446976
Epoch 2, Loss: 0.6709369570016861
Epoch 3, Loss: 0.6820031851530075
Epoch 4, Loss: 0.6496689543128014
Epoch 5, Loss: 0.7001869156956673
Epoch 6, Loss: 0.6693871319293976
Epoch 1, Loss: 0.8466057032346725
Epoch 2, Loss: 0.743011087179184
Epoch 3, Loss: 0.6610006839036942
Epoch 4, Loss: 0.6675705760717392
Epoch 5, Loss: 0.6535019725561142
Epoch 6, Loss: 0.6412678360939026
Epoch 1, Loss: 0.8756408914923668
Epoch 2, Loss: 0.6696189679205418
Epoch 3, Loss: 0.6700818166136742
Epoch 4, Loss: 0.6643064245581627
Epoch 5, Loss: 0.6417724043130875
Epoch 6, Loss: 0.6786620765924454
Epoch 1, Loss: 0.8367787376046181
Epoch 2, Loss: 0.7111828699707985
Epoch 3, Loss: 0.6576069593429565
Epoch 4, Loss: 0.6772262081503868
Epoch 5, Loss: 0.6562769860029221
Epoch 6, Loss: 0.6367123611271381
Epoch 1, Loss: 0.8730569034814835
Epoch 2, Loss: 0.6616421192884445
Epoch 3, Loss: 0.6185345575213432
Epoch 4, Loss: 0.6686306521296501
Epoch 5, Loss: 0.6673005893826485
Epoch 6, Loss: 0.6557910367846489
