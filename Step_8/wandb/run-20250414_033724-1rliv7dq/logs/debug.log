2025-04-14 03:37:24,873 INFO    MainThread:102649 [wandb_init.py:setup_run_log_directory():662] Logging user logs to /workspace/notebooks/Carlos/fine_tunig_project/thesis/Step_8/wandb/run-20250414_033724-1rliv7dq/logs/debug.log
2025-04-14 03:37:24,873 INFO    MainThread:102649 [wandb_init.py:setup_run_log_directory():663] Logging internal logs to /workspace/notebooks/Carlos/fine_tunig_project/thesis/Step_8/wandb/run-20250414_033724-1rliv7dq/logs/debug-internal.log
2025-04-14 03:37:24,873 INFO    MainThread:102649 [wandb_init.py:init():781] calling init triggers
2025-04-14 03:37:24,873 INFO    MainThread:102649 [wandb_init.py:init():786] wandb.init called with sweep_config: {}
config: {'model': 'gpt2', 'dataset': 'Изъяты лексемы с частотой выше 100', 'type': 'freq', 'freq': 100, 'model_name': 'gpt2', 'max_length': 512, 'batch_size': 4, 'epochs': 2, 'learning_rate': 1e-05, 'num_repeats': 6, 'test_size': 0.2, 'threshold': 0.5, 'device': device(type='cuda'), 'tokenizer': GPT2TokenizerFast(name_or_path='gpt2', vocab_size=50257, model_max_length=1024, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<|endoftext|>', 'eos_token': '<|endoftext|>', 'unk_token': '<|endoftext|>'}, clean_up_tokenization_spaces=True), 'model_type': 'gpt', '_wandb': {}}
2025-04-14 03:37:24,873 INFO    MainThread:102649 [wandb_init.py:init():798] finishing previous run: 36v72wcc
2025-04-14 03:37:26,256 INFO    MainThread:102649 [wandb_init.py:init():809] starting backend
2025-04-14 03:37:26,256 INFO    MainThread:102649 [wandb_init.py:init():813] sending inform_init request
2025-04-14 03:37:26,258 INFO    MainThread:102649 [backend.py:_multiprocessing_setup():101] multiprocessing start_methods=fork,spawn,forkserver, using: spawn
2025-04-14 03:37:26,259 INFO    MainThread:102649 [wandb_init.py:init():823] backend started and connected
2025-04-14 03:37:26,268 INFO    MainThread:102649 [wandb_run.py:_label_probe_notebook():1267] probe notebook
2025-04-14 03:37:26,268 INFO    MainThread:102649 [wandb_run.py:_label_probe_notebook():1277] Unable to probe notebook: 'NoneType' object has no attribute 'get'
2025-04-14 03:37:26,269 INFO    MainThread:102649 [wandb_init.py:init():915] updated telemetry
2025-04-14 03:37:26,314 INFO    MainThread:102649 [wandb_init.py:init():939] communicating run to backend with 90.0 second timeout
2025-04-14 03:37:26,816 INFO    MainThread:102649 [wandb_init.py:init():1014] starting run threads in backend
2025-04-14 03:37:26,997 INFO    MainThread:102649 [wandb_run.py:_console_start():2454] atexit reg
2025-04-14 03:37:26,998 INFO    MainThread:102649 [wandb_run.py:_redirect():2306] redirect: wrap_raw
2025-04-14 03:37:26,998 INFO    MainThread:102649 [wandb_run.py:_redirect():2371] Wrapping output streams.
2025-04-14 03:37:26,998 INFO    MainThread:102649 [wandb_run.py:_redirect():2394] Redirects installed.
2025-04-14 03:37:26,999 INFO    MainThread:102649 [wandb_init.py:init():1056] run started, returning control to user process
2025-04-14 03:49:16,109 INFO    MainThread:102649 [wandb_run.py:_finish():2189] finishing run tuesta-lx-moscow-institute-of-physics-and-technology/model-comparison/1rliv7dq
2025-04-14 03:49:16,110 INFO    MainThread:102649 [wandb_run.py:_atexit_cleanup():2419] got exitcode: 0
2025-04-14 03:49:16,110 INFO    MainThread:102649 [wandb_run.py:_restore():2401] restore
2025-04-14 03:49:16,110 INFO    MainThread:102649 [wandb_run.py:_restore():2407] restore done
2025-04-14 03:49:17,772 INFO    MainThread:102649 [wandb_run.py:_footer_history_summary_info():4064] rendering history
2025-04-14 03:49:17,772 INFO    MainThread:102649 [wandb_run.py:_footer_history_summary_info():4096] rendering summary
2025-04-14 03:49:17,773 INFO    MainThread:102649 [wandb_run.py:_footer_sync_info():4025] logging synced files
