_wandb:
    value:
        cli_version: 0.19.9
        m: []
        python_version: 3.8.13
        t:
            "1":
                - 1
                - 2
                - 3
                - 5
                - 11
                - 49
                - 53
                - 55
                - 71
            "2":
                - 1
                - 2
                - 3
                - 5
                - 11
                - 49
                - 53
                - 55
                - 71
            "3":
                - 2
                - 13
                - 16
                - 23
                - 55
            "4": 3.8.13
            "5": 0.19.9
            "6": 4.30.0
            "8":
                - 1
                - 5
            "10":
                - 20
            "12": 0.19.9
            "13": linux-x86_64
batch_size:
    value: 128
dataset:
    value: Изъяты лексемы с частотой выше 29
device:
    value: cuda
epochs:
    value: 4
freq:
    value: 29
learning_rate:
    value: 3e-05
max_length:
    value: 51
model:
    value: distilbert-base-multilingual-cased
model_name:
    value: distilbert-base-multilingual-cased
num_repeats:
    value: 6
test_size:
    value: 0.2
threshold:
    value: 0.5
tokenizer:
    value: 'DistilBertTokenizerFast(name_or_path=''distilbert-base-multilingual-cased'', vocab_size=119547, model_max_length=512, is_fast=True, padding_side=''right'', truncation_side=''right'', special_tokens={''unk_token'': ''[UNK]'', ''sep_token'': ''[SEP]'', ''pad_token'': ''[PAD]'', ''cls_token'': ''[CLS]'', ''mask_token'': ''[MASK]''}, clean_up_tokenization_spaces=True)'
