train_Изъяты лексемы с частотой выше 29 - distilbert-base-multilingual.csv
test_Изъяты лексемы с частотой выше 29 - distilbert-base-multilingual.csv
Epoch 1, Loss: 0.8266093730926514
Epoch 2, Loss: 0.6476037587438311
Epoch 3, Loss: 0.6423301952225822
Epoch 4, Loss: 0.6385234764644078
Epoch 5, Loss: 0.6410566908972604
Epoch 6, Loss: 0.6363001210348946
Epoch 1, Loss: 0.8339969515800476
Epoch 2, Loss: 0.6559629184859139
Epoch 3, Loss: 0.6595550605228969
Epoch 4, Loss: 0.6500277774674552
Epoch 5, Loss: 0.6440915039607457
Epoch 6, Loss: 0.6419291070529393
Epoch 1, Loss: 0.8358583620616368
Epoch 2, Loss: 0.6681177701268878
Epoch 3, Loss: 0.6588804040636335
Epoch 4, Loss: 0.6405205982072013
Epoch 5, Loss: 0.6538561667714801
Epoch 6, Loss: 0.6464937584740775
Epoch 1, Loss: 0.8958973033087594
Epoch 2, Loss: 0.6998747416904995
Epoch 3, Loss: 0.6566305415970939
Epoch 4, Loss: 0.6570662430354527
Epoch 5, Loss: 0.6457917860576085
Epoch 6, Loss: 0.6441625186375209
Epoch 1, Loss: 0.8490128772599357
Epoch 2, Loss: 0.6555047971861703
Epoch 3, Loss: 0.6409173437527248
Epoch 4, Loss: 0.647119905267443
Epoch 5, Loss: 0.6410444889749799
Epoch 6, Loss: 0.6363502400262016
Epoch 1, Loss: 0.896464330809457
Epoch 2, Loss: 0.6781546218054635
Epoch 3, Loss: 0.6646371483802795
Epoch 4, Loss: 0.659462741443089
Epoch 5, Loss: 0.6543118357658386
Epoch 6, Loss: 0.6518338322639465
