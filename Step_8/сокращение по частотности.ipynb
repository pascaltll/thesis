{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e66a70c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34m../dataset\u001b[0m\r\n",
      "├── \u001b[01;34men_espanol\u001b[0m\r\n",
      "│   ├── \u001b[00mdocx2txt.py\u001b[0m\r\n",
      "│   ├── \u001b[00mВторой_жанр_исходная.txt\u001b[0m\r\n",
      "│   └── \u001b[00mПервый_жанр_исходная.txt\u001b[0m\r\n",
      "├── \u001b[00mВторой_жанр_исходная.txt\u001b[0m\r\n",
      "├── \u001b[00mПервый_жанр_исходная.txt\u001b[0m\r\n",
      "├── \u001b[01;34mСокращение по частям речи\u001b[0m\r\n",
      "│   ├── \u001b[00m1.Первый жанр исходная выборка.txt\u001b[0m\r\n",
      "│   ├── \u001b[00m2.Первый жанр без клауз, включающих наречия.txt\u001b[0m\r\n",
      "│   ├── \u001b[00m3.Первый жанр без клауз, включающих глаголы.txt\u001b[0m\r\n",
      "│   ├── \u001b[00m4.Первый жанр без клауз, включающих глаголы и наречия.txt\u001b[0m\r\n",
      "│   ├── \u001b[00mБез прилагательных второй жанр.txt\u001b[0m\r\n",
      "│   ├── \u001b[00mБез прилагательных первый жанр.txt\u001b[0m\r\n",
      "│   └── \u001b[00mСлучайные выборки.txt\u001b[0m\r\n",
      "└── \u001b[01;34mсокращение по частотности\u001b[0m\r\n",
      "    ├── \u001b[00m1а_ без сокращений.txt\u001b[0m\r\n",
      "    ├── \u001b[00m1б_Изъяты лексемы с частотой выше 100.txt\u001b[0m\r\n",
      "    ├── \u001b[00m1в_Изъяты лексемы с частотой выше 49.txt\u001b[0m\r\n",
      "    ├── \u001b[00m1г_Изъяты лексемы с частотой выше 29.txt\u001b[0m\r\n",
      "    ├── \u001b[00m1д_Изъяты лексемы с частотой выше 9.txt\u001b[0m\r\n",
      "    ├── \u001b[00m1е_Изъяты лексемы с частотой выше 5.txt\u001b[0m\r\n",
      "    ├── \u001b[00m1ё_Изъяты лексемы с частотой выше 3.txt\u001b[0m\r\n",
      "    ├── \u001b[00m2а_ без сокращений.txt\u001b[0m\r\n",
      "    ├── \u001b[00m2б_Изъяты лексемы с частотой выше 100.txt\u001b[0m\r\n",
      "    ├── \u001b[00m2в_Изъяты лексемы с частотой выше 49.txt\u001b[0m\r\n",
      "    ├── \u001b[00m2г_Изъяты лексемы с частотой выше 29.txt\u001b[0m\r\n",
      "    ├── \u001b[00m2д_Изъяты лексемы с частотой выше 9.txt\u001b[0m\r\n",
      "    ├── \u001b[00m2е_Изъяты лексемы с частотой выше 5.txt\u001b[0m\r\n",
      "    └── \u001b[00m2ё_Изъяты лексемы с частотой выше 3.txt\u001b[0m\r\n",
      "\r\n",
      "3 directories, 26 files\r\n"
     ]
    }
   ],
   "source": [
    "!tree ../dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "accb463f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Untitled.ipynb\r\n",
      " \u001b[0m\u001b[01;34m__pycache__\u001b[0m/\r\n",
      " accuracy_by_dataset_type.png\r\n",
      " comprehensive_comparison_freq.png\r\n",
      " comprehensive_comparison_pos.png\r\n",
      " confronto_prestazioni.png\r\n",
      "'confusion_matrices_gpt2_1.Первый жанр исходная выборка.png'\r\n",
      "'confusion_matrices_gpt2_Изъяты лексемы с частотой выше 100.png'\r\n",
      " confusion_matrix_DeepPavlov_rubert-base-cased_Изъяты_лексемы_с_частотой_выше_100.png\r\n",
      " confusion_matrix_bert-base-multilingual-cased_Изъяты_лексемы_с_частотой_выше_100.png\r\n",
      " confusion_matrix_distilbert-base-multilingual-cased_Изъяты_лексемы_с_частотой_выше_100.png\r\n",
      " confusion_matrix_facebook_opt-125m_1.Первый_жанр_исходная_выборка.png\r\n",
      " confusion_matrix_facebook_opt-125m_Изъяты_лексемы_с_частотой_выше_100.png\r\n",
      " confusion_matrix_gpt2_1.Первый_жанр_исходная_выборка.png\r\n",
      " confusion_matrix_gpt2_Изъяты_лексемы_с_частотой_выше_100.png\r\n",
      " confusion_matrix_roberta-base_Изъяты_лексемы_с_частотой_выше_100.png\r\n",
      " confusion_matrix_sberbank-ai_rugpt3small_based_on_gpt2_1.Первый_жанр_исходная_выборка.png\r\n",
      " confusion_matrix_sberbank-ai_rugpt3small_based_on_gpt2_Изъяты_лексемы_с_частотой_выше_100.png\r\n",
      " f1_macro_by_dataset_type.png\r\n",
      " frecuencia.png\r\n",
      " frecuencia_lineas.png\r\n",
      " frecuencia_profesional.png\r\n",
      " frecuencia_profesional_ajustada.png\r\n",
      " frecuencia_step_1.png\r\n",
      " frecuencia_test_1.png\r\n",
      " freq_analysis.png\r\n",
      " freq_comparison.png\r\n",
      " funciones.py\r\n",
      " generador.ipynb\r\n",
      " herramientas.ipynb\r\n",
      " loss_comparison.png\r\n",
      " model_comparison_all_datasets.png\r\n",
      " model_results.json\r\n",
      " model_results_GPT.json\r\n",
      " model_results_GPT_bert.json\r\n",
      " model_results_GPT_bert_all.json\r\n",
      " parte_2.png\r\n",
      " parte_2_Step1.png\r\n",
      " partes_discurso.png\r\n",
      " performance_comparison_other.png\r\n",
      " performance_table_freq.csv\r\n",
      " performance_table_pos.csv\r\n",
      " \u001b[01;34mplots\u001b[0m/\r\n",
      " plto.ipynb\r\n",
      " pos_analysis.png\r\n",
      " utils.py\r\n",
      " \u001b[01;34mwandb\u001b[0m/\r\n",
      " zero_shot.ipynb\r\n",
      "\u001b[01;34m'сокращение по частотности'\u001b[0m/\r\n",
      "'сокращение по частотности.ipynb'\r\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b299fb19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def save_results(results, filename):\n",
    "    with open(filename, 'w', encoding='utf-8') as f:\n",
    "        json.dump(results, f, indent=4, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11038bb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_Изъяты лексемы с частотой выше 100.csv\n",
      "test_Изъяты лексемы с частотой выше 100.csv\n",
      "Train labels sample: tensor([0, 0, 0, 0, 1]), Shape: torch.Size([864])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([195])\n",
      "Epoch 1, Loss: 0.3086095005273819\n",
      "Epoch 2, Loss: 0.03777603558929903\n",
      "Epoch 3, Loss: 0.006088302271174533\n",
      "Epoch 4, Loss: 0.005040814617781767\n",
      "Epoch 5, Loss: 0.026641652736413692\n",
      "Epoch 6, Loss: 0.00813552297352414\n",
      "all_preds shape: (195,)\n",
      "all_labels shape: (195,)\n",
      "all_probs shape: (195, 2)\n",
      "Train labels sample: tensor([1, 0, 1, 0, 0]), Shape: torch.Size([864])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([198])\n",
      "Epoch 1, Loss: 0.328420558146068\n",
      "Epoch 2, Loss: 0.0938217458980424\n",
      "Epoch 3, Loss: 0.03659572239433016\n",
      "Epoch 4, Loss: 0.009948871131720287\n",
      "Epoch 5, Loss: 0.003995593886689416\n",
      "Epoch 6, Loss: 0.001113946333394519\n",
      "all_preds shape: (198,)\n",
      "all_labels shape: (198,)\n",
      "all_probs shape: (198, 2)\n",
      "Train labels sample: tensor([1, 0, 0, 0, 1]), Shape: torch.Size([864])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([196])\n",
      "Epoch 1, Loss: 0.4299543116773878\n",
      "Epoch 2, Loss: 0.04542310017028025\n",
      "Epoch 3, Loss: 0.01597335222842438\n",
      "Epoch 4, Loss: 0.03483659238554537\n",
      "Epoch 5, Loss: 0.011337805040446776\n",
      "Epoch 6, Loss: 0.031189014968861426\n",
      "all_preds shape: (196,)\n",
      "all_labels shape: (196,)\n",
      "all_probs shape: (196, 2)\n",
      "Train labels sample: tensor([1, 1, 0, 1, 0]), Shape: torch.Size([864])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([194])\n",
      "Epoch 1, Loss: 0.35902369022369385\n",
      "Epoch 2, Loss: 0.06880455184727907\n",
      "Epoch 3, Loss: 0.019745683430560997\n",
      "Epoch 4, Loss: 0.008452789492106863\n",
      "Epoch 5, Loss: 0.0021961403378684607\n",
      "Epoch 6, Loss: 0.0034316070045211484\n",
      "all_preds shape: (194,)\n",
      "all_labels shape: (194,)\n",
      "all_probs shape: (194, 2)\n",
      "Train labels sample: tensor([0, 0, 0, 0, 1]), Shape: torch.Size([864])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([201])\n",
      "Epoch 1, Loss: 0.44101786400590626\n",
      "Epoch 2, Loss: 0.06041578176830496\n",
      "Epoch 3, Loss: 0.01600259934951152\n",
      "Epoch 4, Loss: 0.005111816172887172\n",
      "Epoch 5, Loss: 0.020542545526820635\n",
      "Epoch 6, Loss: 0.006195420199739081\n",
      "all_preds shape: (201,)\n",
      "all_labels shape: (201,)\n",
      "all_probs shape: (201, 2)\n",
      "Train labels sample: tensor([0, 1, 1, 0, 0]), Shape: torch.Size([864])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([184])\n",
      "Epoch 1, Loss: 0.3683318868279457\n",
      "Epoch 2, Loss: 0.08052446746400424\n",
      "Epoch 3, Loss: 0.057040286250412464\n",
      "Epoch 4, Loss: 0.017878348673028604\n",
      "Epoch 5, Loss: 0.006267011331926499\n",
      "Epoch 6, Loss: 0.001880699203216604\n",
      "all_preds shape: (184,)\n",
      "all_labels shape: (184,)\n",
      "all_probs shape: (184, 2)\n",
      "train_1.Первый жанр исходная выборка.csv\n",
      "test_1.Первый жанр исходная выборка.csv\n",
      "Train labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([888])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([175])\n",
      "Epoch 1, Loss: 0.3046456958566393\n",
      "Epoch 2, Loss: 0.049626187554427555\n",
      "Epoch 3, Loss: 0.014820772156651531\n",
      "Epoch 4, Loss: 0.00826866798368948\n",
      "Epoch 5, Loss: 0.0016601919030238474\n",
      "Epoch 6, Loss: 0.0009419115127197333\n",
      "all_preds shape: (175,)\n",
      "all_labels shape: (175,)\n",
      "all_probs shape: (175, 2)\n",
      "Train labels sample: tensor([0, 0, 0, 1, 1]), Shape: torch.Size([888])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([166])\n",
      "Epoch 1, Loss: 0.3083771743944713\n",
      "Epoch 2, Loss: 0.028635866474360228\n",
      "Epoch 3, Loss: 0.015681602592979158\n",
      "Epoch 4, Loss: 0.012073948264255055\n",
      "Epoch 5, Loss: 0.01577141405349331\n",
      "Epoch 6, Loss: 0.006558292329178325\n",
      "all_preds shape: (166,)\n",
      "all_labels shape: (166,)\n",
      "all_probs shape: (166, 2)\n",
      "Train labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([888])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([165])\n",
      "Epoch 1, Loss: 0.4505480208567211\n",
      "Epoch 2, Loss: 0.08849980682134628\n",
      "Epoch 3, Loss: 0.019763202472989048\n",
      "Epoch 4, Loss: 0.011709157610312104\n",
      "Epoch 5, Loss: 0.0053287459969786665\n",
      "Epoch 6, Loss: 0.020879501992437457\n",
      "all_preds shape: (165,)\n",
      "all_labels shape: (165,)\n",
      "all_probs shape: (165, 2)\n",
      "Train labels sample: tensor([1, 0, 1, 0, 0]), Shape: torch.Size([888])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([165])\n",
      "Epoch 1, Loss: 0.35003930436713354\n",
      "Epoch 2, Loss: 0.03909541852772236\n",
      "Epoch 3, Loss: 0.014272715297660657\n",
      "Epoch 4, Loss: 0.004463041334279946\n",
      "Epoch 5, Loss: 0.004197441157884896\n",
      "Epoch 6, Loss: 0.005245077748051179\n",
      "all_preds shape: (165,)\n",
      "all_labels shape: (165,)\n",
      "all_probs shape: (165, 2)\n",
      "Train labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([888])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([165])\n",
      "Epoch 1, Loss: 0.32968301326036453\n",
      "Epoch 2, Loss: 0.047406762572271485\n",
      "Epoch 3, Loss: 0.029120171243058785\n",
      "Epoch 4, Loss: 0.027273942583373616\n",
      "Epoch 5, Loss: 0.0304839586273634\n",
      "Epoch 6, Loss: 0.0019598210097423623\n",
      "all_preds shape: (165,)\n",
      "all_labels shape: (165,)\n",
      "all_probs shape: (165, 2)\n",
      "Train labels sample: tensor([0, 1, 1, 0, 1]), Shape: torch.Size([888])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([161])\n",
      "Epoch 1, Loss: 0.3874376543930599\n",
      "Epoch 2, Loss: 0.10245879313775472\n",
      "Epoch 3, Loss: 0.02484535173113857\n",
      "Epoch 4, Loss: 0.004513476143724152\n",
      "Epoch 5, Loss: 0.011767766521578389\n",
      "Epoch 6, Loss: 0.01619568412258689\n",
      "all_preds shape: (161,)\n",
      "all_labels shape: (161,)\n",
      "all_probs shape: (161, 2)\n",
      "train_Изъяты лексемы с частотой выше 100.csv\n",
      "test_Изъяты лексемы с частотой выше 100.csv\n",
      "Train labels sample: tensor([1, 1, 1, 0, 0]), Shape: torch.Size([871])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([190])\n",
      "Epoch 1, Loss: 0.2980841669653143\n",
      "Epoch 2, Loss: 0.06259956317288536\n",
      "Epoch 3, Loss: 0.025442225991615226\n",
      "Epoch 4, Loss: 0.016364791696625098\n",
      "Epoch 5, Loss: 0.011676284102057772\n",
      "Epoch 6, Loss: 0.009745315698507642\n",
      "all_preds shape: (190,)\n",
      "all_labels shape: (190,)\n",
      "all_probs shape: (190, 2)\n",
      "Train labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([871])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([192])\n",
      "Epoch 1, Loss: 0.368491924234799\n",
      "Epoch 2, Loss: 0.08270320881690298\n",
      "Epoch 3, Loss: 0.0750741668577705\n",
      "Epoch 4, Loss: 0.03179102510746036\n",
      "Epoch 5, Loss: 0.01592305488884449\n",
      "Epoch 6, Loss: 0.00768464248228286\n",
      "all_preds shape: (192,)\n",
      "all_labels shape: (192,)\n",
      "all_probs shape: (192, 2)\n",
      "Train labels sample: tensor([0, 0, 1, 1, 1]), Shape: torch.Size([871])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([190])\n",
      "Epoch 1, Loss: 0.5070545056036541\n",
      "Epoch 2, Loss: 0.08119058183261327\n",
      "Epoch 3, Loss: 0.023635654045002803\n",
      "Epoch 4, Loss: 0.014877594408712216\n",
      "Epoch 5, Loss: 0.0030090563731001957\n",
      "Epoch 6, Loss: 0.0016761362619165862\n",
      "all_preds shape: (190,)\n",
      "all_labels shape: (190,)\n",
      "all_probs shape: (190, 2)\n",
      "Train labels sample: tensor([1, 1, 1, 0, 1]), Shape: torch.Size([871])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([200])\n",
      "Epoch 1, Loss: 0.3884051250559943\n",
      "Epoch 2, Loss: 0.04247987988804068\n",
      "Epoch 3, Loss: 0.048857501574925015\n",
      "Epoch 4, Loss: 0.01491375726514629\n",
      "Epoch 5, Loss: 0.027186937231038297\n",
      "Epoch 6, Loss: 0.009779073763638735\n",
      "all_preds shape: (200,)\n",
      "all_labels shape: (200,)\n",
      "all_probs shape: (200, 2)\n",
      "Train labels sample: tensor([0, 0, 0, 0, 1]), Shape: torch.Size([871])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([189])\n",
      "Epoch 1, Loss: 0.39469926059246063\n",
      "Epoch 2, Loss: 0.0668208689561912\n",
      "Epoch 3, Loss: 0.02147073019295931\n",
      "Epoch 4, Loss: 0.004727874117504273\n",
      "Epoch 5, Loss: 0.006954811895931405\n",
      "Epoch 6, Loss: 0.001308762950689665\n",
      "all_preds shape: (189,)\n",
      "all_labels shape: (189,)\n",
      "all_probs shape: (189, 2)\n",
      "Train labels sample: tensor([0, 0, 0, 0, 1]), Shape: torch.Size([871])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([191])\n",
      "Epoch 1, Loss: 0.3812298093523298\n",
      "Epoch 2, Loss: 0.1135103665292263\n",
      "Epoch 3, Loss: 0.049888265053076405\n",
      "Epoch 4, Loss: 0.018664518038609197\n",
      "Epoch 5, Loss: 0.007675884757190943\n",
      "Epoch 6, Loss: 0.002728367507058595\n",
      "all_preds shape: (191,)\n",
      "all_labels shape: (191,)\n",
      "all_probs shape: (191, 2)\n",
      "train_1.Первый жанр исходная выборка.csv\n",
      "test_1.Первый жанр исходная выборка.csv\n",
      "Train labels sample: tensor([1, 1, 1, 0, 0]), Shape: torch.Size([893])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([169])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.3739632357444082\n",
      "Epoch 2, Loss: 0.046635067356484275\n",
      "Epoch 3, Loss: 0.05151533581582563\n",
      "Epoch 4, Loss: 0.021691589183839306\n",
      "Epoch 5, Loss: 0.00633539109756904\n",
      "Epoch 6, Loss: 0.004937135331731822\n",
      "all_preds shape: (169,)\n",
      "all_labels shape: (169,)\n",
      "all_probs shape: (169, 2)\n",
      "Train labels sample: tensor([1, 0, 1, 0, 0]), Shape: torch.Size([893])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([164])\n",
      "Epoch 1, Loss: 0.49733954455171314\n",
      "Epoch 2, Loss: 0.09982437533991677\n",
      "Epoch 3, Loss: 0.025377418180661544\n",
      "Epoch 4, Loss: 0.016392703833324567\n",
      "Epoch 5, Loss: 0.0037249907452080932\n",
      "Epoch 6, Loss: 0.0024078608257696033\n",
      "all_preds shape: (164,)\n",
      "all_labels shape: (164,)\n",
      "all_probs shape: (164, 2)\n",
      "Train labels sample: tensor([1, 0, 1, 0, 0]), Shape: torch.Size([893])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([164])\n",
      "Epoch 1, Loss: 0.5543669249330249\n",
      "Epoch 2, Loss: 0.09280082583427429\n",
      "Epoch 3, Loss: 0.05177431067984019\n",
      "Epoch 4, Loss: 0.016960939592016593\n",
      "Epoch 5, Loss: 0.008830353085483824\n",
      "Epoch 6, Loss: 0.0025230476665975793\n",
      "all_preds shape: (164,)\n",
      "all_labels shape: (164,)\n",
      "all_probs shape: (164, 2)\n",
      "Train labels sample: tensor([0, 0, 0, 1, 1]), Shape: torch.Size([893])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([169])\n",
      "Epoch 1, Loss: 0.47149636490004404\n",
      "Epoch 2, Loss: 0.07763762293117386\n",
      "Epoch 3, Loss: 0.06625912398365992\n",
      "Epoch 4, Loss: 0.025918185112199614\n",
      "Epoch 5, Loss: 0.015091316841010536\n",
      "Epoch 6, Loss: 0.007119214860722423\n",
      "all_preds shape: (169,)\n",
      "all_labels shape: (169,)\n",
      "all_probs shape: (169, 2)\n",
      "Train labels sample: tensor([0, 0, 1, 0, 1]), Shape: torch.Size([893])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([158])\n",
      "Epoch 1, Loss: 0.3445317340748651\n",
      "Epoch 2, Loss: 0.09352269529231957\n",
      "Epoch 3, Loss: 0.036126471257635524\n",
      "Epoch 4, Loss: 0.010865454628531421\n",
      "Epoch 5, Loss: 0.009856833377853036\n",
      "Epoch 6, Loss: 0.005983754942592766\n",
      "all_preds shape: (158,)\n",
      "all_labels shape: (158,)\n",
      "all_probs shape: (158, 2)\n",
      "Train labels sample: tensor([1, 0, 0, 1, 0]), Shape: torch.Size([893])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([160])\n",
      "Epoch 1, Loss: 0.383063011935779\n",
      "Epoch 2, Loss: 0.05530363614005702\n",
      "Epoch 3, Loss: 0.03351851466244885\n",
      "Epoch 4, Loss: 0.013048655286963497\n",
      "Epoch 5, Loss: 0.006045986233013017\n",
      "Epoch 6, Loss: 0.019721555041282306\n",
      "all_preds shape: (160,)\n",
      "all_labels shape: (160,)\n",
      "all_probs shape: (160, 2)\n",
      "train_Изъяты лексемы с частотой выше 100.csv\n",
      "test_Изъяты лексемы с частотой выше 100.csv\n",
      "Train labels sample: tensor([1, 1, 1, 0, 0]), Shape: torch.Size([871])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([190])\n",
      "Epoch 1, Loss: 0.8071761471884591\n",
      "Epoch 2, Loss: 0.6654491680009025\n",
      "Epoch 3, Loss: 0.6563413568905422\n",
      "Epoch 4, Loss: 0.652600611959185\n",
      "Epoch 5, Loss: 0.6495933447565351\n",
      "Epoch 6, Loss: 0.6376218625477382\n",
      "all_preds shape: (190,)\n",
      "all_labels shape: (190,)\n",
      "all_probs shape: (190, 2)\n",
      "Train labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([871])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([192])\n",
      "Epoch 1, Loss: 0.9004837700298854\n",
      "Epoch 2, Loss: 0.6931014742170062\n",
      "Epoch 3, Loss: 0.668530557836805\n",
      "Epoch 4, Loss: 0.6707924774714878\n",
      "Epoch 5, Loss: 0.6693378857203892\n",
      "Epoch 6, Loss: 0.6656189731189183\n",
      "all_preds shape: (192,)\n",
      "all_labels shape: (192,)\n",
      "all_probs shape: (192, 2)\n",
      "Train labels sample: tensor([0, 0, 1, 1, 1]), Shape: torch.Size([871])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([190])\n",
      "Epoch 1, Loss: 0.8950305581092834\n",
      "Epoch 2, Loss: 0.6943391306059701\n",
      "Epoch 3, Loss: 0.6735856192452567\n",
      "Epoch 4, Loss: 0.665157505444118\n",
      "Epoch 5, Loss: 0.6612624270575387\n",
      "Epoch 6, Loss: 0.6587281652859279\n",
      "all_preds shape: (190,)\n",
      "all_labels shape: (190,)\n",
      "all_probs shape: (190, 2)\n",
      "Train labels sample: tensor([1, 1, 1, 0, 1]), Shape: torch.Size([871])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([200])\n",
      "Epoch 1, Loss: 0.8972793902669635\n",
      "Epoch 2, Loss: 0.6878210050719125\n",
      "Epoch 3, Loss: 0.6657601765223912\n",
      "Epoch 4, Loss: 0.6611689925193787\n",
      "Epoch 5, Loss: 0.6573043210165841\n",
      "Epoch 6, Loss: 0.6453092779432025\n",
      "all_preds shape: (200,)\n",
      "all_labels shape: (200,)\n",
      "all_probs shape: (200, 2)\n",
      "Train labels sample: tensor([0, 0, 0, 0, 1]), Shape: torch.Size([871])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([189])\n",
      "Epoch 1, Loss: 0.8815067069871085\n",
      "Epoch 2, Loss: 0.6809253862925938\n",
      "Epoch 3, Loss: 0.6666228515761239\n",
      "Epoch 4, Loss: 0.6705131701060704\n",
      "Epoch 5, Loss: 0.6667794159480503\n",
      "Epoch 6, Loss: 0.6746700831821987\n",
      "all_preds shape: (189,)\n",
      "all_labels shape: (189,)\n",
      "all_probs shape: (189, 2)\n",
      "Train labels sample: tensor([0, 0, 0, 0, 1]), Shape: torch.Size([871])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([191])\n",
      "Epoch 1, Loss: 0.9633069123540606\n",
      "Epoch 2, Loss: 0.6930692536490304\n",
      "Epoch 3, Loss: 0.680635392665863\n",
      "Epoch 4, Loss: 0.6775682994297573\n",
      "Epoch 5, Loss: 0.6694468004362923\n",
      "Epoch 6, Loss: 0.6695350153105599\n",
      "all_preds shape: (191,)\n",
      "all_labels shape: (191,)\n",
      "all_probs shape: (191, 2)\n",
      "train_1.Первый жанр исходная выборка.csv\n",
      "test_1.Первый жанр исходная выборка.csv\n",
      "Train labels sample: tensor([1, 1, 1, 0, 0]), Shape: torch.Size([893])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([169])\n",
      "Epoch 1, Loss: 0.8498027920722961\n",
      "Epoch 2, Loss: 0.6922602653503418\n",
      "Epoch 3, Loss: 0.6744090574128287\n",
      "Epoch 4, Loss: 0.6638824599129813\n",
      "Epoch 5, Loss: 0.6678365213530404\n",
      "Epoch 6, Loss: 0.659518871988569\n",
      "all_preds shape: (169,)\n",
      "all_labels shape: (169,)\n",
      "all_probs shape: (169, 2)\n",
      "Train labels sample: tensor([1, 0, 1, 0, 0]), Shape: torch.Size([893])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([164])\n",
      "Epoch 1, Loss: 0.9351479411125183\n",
      "Epoch 2, Loss: 0.6971280830247062\n",
      "Epoch 3, Loss: 0.6839134097099304\n",
      "Epoch 4, Loss: 0.6724983709199088\n",
      "Epoch 5, Loss: 0.6698312163352966\n",
      "Epoch 6, Loss: 0.6729138578687396\n",
      "all_preds shape: (164,)\n",
      "all_labels shape: (164,)\n",
      "all_probs shape: (164, 2)\n",
      "Train labels sample: tensor([1, 0, 1, 0, 0]), Shape: torch.Size([893])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([164])\n",
      "Epoch 1, Loss: 0.8677647284099034\n",
      "Epoch 2, Loss: 0.6903993487358093\n",
      "Epoch 3, Loss: 0.6762953911508832\n",
      "Epoch 4, Loss: 0.6741595183100019\n",
      "Epoch 5, Loss: 0.6653449024472918\n",
      "Epoch 6, Loss: 0.665375794683184\n",
      "all_preds shape: (164,)\n",
      "all_labels shape: (164,)\n",
      "all_probs shape: (164, 2)\n",
      "Train labels sample: tensor([0, 0, 0, 1, 1]), Shape: torch.Size([893])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([169])\n",
      "Epoch 1, Loss: 0.7736740452902657\n",
      "Epoch 2, Loss: 0.6594176888465881\n",
      "Epoch 3, Loss: 0.6494511195591518\n",
      "Epoch 4, Loss: 0.5805986864226205\n",
      "Epoch 5, Loss: 0.41628427164895193\n",
      "Epoch 6, Loss: 0.2835297797407423\n",
      "all_preds shape: (169,)\n",
      "all_labels shape: (169,)\n",
      "all_probs shape: (169, 2)\n",
      "Train labels sample: tensor([0, 0, 1, 0, 1]), Shape: torch.Size([893])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([158])\n",
      "Epoch 1, Loss: 0.8820084759167263\n",
      "Epoch 2, Loss: 0.6680098601749965\n",
      "Epoch 3, Loss: 0.6708650418690273\n",
      "Epoch 4, Loss: 0.662563613482884\n",
      "Epoch 5, Loss: 0.6631785716329303\n",
      "Epoch 6, Loss: 0.6663902657372611\n",
      "all_preds shape: (158,)\n",
      "all_labels shape: (158,)\n",
      "all_probs shape: (158, 2)\n",
      "Train labels sample: tensor([1, 0, 0, 1, 0]), Shape: torch.Size([893])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([160])\n",
      "Epoch 1, Loss: 0.8940751893179757\n",
      "Epoch 2, Loss: 0.6829661130905151\n",
      "Epoch 3, Loss: 0.6663183740207127\n",
      "Epoch 4, Loss: 0.6617076141493661\n",
      "Epoch 5, Loss: 0.6607134171894619\n",
      "Epoch 6, Loss: 0.6608528665133885\n",
      "all_preds shape: (160,)\n",
      "all_labels shape: (160,)\n",
      "all_probs shape: (160, 2)\n",
      "train_Изъяты лексемы с частотой выше 100.csv\n",
      "test_Изъяты лексемы с частотой выше 100.csv\n",
      "Train labels sample: tensor([0, 0, 1, 0, 0]), Shape: torch.Size([887])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([200])\n",
      "Epoch 1, Loss: 0.7748863186155047\n",
      "Epoch 2, Loss: 0.6722561291285923\n",
      "Epoch 3, Loss: 0.6583530391965594\n",
      "Epoch 4, Loss: 0.660930871963501\n",
      "Epoch 5, Loss: 0.6431299533162799\n",
      "Epoch 6, Loss: 0.6490974000522068\n",
      "all_preds shape: (200,)\n",
      "all_labels shape: (200,)\n",
      "all_probs shape: (200, 2)\n",
      "Train labels sample: tensor([0, 0, 0, 1, 0]), Shape: torch.Size([887])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([203])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.9040160434586662\n",
      "Epoch 2, Loss: 0.6759007147380284\n",
      "Epoch 3, Loss: 0.6704493590763637\n",
      "Epoch 4, Loss: 0.6645495891571045\n",
      "Epoch 5, Loss: 0.6620397567749023\n",
      "Epoch 6, Loss: 0.6626296554292951\n",
      "all_preds shape: (203,)\n",
      "all_labels shape: (203,)\n",
      "all_probs shape: (203, 2)\n",
      "Train labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([887])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([199])\n",
      "Epoch 1, Loss: 0.8801490494183132\n",
      "Epoch 2, Loss: 0.684903587613787\n",
      "Epoch 3, Loss: 0.6708846858569554\n",
      "Epoch 4, Loss: 0.6669694270406451\n",
      "Epoch 5, Loss: 0.660994325365339\n",
      "Epoch 6, Loss: 0.6637258444513593\n",
      "all_preds shape: (199,)\n",
      "all_labels shape: (199,)\n",
      "all_probs shape: (199, 2)\n",
      "Train labels sample: tensor([0, 1, 0, 0, 0]), Shape: torch.Size([887])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([194])\n",
      "Epoch 1, Loss: 1.0147884828703744\n",
      "Epoch 2, Loss: 0.6897607105118888\n",
      "Epoch 3, Loss: 0.6736181463514056\n",
      "Epoch 4, Loss: 0.6641272902488708\n",
      "Epoch 5, Loss: 0.671034038066864\n",
      "Epoch 6, Loss: 0.6603925483567374\n",
      "all_preds shape: (194,)\n",
      "all_labels shape: (194,)\n",
      "all_probs shape: (194, 2)\n",
      "Train labels sample: tensor([0, 1, 0, 0, 0]), Shape: torch.Size([887])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([183])\n",
      "Epoch 1, Loss: 0.9249727215085711\n",
      "Epoch 2, Loss: 0.6992727858679635\n",
      "Epoch 3, Loss: 0.6696341122899737\n",
      "Epoch 4, Loss: 0.6657330053193229\n",
      "Epoch 5, Loss: 0.6613431147166661\n",
      "Epoch 6, Loss: 0.661947923047202\n",
      "all_preds shape: (183,)\n",
      "all_labels shape: (183,)\n",
      "all_probs shape: (183, 2)\n",
      "Train labels sample: tensor([1, 1, 1, 0, 0]), Shape: torch.Size([887])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([189])\n",
      "Epoch 1, Loss: 0.9607001287596566\n",
      "Epoch 2, Loss: 0.6981463432312012\n",
      "Epoch 3, Loss: 0.693332850933075\n",
      "Epoch 4, Loss: 0.6782452889851162\n",
      "Epoch 5, Loss: 0.6594014763832092\n",
      "Epoch 6, Loss: 0.6701882481575012\n",
      "all_preds shape: (189,)\n",
      "all_labels shape: (189,)\n",
      "all_probs shape: (189, 2)\n",
      "train_1.Первый жанр исходная выборка.csv\n",
      "test_1.Первый жанр исходная выборка.csv\n",
      "Train labels sample: tensor([1, 0, 0, 1, 1]), Shape: torch.Size([912])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([169])\n",
      "Epoch 1, Loss: 0.8338094055652618\n",
      "Epoch 2, Loss: 0.6832779571413994\n",
      "Epoch 3, Loss: 0.6703584492206573\n",
      "Epoch 4, Loss: 0.6556365787982941\n",
      "Epoch 5, Loss: 0.6656618341803551\n",
      "Epoch 6, Loss: 0.653018593788147\n",
      "all_preds shape: (169,)\n",
      "all_labels shape: (169,)\n",
      "all_probs shape: (169, 2)\n",
      "Train labels sample: tensor([0, 0, 0, 1, 1]), Shape: torch.Size([912])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([169])\n",
      "Epoch 1, Loss: 0.9002974331378937\n",
      "Epoch 2, Loss: 0.681846559047699\n",
      "Epoch 3, Loss: 0.6791367828845978\n",
      "Epoch 4, Loss: 0.6719870418310165\n",
      "Epoch 5, Loss: 0.6888494342565536\n",
      "Epoch 6, Loss: 0.6664277091622353\n",
      "all_preds shape: (169,)\n",
      "all_labels shape: (169,)\n",
      "all_probs shape: (169, 2)\n",
      "Train labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([912])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([168])\n",
      "Epoch 1, Loss: 0.7754160240292549\n",
      "Epoch 2, Loss: 0.6844696253538132\n",
      "Epoch 3, Loss: 0.6751008257269859\n",
      "Epoch 4, Loss: 0.6616140156984329\n",
      "Epoch 5, Loss: 0.6474443674087524\n",
      "Epoch 6, Loss: 0.6629531979560852\n",
      "all_preds shape: (168,)\n",
      "all_labels shape: (168,)\n",
      "all_probs shape: (168, 2)\n",
      "Train labels sample: tensor([1, 1, 1, 1, 0]), Shape: torch.Size([912])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([167])\n",
      "Epoch 1, Loss: 0.7864488661289215\n",
      "Epoch 2, Loss: 0.6791935637593269\n",
      "Epoch 3, Loss: 0.6518305167555809\n",
      "Epoch 4, Loss: 0.6663543283939362\n",
      "Epoch 5, Loss: 0.6717585399746895\n",
      "Epoch 6, Loss: 0.6602609008550644\n",
      "all_preds shape: (167,)\n",
      "all_labels shape: (167,)\n",
      "all_probs shape: (167, 2)\n",
      "Train labels sample: tensor([0, 1, 0, 0, 0]), Shape: torch.Size([912])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([168])\n",
      "Epoch 1, Loss: 0.8211872577667236\n",
      "Epoch 2, Loss: 0.6854568123817444\n",
      "Epoch 3, Loss: 0.6767724454402924\n",
      "Epoch 4, Loss: 0.6602822244167328\n",
      "Epoch 5, Loss: 0.6505830436944962\n",
      "Epoch 6, Loss: 0.6663383170962334\n",
      "all_preds shape: (168,)\n",
      "all_labels shape: (168,)\n",
      "all_probs shape: (168, 2)\n",
      "Train labels sample: tensor([1, 0, 0, 0, 1]), Shape: torch.Size([912])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([152])\n",
      "Epoch 1, Loss: 0.8110586032271385\n",
      "Epoch 2, Loss: 0.7038716897368431\n",
      "Epoch 3, Loss: 0.6877636313438416\n",
      "Epoch 4, Loss: 0.6729128584265709\n",
      "Epoch 5, Loss: 0.6671715900301933\n",
      "Epoch 6, Loss: 0.6746296659111977\n",
      "all_preds shape: (152,)\n",
      "all_labels shape: (152,)\n",
      "all_probs shape: (152, 2)\n",
      "train_Изъяты лексемы с частотой выше 100.csv\n",
      "test_Изъяты лексемы с частотой выше 100.csv\n",
      "Train labels sample: tensor([0, 0, 1, 0, 0]), Shape: torch.Size([876])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([205])\n",
      "Epoch 1, Loss: 0.6623252630233765\n",
      "Epoch 2, Loss: 0.6099189434732709\n",
      "Epoch 3, Loss: 0.576145065682275\n",
      "Epoch 4, Loss: 0.5632724527801786\n",
      "Epoch 5, Loss: 0.5382360752139773\n",
      "Epoch 6, Loss: 0.4891888477972576\n",
      "all_preds shape: (205,)\n",
      "all_labels shape: (205,)\n",
      "all_probs shape: (205, 2)\n",
      "Train labels sample: tensor([0, 0, 0, 0, 1]), Shape: torch.Size([876])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([210])\n",
      "Epoch 1, Loss: 0.6796164299760546\n",
      "Epoch 2, Loss: 0.6094832760947091\n",
      "Epoch 3, Loss: 0.5844805794102805\n",
      "Epoch 4, Loss: 0.5680764636823109\n",
      "Epoch 5, Loss: 0.560800130878176\n",
      "Epoch 6, Loss: 0.5420544892549515\n",
      "all_preds shape: (210,)\n",
      "all_labels shape: (210,)\n",
      "all_probs shape: (210, 2)\n",
      "Train labels sample: tensor([0, 0, 0, 1, 0]), Shape: torch.Size([876])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([190])\n",
      "Epoch 1, Loss: 0.9193017908505031\n",
      "Epoch 2, Loss: 0.6659050328390939\n",
      "Epoch 3, Loss: 0.591091262442725\n",
      "Epoch 4, Loss: 0.5688922277518681\n",
      "Epoch 5, Loss: 0.5298527564321246\n",
      "Epoch 6, Loss: 0.4821105918713978\n",
      "all_preds shape: (190,)\n",
      "all_labels shape: (190,)\n",
      "all_probs shape: (190, 2)\n",
      "Train labels sample: tensor([0, 0, 0, 1, 0]), Shape: torch.Size([876])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([194])\n",
      "Epoch 1, Loss: 0.6903402635029384\n",
      "Epoch 2, Loss: 0.5784687101840973\n",
      "Epoch 3, Loss: 0.5621633401938847\n",
      "Epoch 4, Loss: 0.5239621464695249\n",
      "Epoch 5, Loss: 0.49124735380922047\n",
      "Epoch 6, Loss: 0.4415626462016787\n",
      "all_preds shape: (194,)\n",
      "all_labels shape: (194,)\n",
      "all_probs shape: (194, 2)\n",
      "Train labels sample: tensor([1, 0, 1, 0, 1]), Shape: torch.Size([876])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([190])\n",
      "Epoch 1, Loss: 0.9391619307654244\n",
      "Epoch 2, Loss: 0.5954850614070892\n",
      "Epoch 3, Loss: 0.5544931037085397\n",
      "Epoch 4, Loss: 0.5197737110512597\n",
      "Epoch 5, Loss: 0.4926387816667557\n",
      "Epoch 6, Loss: 0.4356678639139448\n",
      "all_preds shape: (190,)\n",
      "all_labels shape: (190,)\n",
      "all_probs shape: (190, 2)\n",
      "Train labels sample: tensor([0, 1, 1, 1, 0]), Shape: torch.Size([876])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([187])\n",
      "Epoch 1, Loss: 1.718851021357945\n",
      "Epoch 2, Loss: 0.7088099462645394\n",
      "Epoch 3, Loss: 0.6166907293455941\n",
      "Epoch 4, Loss: 0.5885096022060939\n",
      "Epoch 5, Loss: 0.5749397107533046\n",
      "Epoch 6, Loss: 0.5471679738589695\n",
      "all_preds shape: (187,)\n",
      "all_labels shape: (187,)\n",
      "all_probs shape: (187, 2)\n",
      "train_1.Первый жанр исходная выборка.csv\n",
      "test_1.Первый жанр исходная выборка.csv\n",
      "Train labels sample: tensor([0, 1, 0, 0, 1]), Shape: torch.Size([900])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([167])\n",
      "Epoch 1, Loss: 1.77743821144104\n",
      "Epoch 2, Loss: 0.7313036322593689\n",
      "Epoch 3, Loss: 0.616239607334137\n",
      "Epoch 4, Loss: 0.5894339263439179\n",
      "Epoch 5, Loss: 0.5488479892412822\n",
      "Epoch 6, Loss: 0.5230151851971944\n",
      "all_preds shape: (167,)\n",
      "all_labels shape: (167,)\n",
      "all_probs shape: (167, 2)\n",
      "Train labels sample: tensor([1, 0, 0, 1, 1]), Shape: torch.Size([900])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([159])\n",
      "Epoch 1, Loss: 1.3186337351799011\n",
      "Epoch 2, Loss: 0.6840644756952922\n",
      "Epoch 3, Loss: 0.5674396614233653\n",
      "Epoch 4, Loss: 0.5252012014389038\n",
      "Epoch 5, Loss: 0.48930118680000306\n",
      "Epoch 6, Loss: 0.4424501955509186\n",
      "all_preds shape: (159,)\n",
      "all_labels shape: (159,)\n",
      "all_probs shape: (159, 2)\n",
      "Train labels sample: tensor([1, 1, 1, 1, 1]), Shape: torch.Size([900])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([162])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 1.2131410221258798\n",
      "Epoch 2, Loss: 0.5921114842096965\n",
      "Epoch 3, Loss: 0.5892889738082886\n",
      "Epoch 4, Loss: 0.5156688074270884\n",
      "Epoch 5, Loss: 0.49319352904955543\n",
      "Epoch 6, Loss: 0.476404865582784\n",
      "all_preds shape: (162,)\n",
      "all_labels shape: (162,)\n",
      "all_probs shape: (162, 2)\n",
      "Train labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([900])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([161])\n",
      "Epoch 1, Loss: 0.6183641831080119\n",
      "Epoch 2, Loss: 0.5665915111700693\n",
      "Epoch 3, Loss: 0.5657343149185181\n",
      "Epoch 4, Loss: 0.5572344402472178\n",
      "Epoch 5, Loss: 0.515760354200999\n",
      "Epoch 6, Loss: 0.4764257351557414\n",
      "all_preds shape: (161,)\n",
      "all_labels shape: (161,)\n",
      "all_probs shape: (161, 2)\n",
      "Train labels sample: tensor([0, 1, 1, 0, 0]), Shape: torch.Size([900])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([158])\n",
      "Epoch 1, Loss: 1.4152865211168926\n",
      "Epoch 2, Loss: 0.6237733324368795\n",
      "Epoch 3, Loss: 0.5173249026139577\n",
      "Epoch 4, Loss: 0.5044663906097412\n",
      "Epoch 5, Loss: 0.43728011250495913\n",
      "Epoch 6, Loss: 0.382498895128568\n",
      "all_preds shape: (158,)\n",
      "all_labels shape: (158,)\n",
      "all_probs shape: (158, 2)\n",
      "Train labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([900])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([162])\n",
      "Epoch 1, Loss: 1.8753561099370322\n",
      "Epoch 2, Loss: 0.7282496094703674\n",
      "Epoch 3, Loss: 0.6373110771179199\n",
      "Epoch 4, Loss: 0.5840271810690562\n",
      "Epoch 5, Loss: 0.5314749797185262\n",
      "Epoch 6, Loss: 0.5405159036318461\n",
      "all_preds shape: (162,)\n",
      "all_labels shape: (162,)\n",
      "all_probs shape: (162, 2)\n",
      "train_Изъяты лексемы с частотой выше 100.csv\n",
      "test_Изъяты лексемы с частотой выше 100.csv\n",
      "Train labels sample: tensor([1, 1, 0, 0, 0]), Shape: torch.Size([880])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([197])\n",
      "Epoch 1, Loss: 0.5883917255061013\n",
      "Epoch 2, Loss: 0.4131399818829128\n",
      "Epoch 3, Loss: 0.23483910198722566\n",
      "Epoch 4, Loss: 0.10320174241704601\n",
      "Epoch 5, Loss: 0.07381990658385414\n",
      "Epoch 6, Loss: 0.03350831315453563\n",
      "all_preds shape: (197,)\n",
      "all_labels shape: (197,)\n",
      "all_probs shape: (197, 2)\n",
      "Train labels sample: tensor([0, 0, 0, 0, 1]), Shape: torch.Size([880])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([204])\n",
      "Epoch 1, Loss: 0.5348247843129295\n",
      "Epoch 2, Loss: 0.3144993579813412\n",
      "Epoch 3, Loss: 0.2018787137099675\n",
      "Epoch 4, Loss: 0.12280139034347874\n",
      "Epoch 5, Loss: 0.05907720220940454\n",
      "Epoch 6, Loss: 0.03692446183413267\n",
      "all_preds shape: (204,)\n",
      "all_labels shape: (204,)\n",
      "all_probs shape: (204, 2)\n",
      "Train labels sample: tensor([0, 1, 0, 0, 0]), Shape: torch.Size([880])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([191])\n",
      "Epoch 1, Loss: 0.5437778277056557\n",
      "Epoch 2, Loss: 0.3463572221142905\n",
      "Epoch 3, Loss: 0.19114085446510995\n",
      "Epoch 4, Loss: 0.09667565008359295\n",
      "Epoch 5, Loss: 0.04851682510759149\n",
      "Epoch 6, Loss: 0.033873558044433594\n",
      "all_preds shape: (191,)\n",
      "all_labels shape: (191,)\n",
      "all_probs shape: (191, 2)\n",
      "Train labels sample: tensor([0, 0, 1, 1, 0]), Shape: torch.Size([880])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([197])\n",
      "Epoch 1, Loss: 0.6083407274314335\n",
      "Epoch 2, Loss: 0.4208522119692394\n",
      "Epoch 3, Loss: 0.2141209686441081\n",
      "Epoch 4, Loss: 0.11173343019826072\n",
      "Epoch 5, Loss: 0.06865348507251058\n",
      "Epoch 6, Loss: 0.04556592380894082\n",
      "all_preds shape: (197,)\n",
      "all_labels shape: (197,)\n",
      "all_probs shape: (197, 2)\n",
      "Train labels sample: tensor([0, 1, 1, 0, 0]), Shape: torch.Size([880])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([194])\n",
      "Epoch 1, Loss: 0.5373367113726479\n",
      "Epoch 2, Loss: 0.3243324969496046\n",
      "Epoch 3, Loss: 0.15467004158667155\n",
      "Epoch 4, Loss: 0.08713016366319996\n",
      "Epoch 5, Loss: 0.07158607723457473\n",
      "Epoch 6, Loss: 0.051968496425875595\n",
      "all_preds shape: (194,)\n",
      "all_labels shape: (194,)\n",
      "all_probs shape: (194, 2)\n",
      "Train labels sample: tensor([1, 1, 0, 0, 1]), Shape: torch.Size([880])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([190])\n",
      "Epoch 1, Loss: 0.5444223838193076\n",
      "Epoch 2, Loss: 0.29624209127255846\n",
      "Epoch 3, Loss: 0.13449249310152872\n",
      "Epoch 4, Loss: 0.10594218650034495\n",
      "Epoch 5, Loss: 0.04744029909904514\n",
      "Epoch 6, Loss: 0.022845318873545954\n",
      "all_preds shape: (190,)\n",
      "all_labels shape: (190,)\n",
      "all_probs shape: (190, 2)\n",
      "train_1.Первый жанр исходная выборка.csv\n",
      "test_1.Первый жанр исходная выборка.csv\n",
      "Train labels sample: tensor([0, 0, 0, 1, 0]), Shape: torch.Size([905])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([170])\n",
      "Epoch 1, Loss: 0.5888458947340648\n",
      "Epoch 2, Loss: 0.4236793657143911\n",
      "Epoch 3, Loss: 0.2440290331840515\n",
      "Epoch 4, Loss: 0.14856167982021967\n",
      "Epoch 5, Loss: 0.0934219591319561\n",
      "Epoch 6, Loss: 0.05639076381921768\n",
      "all_preds shape: (170,)\n",
      "all_labels shape: (170,)\n",
      "all_probs shape: (170, 2)\n",
      "Train labels sample: tensor([1, 0, 0, 1, 1]), Shape: torch.Size([905])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([169])\n",
      "Epoch 1, Loss: 0.5768994768460591\n",
      "Epoch 2, Loss: 0.35506528119246167\n",
      "Epoch 3, Loss: 0.1702410121758779\n",
      "Epoch 4, Loss: 0.1220645194252332\n",
      "Epoch 5, Loss: 0.0874972295636932\n",
      "Epoch 6, Loss: 0.04097289405763149\n",
      "all_preds shape: (169,)\n",
      "all_labels shape: (169,)\n",
      "all_probs shape: (169, 2)\n",
      "Train labels sample: tensor([1, 0, 0, 0, 0]), Shape: torch.Size([905])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([164])\n",
      "Epoch 1, Loss: 0.5136900544166565\n",
      "Epoch 2, Loss: 0.26395557026068367\n",
      "Epoch 3, Loss: 0.1272677527119716\n",
      "Epoch 4, Loss: 0.06966361477971077\n",
      "Epoch 5, Loss: 0.09325299275418122\n",
      "Epoch 6, Loss: 0.05310521193314344\n",
      "all_preds shape: (164,)\n",
      "all_labels shape: (164,)\n",
      "all_probs shape: (164, 2)\n",
      "Train labels sample: tensor([1, 1, 0, 0, 1]), Shape: torch.Size([905])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([153])\n",
      "Epoch 1, Loss: 0.5830160915851593\n",
      "Epoch 2, Loss: 0.4350384384393692\n",
      "Epoch 3, Loss: 0.2585338662068049\n",
      "Epoch 4, Loss: 0.12905709246794383\n",
      "Epoch 5, Loss: 0.08044751435518264\n",
      "Epoch 6, Loss: 0.03571648287276427\n",
      "all_preds shape: (153,)\n",
      "all_labels shape: (153,)\n",
      "all_probs shape: (153, 2)\n",
      "Train labels sample: tensor([0, 1, 1, 1, 1]), Shape: torch.Size([905])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([165])\n",
      "Epoch 1, Loss: 0.6035879532496135\n",
      "Epoch 2, Loss: 0.4388018767038981\n",
      "Epoch 3, Loss: 0.27133314112822216\n",
      "Epoch 4, Loss: 0.16548166126012803\n",
      "Epoch 5, Loss: 0.08077623893817266\n"
     ]
    }
   ],
   "source": [
    "import funciones\n",
    "from utils import train_wrapper\n",
    "import warnings\n",
    "import os\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "from tqdm import tqdm\n",
    "from contextlib import redirect_stderr\n",
    "import multiprocessing as mp\n",
    "import numpy as np\n",
    "#import wandb\n",
    "import nbformat\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import gc\n",
    "import re\n",
    "import nltk\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import BertForSequenceClassification, AdamW\n",
    "from razdel import sentenize\n",
    "import numpy as np\n",
    "\n",
    "# Suprimir warnings específicos\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "mp.set_start_method('spawn', force=True)\n",
    "\n",
    "\n",
    "import json\n",
    "\n",
    "\n",
    "def convert_numpy(obj):\n",
    "    if isinstance(obj, np.ndarray):\n",
    "        return obj.tolist()\n",
    "    if isinstance(obj, (np.float32, np.float64, np.int32, np.int64)):\n",
    "        return obj.item()\n",
    "    return obj\n",
    "\n",
    "def save_results(results, filename):\n",
    "    with open(filename, 'w', encoding='utf-8') as f:\n",
    "        json.dump(results, f, indent=4, ensure_ascii=False, default=convert_numpy)\n",
    "\n",
    "# import funciones\n",
    "# from utils import train_wrapper\n",
    "# import warnings\n",
    "# import os\n",
    "# import torch\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # Suprimir warnings específicos\n",
    "# warnings.filterwarnings('ignore', category=UserWarning)  # Para sklearn y otros\n",
    "# warnings.filterwarnings('ignore', category=FutureWarning)  # Para huggingface y transformers\n",
    "# from concurrent.futures import ProcessPoolExecutor\n",
    "# from tqdm import tqdm\n",
    "# from contextlib import redirect_stderr\n",
    "# from concurrent.futures import ProcessPoolExecutor\n",
    "# import multiprocessing as mp\n",
    "# import numpy as np\n",
    "# mp.set_start_method('spawn', force=True)\n",
    "# #os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:128\"\n",
    "\n",
    "###############################################################################\n",
    "# import wandb\n",
    "# import nbformat\n",
    "# # Configurar la clave de la API como variable de entorno\n",
    "# os.environ[\"WANDB_API_KEY\"] = \"ca85316ed713b2425615fb3a613d7eb414c9f57f\"  # Reemplaza con tu clave\n",
    "# # Iniciar wandb sin especificar entity (se detecta automáticamente)\n",
    "# wandb.init(project=\"model-clasification\")\n",
    "# wandb.init(\n",
    "#     settings=wandb.Settings(\n",
    "#         start_method=\"thread\",\n",
    "#         timeout=30,\n",
    "#         sync_dir=\"/tmp/wandb\",  # Usa un directorio temporal\n",
    "#         disable_code=True       # Mejora la estabilidad\n",
    "#     )\n",
    "# )\n",
    "#os.environ[\"WANDB_NOTEBOOK_NAME\"] = \"сокращение по частотности.ipynb\"\n",
    "###############################################################################\n",
    "\n",
    "\n",
    "def create_custom_config(model_name, model_type, dataset):\n",
    "    \"\"\"Crea configuración de entrenamiento adaptativa\"\"\"\n",
    "    common_config = {\n",
    "#         'dataset_name':dataset.get('name', ''),\n",
    "        'model_name': model_name,\n",
    "        'model_type': model_type,\n",
    "        'num_repeats': 6,\n",
    "        'test_size': 0.2,\n",
    "        'threshold': 0.5\n",
    "    }\n",
    "\n",
    "    # Configuración específica para GPT\n",
    "    if model_type == 'gpt':\n",
    "        return funciones.TrainingConfig(\n",
    "            **common_config,\n",
    "            max_length=52,\n",
    "            batch_size=64,\n",
    "            epochs=6,\n",
    "            learning_rate=1e-5\n",
    "        )\n",
    "#         freq_threshold = dataset.get('freq_threshold')\n",
    "#         if freq_threshold in [100, 49, 29, 9, 5, 3]:\n",
    "#             configs = {\n",
    "#                 100: (52, 32, 6, 1e-5),#test 1\n",
    "#                 49: (60, 128, 4, 3e-5),\n",
    "#                 29: (51, 128, 4, 3e-5),\n",
    "#                 9: (45, 128, 5, 4e-5),\n",
    "#                 5: (150, 32, 6, 5e-5),\n",
    "#                 3: (150, 32, 6, 5e-5)\n",
    "#             }\n",
    "#             max_len, batch, epochs, lr = configs[freq_threshold]\n",
    "#             return funciones.TrainingConfig(\n",
    "#                 **common_config,\n",
    "#                 max_length=max_len,\n",
    "#                 batch_size=batch,\n",
    "#                 epochs=epochs,\n",
    "#                 learning_rate=lr\n",
    "#             )\n",
    "\n",
    "        # Configuración por nombre de dataset\n",
    "        dataset_name = dataset.get('name', '')\n",
    "        if any(x in dataset_name for x in ['1', '2', '3', '4']):\n",
    "            return funciones.TrainingConfig(\n",
    "                **common_config,\n",
    "                max_length=60,\n",
    "                batch_size=128,\n",
    "                epochs=6,\n",
    "                learning_rate=5e-5\n",
    "            )\n",
    "\n",
    "\n",
    "    # Configuraciones basadas en frecuencia\n",
    "    freq_threshold = dataset.get('freq_threshold')\n",
    "    if freq_threshold in [100, 49, 29, 9, 5, 3]:\n",
    "        configs = {\n",
    "            100: (52, 128, 3, 2e-5),\n",
    "            49: (60, 128, 4, 3e-5),\n",
    "            29: (51, 128, 4, 3e-5),\n",
    "            9: (45, 128, 5, 4e-5),\n",
    "            5: (150, 32, 6, 5e-5),\n",
    "            3: (150, 32, 6, 5e-5)\n",
    "        }\n",
    "        max_len, batch, epochs, lr = configs[freq_threshold]\n",
    "        return funciones.TrainingConfig(\n",
    "            **common_config,\n",
    "            max_length=max_len,\n",
    "            batch_size=batch,\n",
    "            epochs=epochs,\n",
    "            learning_rate=lr\n",
    "        )\n",
    "\n",
    "    # Configuración por nombre de dataset\n",
    "    dataset_name = dataset.get('name', '')\n",
    "    if any(x in dataset_name for x in ['1', '2', '3', '4']):\n",
    "        return funciones.TrainingConfig(\n",
    "            **common_config,\n",
    "            max_length=60,\n",
    "            batch_size=128,\n",
    "            epochs=6,\n",
    "            learning_rate=5e-5\n",
    "        )\n",
    "\n",
    "    # Configuración por defecto\n",
    "    return funciones.TrainingConfig(\n",
    "        **common_config,\n",
    "        max_length=60,\n",
    "        batch_size=32,\n",
    "        epochs=4,\n",
    "        learning_rate=3e-5\n",
    "    )\n",
    "\n",
    "models = [\n",
    "        {'model':'DeepPavlov/rubert-base-cased',\n",
    "         'name':'DeepPavlov-rubert-base',\n",
    "         'type': 'bert'},# Modelo original\n",
    "        {'model':'bert-base-multilingual-cased',\n",
    "         'name':'BERT multilingual',\n",
    "         'type': 'bert'},# BERT multilingüe\n",
    "        {'model':'distilbert-base-multilingual-cased',\n",
    "         'name':'distilbert-base-multilingual',\n",
    "         'type': 'bert'},# Versión ligera de BERT\n",
    "        {'model':'roberta-base',\n",
    "         'name':'roberta-base', \n",
    "        'type': 'bert'}, # RoBERTa \n",
    "        {'model': 'gpt2',\n",
    "         'name': 'gpt2',\n",
    "         'type': 'gpt'},  #  GPT model\n",
    "        {'model': 'facebook/opt-125m',\n",
    "         'name': 'facebook',\n",
    "         'type': 'gpt'},  #  GPT model\n",
    "        {'model': 'sberbank-ai/rugpt3small_based_on_gpt2',\n",
    "         'name': 'rugpt3',\n",
    "         'type': 'gpt'}\n",
    "    ]\n",
    "\n",
    "datasets = [\n",
    "        {\n",
    "            'path1': '../dataset/сокращение по частотности/1б_Изъяты лексемы с частотой выше 100.txt',\n",
    "            'path2': '../dataset/сокращение по частотности/2б_Изъяты лексемы с частотой выше 100.txt',\n",
    "            'name': 'Изъяты лексемы с частотой выше 100',\n",
    "            'type': 'freq',\n",
    "            'freq': 100\n",
    "        },\n",
    "#         {\n",
    "#             'path1': '../dataset/сокращение по частотности/1в_Изъяты лексемы с частотой выше 49.txt',\n",
    "#             'path2': '../dataset/сокращение по частотности/2в_Изъяты лексемы с частотой выше 49.txt',\n",
    "#             'name': 'Изъяты лексемы с частотой выше 49',\n",
    "#             'type': 'freq',\n",
    "#             'freq': 49\n",
    "#         },\n",
    "#         {\n",
    "#             'path1': '../dataset/сокращение по частотности/1г_Изъяты лексемы с частотой выше 29.txt',\n",
    "#             'path2': '../dataset/сокращение по частотности/2г_Изъяты лексемы с частотой выше 29.txt',\n",
    "#             'name': 'Изъяты лексемы с частотой выше 29',\n",
    "#             'type': 'freq',\n",
    "#             'freq': 29\n",
    "#         },\n",
    "#         {\n",
    "#             'path1': '../dataset/сокращение по частотности/1д_Изъяты лексемы с частотой выше 9.txt',\n",
    "#             'path2': '../dataset/сокращение по частотности/2д_Изъяты лексемы с частотой выше 9.txt',\n",
    "#             'name': 'Изъяты лексемы с частотой выше 9',\n",
    "#             'type': 'freq',\n",
    "#             'freq': 9\n",
    "#         },\n",
    "#         {\n",
    "#             'path1': '../dataset/сокращение по частотности/1е_Изъяты лексемы с частотой выше 5.txt',\n",
    "#             'path2': '../dataset/сокращение по частотности/2е_Изъяты лексемы с частотой выше 5.txt',\n",
    "#             'name': 'Изъяты лексемы с частотой выше 5',\n",
    "#             'type': 'freq',\n",
    "#             'freq': 5\n",
    "#         },\n",
    "#         {\n",
    "#             'path1': '../dataset/сокращение по частотности/1ё_Изъяты лексемы с частотой выше 3.txt',\n",
    "#             'path2': '../dataset/сокращение по частотности/2ё_Изъяты лексемы с частотой выше 3.txt',\n",
    "#             'name': 'Изъяты лексемы с частотой выше 3',\n",
    "#             'type': 'freq',\n",
    "#             'freq': 3\n",
    "#         },\n",
    "\n",
    "#             {\n",
    "#             'path1': '../dataset/Сокращение по частям речи/Без прилагательных первый жанр.txt',\n",
    "#             'path2': '../dataset/Сокращение по частям речи/Без прилагательных второй жанр.txt',\n",
    "#             'name': 'Без прилагательных второй жанр',\n",
    "#             'type': 'pos',\n",
    "#             'freq': None\n",
    "#             },\n",
    "          {\n",
    "            'path1': '../dataset/Сокращение по частям речи/1.Первый жанр исходная выборка.txt',\n",
    "            'path2': '../dataset/Второй_жанр_исходная.txt',\n",
    "            'name': '1.Первый жанр исходная выборка',\n",
    "            'type': 'pos',\n",
    "            'freq': None\n",
    "\n",
    "        },\n",
    "#         {\n",
    "#             'path1': '../dataset/Сокращение по частям речи/2.Первый жанр без клауз, включающих наречия.txt',\n",
    "#             'path2': '../dataset/Второй_жанр_исходная.txt',\n",
    "#             'name': '2.Первый жанр без клауз, включающих наречия',\n",
    "#             'type': 'pos',\n",
    "#             'freq': None\n",
    "#         },\n",
    "#         {\n",
    "#             'path1': '../dataset/Сокращение по частям речи/3.Первый жанр без клауз, включающих глаголы.txt',\n",
    "#             'path2': '../dataset/Второй_жанр_исходная.txt',\n",
    "#             'name': '3.Первый жанр без клауз, включающих глаголы',\n",
    "#             'type': 'pos',\n",
    "#             'freq': None\n",
    "#         },\n",
    "#         {\n",
    "#             'path1': '../dataset/Сокращение по частям речи/4.Первый жанр без клауз, включающих глаголы и наречия.txt',\n",
    "#             'path2': '../dataset/Второй_жанр_исходная.txt',\n",
    "#             'name': '4.Первый жанр без клауз, включающих глаголы и наречия',\n",
    "#             'type': 'pos',\n",
    "#             'freq': None\n",
    "#         },\n",
    "    ]\n",
    "\n",
    "def main():\n",
    "\n",
    "    results = []\n",
    "    for model in models:\n",
    "        for dataset in datasets:\n",
    "            config = create_custom_config(model['model'], model['type'], dataset)\n",
    "            \n",
    "            \n",
    "            # Entrenar y limpiar memoria\n",
    "            torch.cuda.empty_cache()\n",
    "            result = funciones.train_and_evaluate_dataset(\n",
    "                dataset['path1'],\n",
    "                dataset['path2'],\n",
    "                config,\n",
    "                dataset['name'],\n",
    "                dataset['type']\n",
    "                \n",
    "            )\n",
    "            results.append(result) \n",
    "        \n",
    "        del model\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "        \n",
    "    \n",
    "    save_results(results, 'model_results_GPT_bert_all.json')    \n",
    "\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd31457",
   "metadata": {},
   "outputs": [],
   "source": [
    "#batch_size=128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7dfbb89",
   "metadata": {},
   "outputs": [],
   "source": [
    "#display_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1ac659",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import IPython\n",
    "\n",
    "# Reiniciar el kernel\n",
    "IPython.display.display(IPython.display.Javascript(\"Jupyter.notebook.kernel.restart()\"))\n",
    "\n",
    "# Apagar el kernel después de reiniciar\n",
    "os._exit(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d8fee8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f4a8d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
