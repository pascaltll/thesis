{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e66a70c9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34m../dataset\u001b[00m\r\n",
      "├── \u001b[01;34men_espanol\u001b[00m\r\n",
      "│   ├── docx2txt.py\r\n",
      "│   ├── Второй_жанр_исходная.txt\r\n",
      "│   └── Первый_жанр_исходная.txt\r\n",
      "├── Второй_жанр_исходная.txt\r\n",
      "├── Первый_жанр_исходная.txt\r\n",
      "├── \u001b[01;34mСокращение по частям речи\u001b[00m\r\n",
      "│   ├── 1.Первый жанр исходная выборка.txt\r\n",
      "│   ├── 2.Первый жанр без клауз, включающих наречия.txt\r\n",
      "│   ├── 3.Первый жанр без клауз, включающих глаголы.txt\r\n",
      "│   ├── 4.Первый жанр без клауз, включающих глаголы и наречия.txt\r\n",
      "│   ├── 5.без клауз, включающих местоимения.txt\r\n",
      "│   ├── 6.без слов функциональных.txt\r\n",
      "│   ├── Без прилагательных второй жанр.txt\r\n",
      "│   ├── Без прилагательных первый жанр.txt\r\n",
      "│   ├── Второй_жанр без клауз, включающих местоимения.txt\r\n",
      "│   ├── Второй_жанр без слов функциональных.txt\r\n",
      "│   └── Случайные выборки.txt\r\n",
      "└── \u001b[01;34mсокращение по частотности\u001b[00m\r\n",
      "    ├── 1а_ без сокращений.txt\r\n",
      "    ├── 1б_Изъяты лексемы с частотой выше 100.txt\r\n",
      "    ├── 1в_Изъяты лексемы с частотой выше 49.txt\r\n",
      "    ├── 1г_Изъяты лексемы с частотой выше 29.txt\r\n",
      "    ├── 1д_Изъяты лексемы с частотой выше 9.txt\r\n",
      "    ├── 1е_Изъяты лексемы с частотой выше 5.txt\r\n",
      "    ├── 1ё_Изъяты лексемы с частотой выше 3.txt\r\n",
      "    ├── 2а_ без сокращений.txt\r\n",
      "    ├── 2б_Изъяты лексемы с частотой выше 100.txt\r\n",
      "    ├── 2в_Изъяты лексемы с частотой выше 49.txt\r\n",
      "    ├── 2г_Изъяты лексемы с частотой выше 29.txt\r\n",
      "    ├── 2д_Изъяты лексемы с частотой выше 9.txt\r\n",
      "    ├── 2е_Изъяты лексемы с частотой выше 5.txt\r\n",
      "    └── 2ё_Изъяты лексемы с частотой выше 3.txt\r\n",
      "\r\n",
      "3 directories, 30 files\r\n"
     ]
    }
   ],
   "source": [
    "!tree ../dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b299fb19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def save_results(results, filename):\n",
    "    with open(filename, 'w', encoding='utf-8') as f:\n",
    "        json.dump(results, f, indent=4, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11038bb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-23 13:02:44.193920: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_Изъяты лексемы с частотой выше 100.csv\n",
      "test_Изъяты лексемы с частотой выше 100.csv\n",
      "Train labels sample: tensor([0, 0, 0, 0, 1]), Shape: torch.Size([864])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([195])\n",
      "##########################DeepPavlov/rubert-base-cased---bert####################\n",
      "Epoch 1, Loss: 0.13408770542850512\n",
      "Epoch 2, Loss: 0.031455091472404696\n",
      "Epoch 3, Loss: 0.0025195426995331355\n",
      "Epoch 4, Loss: 0.0005683445762972244\n",
      "Epoch 5, Loss: 0.00036313768456845236\n",
      "Epoch 6, Loss: 0.00027049187364927666\n",
      "all_preds shape: (195,)\n",
      "all_labels shape: (195,)\n",
      "all_probs shape: (195, 2)\n",
      "Train labels sample: tensor([1, 0, 1, 0, 0]), Shape: torch.Size([864])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([198])\n",
      "##########################DeepPavlov/rubert-base-cased---bert####################\n",
      "Epoch 1, Loss: 0.15018639346170756\n",
      "Epoch 2, Loss: 0.02072213014104852\n",
      "Epoch 3, Loss: 0.001745199996986668\n",
      "Epoch 4, Loss: 0.0005900748699248113\n",
      "Epoch 5, Loss: 0.00036390640404230606\n",
      "Epoch 6, Loss: 0.0002733572107024008\n",
      "all_preds shape: (198,)\n",
      "all_labels shape: (198,)\n",
      "all_probs shape: (198, 2)\n",
      "Train labels sample: tensor([1, 0, 0, 0, 1]), Shape: torch.Size([864])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([196])\n",
      "##########################DeepPavlov/rubert-base-cased---bert####################\n",
      "Epoch 1, Loss: 0.14016012906924719\n",
      "Epoch 2, Loss: 0.011536093726236787\n",
      "Epoch 3, Loss: 0.016073263890575618\n",
      "Epoch 4, Loss: 0.001586051770977469\n",
      "Epoch 5, Loss: 0.0005373597642001523\n",
      "Epoch 6, Loss: 0.00032051649166667766\n",
      "all_preds shape: (196,)\n",
      "all_labels shape: (196,)\n",
      "all_probs shape: (196, 2)\n",
      "Train labels sample: tensor([1, 1, 0, 1, 0]), Shape: torch.Size([864])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([194])\n",
      "##########################DeepPavlov/rubert-base-cased---bert####################\n",
      "Epoch 1, Loss: 0.15876050370193465\n",
      "Epoch 2, Loss: 0.040452311130206066\n",
      "Epoch 3, Loss: 0.010115557591672297\n",
      "Epoch 4, Loss: 0.0009576042012432245\n",
      "Epoch 5, Loss: 0.0005875818217949321\n",
      "Epoch 6, Loss: 0.0004176222832433672\n",
      "all_preds shape: (194,)\n",
      "all_labels shape: (194,)\n",
      "all_probs shape: (194, 2)\n",
      "Train labels sample: tensor([0, 0, 0, 0, 1]), Shape: torch.Size([864])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([201])\n",
      "##########################DeepPavlov/rubert-base-cased---bert####################\n",
      "Epoch 1, Loss: 0.14058764173683744\n",
      "Epoch 2, Loss: 0.020205901713645155\n",
      "Epoch 3, Loss: 0.017476602015516686\n",
      "Epoch 4, Loss: 0.0017910247579156593\n",
      "Epoch 5, Loss: 0.00042671477368222204\n",
      "Epoch 6, Loss: 0.0002754248492204136\n",
      "all_preds shape: (201,)\n",
      "all_labels shape: (201,)\n",
      "all_probs shape: (201, 2)\n",
      "Train labels sample: tensor([0, 1, 1, 0, 0]), Shape: torch.Size([864])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([184])\n",
      "##########################DeepPavlov/rubert-base-cased---bert####################\n",
      "Epoch 1, Loss: 0.13204576351024486\n",
      "Epoch 2, Loss: 0.02109669233646451\n",
      "Epoch 3, Loss: 0.011363467284590352\n",
      "Epoch 4, Loss: 0.0006157503440691573\n",
      "Epoch 5, Loss: 0.00040715309377345775\n",
      "Epoch 6, Loss: 0.0002888521795048965\n",
      "all_preds shape: (184,)\n",
      "all_labels shape: (184,)\n",
      "all_probs shape: (184, 2)\n",
      "train_Изъяты лексемы с частотой выше 49.csv\n",
      "test_Изъяты лексемы с частотой выше 49.csv\n",
      "Train labels sample: tensor([0, 0, 1, 0, 0]), Shape: torch.Size([887])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([177])\n",
      "##########################DeepPavlov/rubert-base-cased---bert####################\n",
      "Epoch 1, Loss: 0.13618561959758932\n",
      "Epoch 2, Loss: 0.087480609371726\n",
      "Epoch 3, Loss: 0.022907055694044436\n",
      "Epoch 4, Loss: 0.0022944630732776466\n",
      "Epoch 5, Loss: 0.01039785625523239\n",
      "Epoch 6, Loss: 0.0010835368094766246\n",
      "all_preds shape: (177,)\n",
      "all_labels shape: (177,)\n",
      "all_probs shape: (177, 2)\n",
      "Train labels sample: tensor([0, 0, 0, 1, 0]), Shape: torch.Size([887])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([200])\n",
      "##########################DeepPavlov/rubert-base-cased---bert####################\n",
      "Epoch 1, Loss: 0.20582675368392042\n",
      "Epoch 2, Loss: 0.04273190572192626\n",
      "Epoch 3, Loss: 0.01600149009651172\n",
      "Epoch 4, Loss: 0.006067612823764128\n",
      "Epoch 5, Loss: 0.0012560179514236683\n",
      "Epoch 6, Loss: 0.00046394497621804476\n",
      "all_preds shape: (200,)\n",
      "all_labels shape: (200,)\n",
      "all_probs shape: (200, 2)\n",
      "Train labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([887])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([196])\n",
      "##########################DeepPavlov/rubert-base-cased---bert####################\n",
      "Epoch 1, Loss: 0.1497363402283684\n",
      "Epoch 2, Loss: 0.011354247658995778\n",
      "Epoch 3, Loss: 0.013319691246059457\n",
      "Epoch 4, Loss: 0.000593547838174605\n",
      "Epoch 5, Loss: 0.000337679357471643\n",
      "Epoch 6, Loss: 0.00025411001167542836\n",
      "all_preds shape: (196,)\n",
      "all_labels shape: (196,)\n",
      "all_probs shape: (196, 2)\n",
      "Train labels sample: tensor([0, 1, 0, 0, 0]), Shape: torch.Size([887])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([182])\n",
      "##########################DeepPavlov/rubert-base-cased---bert####################\n",
      "Epoch 1, Loss: 0.15856735062802077\n",
      "Epoch 2, Loss: 0.044295397691062784\n",
      "Epoch 3, Loss: 0.019818947247196256\n",
      "Epoch 4, Loss: 0.00080862597263019\n",
      "Epoch 5, Loss: 0.00043037991002035724\n",
      "Epoch 6, Loss: 0.00032135307057095427\n",
      "all_preds shape: (182,)\n",
      "all_labels shape: (182,)\n",
      "all_probs shape: (182, 2)\n",
      "Train labels sample: tensor([0, 1, 0, 0, 0]), Shape: torch.Size([887])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([193])\n",
      "##########################DeepPavlov/rubert-base-cased---bert####################\n",
      "Epoch 1, Loss: 0.15940695674258418\n",
      "Epoch 2, Loss: 0.02899508831199325\n",
      "Epoch 3, Loss: 0.005453652401878831\n",
      "Epoch 4, Loss: 0.0005570783136395871\n",
      "Epoch 5, Loss: 0.0003719677032287499\n",
      "Epoch 6, Loss: 0.0002575431088709073\n",
      "all_preds shape: (193,)\n",
      "all_labels shape: (193,)\n",
      "all_probs shape: (193, 2)\n",
      "Train labels sample: tensor([1, 1, 1, 0, 0]), Shape: torch.Size([887])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([186])\n",
      "##########################DeepPavlov/rubert-base-cased---bert####################\n",
      "Epoch 1, Loss: 0.2008195988434766\n",
      "Epoch 2, Loss: 0.03690251460232373\n",
      "Epoch 3, Loss: 0.01806806198978198\n",
      "Epoch 4, Loss: 0.029581359991945128\n",
      "Epoch 5, Loss: 0.03366761984320225\n",
      "Epoch 6, Loss: 0.0031794938866888905\n",
      "all_preds shape: (186,)\n",
      "all_labels shape: (186,)\n",
      "all_probs shape: (186, 2)\n",
      "train_Изъяты лексемы с частотой выше 29.csv\n",
      "test_Изъяты лексемы с частотой выше 29.csv\n",
      "Train labels sample: tensor([0, 1, 1, 0, 0]), Shape: torch.Size([869])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([197])\n",
      "##########################DeepPavlov/rubert-base-cased---bert####################\n",
      "Epoch 1, Loss: 0.2245232596062124\n",
      "Epoch 2, Loss: 0.06873878393830224\n",
      "Epoch 3, Loss: 0.02749434778339822\n",
      "Epoch 4, Loss: 0.007893009525088762\n",
      "Epoch 5, Loss: 0.05302489865147932\n",
      "Epoch 6, Loss: 0.0007898878390816125\n",
      "all_preds shape: (197,)\n",
      "all_labels shape: (197,)\n",
      "all_probs shape: (197, 2)\n",
      "Train labels sample: tensor([0, 1, 0, 0, 1]), Shape: torch.Size([869])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([214])\n",
      "##########################DeepPavlov/rubert-base-cased---bert####################\n",
      "Epoch 1, Loss: 0.19230545427311552\n",
      "Epoch 2, Loss: 0.04294217394834215\n",
      "Epoch 3, Loss: 0.033570259606296365\n",
      "Epoch 4, Loss: 0.0024865580923770637\n",
      "Epoch 5, Loss: 0.0006751164561137557\n",
      "Epoch 6, Loss: 0.0004527896256397732\n",
      "all_preds shape: (214,)\n",
      "all_labels shape: (214,)\n",
      "all_probs shape: (214, 2)\n",
      "Train labels sample: tensor([1, 1, 1, 0, 1]), Shape: torch.Size([869])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([210])\n",
      "##########################DeepPavlov/rubert-base-cased---bert####################\n",
      "Epoch 1, Loss: 0.1690363798629154\n",
      "Epoch 2, Loss: 0.07818735896355726\n",
      "Epoch 3, Loss: 0.0379783480766822\n",
      "Epoch 4, Loss: 0.014554288926195692\n",
      "Epoch 5, Loss: 0.021682569582480937\n",
      "Epoch 6, Loss: 0.031224455318244342\n",
      "all_preds shape: (210,)\n",
      "all_labels shape: (210,)\n",
      "all_probs shape: (210, 2)\n",
      "Train labels sample: tensor([1, 0, 0, 0, 1]), Shape: torch.Size([869])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([211])\n",
      "##########################DeepPavlov/rubert-base-cased---bert####################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.1718068239363757\n",
      "Epoch 2, Loss: 0.05606303099881519\n",
      "Epoch 3, Loss: 0.09510417614682493\n",
      "Epoch 4, Loss: 0.03139557075602087\n",
      "Epoch 5, Loss: 0.005103297860742631\n",
      "Epoch 6, Loss: 0.0011785627766089006\n",
      "all_preds shape: (211,)\n",
      "all_labels shape: (211,)\n",
      "all_probs shape: (211, 2)\n",
      "Train labels sample: tensor([0, 0, 0, 1, 0]), Shape: torch.Size([869])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([209])\n",
      "##########################DeepPavlov/rubert-base-cased---bert####################\n",
      "Epoch 1, Loss: 0.1541359152814204\n",
      "Epoch 2, Loss: 0.02884636555417356\n",
      "Epoch 3, Loss: 0.001839271269273013\n",
      "Epoch 4, Loss: 0.0005720990455963395\n",
      "Epoch 5, Loss: 0.0003710168318568983\n",
      "Epoch 6, Loss: 0.0002762339789610864\n",
      "all_preds shape: (209,)\n",
      "all_labels shape: (209,)\n",
      "all_probs shape: (209, 2)\n",
      "Train labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([869])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([203])\n",
      "##########################DeepPavlov/rubert-base-cased---bert####################\n",
      "Epoch 1, Loss: 0.12265281248837709\n",
      "Epoch 2, Loss: 0.05332850937900895\n",
      "Epoch 3, Loss: 0.021924828265962953\n",
      "Epoch 4, Loss: 0.0020584407812831076\n",
      "Epoch 5, Loss: 0.0005324962437787855\n",
      "Epoch 6, Loss: 0.00035743003933351827\n",
      "all_preds shape: (203,)\n",
      "all_labels shape: (203,)\n",
      "all_probs shape: (203, 2)\n",
      "train_Изъяты лексемы с частотой выше 9.csv\n",
      "test_Изъяты лексемы с частотой выше 9.csv\n",
      "Train labels sample: tensor([1, 1, 0, 0, 0]), Shape: torch.Size([744])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([280])\n",
      "##########################DeepPavlov/rubert-base-cased---bert####################\n",
      "Epoch 1, Loss: 0.24665255014163753\n",
      "Epoch 2, Loss: 0.07593165601914127\n",
      "Epoch 3, Loss: 0.029569739728079487\n",
      "Epoch 4, Loss: 0.00772685438763195\n",
      "all_preds shape: (280,)\n",
      "all_labels shape: (280,)\n",
      "all_probs shape: (280, 2)\n",
      "Train labels sample: tensor([0, 0, 0, 1, 0]), Shape: torch.Size([744])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([273])\n",
      "##########################DeepPavlov/rubert-base-cased---bert####################\n",
      "Epoch 1, Loss: 0.28355495103945333\n",
      "Epoch 2, Loss: 0.05350351306454589\n",
      "Epoch 3, Loss: 0.027025278095000733\n",
      "Epoch 4, Loss: 0.00676347863918636\n",
      "all_preds shape: (273,)\n",
      "all_labels shape: (273,)\n",
      "all_probs shape: (273, 2)\n",
      "Train labels sample: tensor([0, 0, 0, 0, 1]), Shape: torch.Size([744])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([274])\n",
      "##########################DeepPavlov/rubert-base-cased---bert####################\n",
      "Epoch 1, Loss: 0.29467435739934444\n",
      "Epoch 2, Loss: 0.08002672608320911\n",
      "Epoch 3, Loss: 0.03240583357789243\n",
      "Epoch 4, Loss: 0.014164615519500027\n",
      "all_preds shape: (274,)\n",
      "all_labels shape: (274,)\n",
      "all_probs shape: (274, 2)\n",
      "Train labels sample: tensor([0, 0, 1, 1, 1]), Shape: torch.Size([744])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([284])\n",
      "##########################DeepPavlov/rubert-base-cased---bert####################\n",
      "Epoch 1, Loss: 0.3826295019437869\n",
      "Epoch 2, Loss: 0.05821817015142491\n",
      "Epoch 3, Loss: 0.02310430947303151\n",
      "Epoch 4, Loss: 0.015581041943126669\n",
      "all_preds shape: (284,)\n",
      "all_labels shape: (284,)\n",
      "all_probs shape: (284, 2)\n",
      "Train labels sample: tensor([1, 0, 1, 0, 1]), Shape: torch.Size([744])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([348])\n",
      "##########################DeepPavlov/rubert-base-cased---bert####################\n",
      "Epoch 1, Loss: 0.3818984301760793\n",
      "Epoch 2, Loss: 0.05873050300093988\n",
      "Epoch 3, Loss: 0.018203438075336937\n",
      "Epoch 4, Loss: 0.003247337619541213\n",
      "all_preds shape: (348,)\n",
      "all_labels shape: (348,)\n",
      "all_probs shape: (348, 2)\n",
      "Train labels sample: tensor([0, 1, 1, 0, 0]), Shape: torch.Size([744])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([275])\n",
      "##########################DeepPavlov/rubert-base-cased---bert####################\n",
      "Epoch 1, Loss: 0.2653373139134298\n",
      "Epoch 2, Loss: 0.05913136616194\n",
      "Epoch 3, Loss: 0.009671811528581506\n",
      "Epoch 4, Loss: 0.0026994246824566894\n",
      "all_preds shape: (275,)\n",
      "all_labels shape: (275,)\n",
      "all_probs shape: (275, 2)\n",
      "train_Изъяты лексемы с частотой выше 5.csv\n",
      "test_Изъяты лексемы с частотой выше 5.csv\n",
      "Train labels sample: tensor([0, 0, 1, 0, 0]), Shape: torch.Size([96])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([527])\n",
      "##########################DeepPavlov/rubert-base-cased---bert####################\n",
      "Epoch 1, Loss: 0.54155965646108\n",
      "Epoch 2, Loss: 0.22772624840339026\n",
      "Epoch 3, Loss: 0.06611466935525338\n",
      "Epoch 4, Loss: 0.1403055676879982\n",
      "Epoch 5, Loss: 0.008874127874150872\n",
      "Epoch 6, Loss: 0.01119077488935242\n",
      "all_preds shape: (527,)\n",
      "all_labels shape: (527,)\n",
      "all_probs shape: (527, 2)\n",
      "Train labels sample: tensor([1, 0, 0, 1, 1]), Shape: torch.Size([96])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([507])\n",
      "##########################DeepPavlov/rubert-base-cased---bert####################\n",
      "Epoch 1, Loss: 0.44768499583005905\n",
      "Epoch 2, Loss: 0.09961498032013576\n",
      "Epoch 3, Loss: 0.012270476281022033\n",
      "Epoch 4, Loss: 0.004082540632225573\n",
      "Epoch 5, Loss: 0.0023507636700135968\n",
      "Epoch 6, Loss: 0.0014336163876578212\n",
      "all_preds shape: (507,)\n",
      "all_labels shape: (507,)\n",
      "all_probs shape: (507, 2)\n",
      "Train labels sample: tensor([0, 0, 0, 1, 1]), Shape: torch.Size([96])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([513])\n",
      "##########################DeepPavlov/rubert-base-cased---bert####################\n",
      "Epoch 1, Loss: 0.5207257519165674\n",
      "Epoch 2, Loss: 0.251959631840388\n",
      "Epoch 3, Loss: 0.047824097176392875\n",
      "Epoch 4, Loss: 0.006929278994599978\n",
      "Epoch 5, Loss: 0.0030041156569495797\n",
      "Epoch 6, Loss: 0.0017451734165661037\n",
      "all_preds shape: (513,)\n",
      "all_labels shape: (513,)\n",
      "all_probs shape: (513, 2)\n",
      "Train labels sample: tensor([0, 0, 0, 1, 0]), Shape: torch.Size([96])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([575])\n",
      "##########################DeepPavlov/rubert-base-cased---bert####################\n",
      "Epoch 1, Loss: 0.5258675515651703\n",
      "Epoch 2, Loss: 0.20441949864228567\n",
      "Epoch 3, Loss: 0.06676228406528632\n",
      "Epoch 4, Loss: 0.01052920698809127\n",
      "Epoch 5, Loss: 0.004754696235371132\n",
      "Epoch 6, Loss: 0.002772282731408874\n",
      "all_preds shape: (575,)\n",
      "all_labels shape: (575,)\n",
      "all_probs shape: (575, 2)\n",
      "Train labels sample: tensor([0, 0, 0, 0, 1]), Shape: torch.Size([96])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([491])\n",
      "##########################DeepPavlov/rubert-base-cased---bert####################\n",
      "Epoch 1, Loss: 0.417276531457901\n",
      "Epoch 2, Loss: 0.15074557128051916\n",
      "Epoch 3, Loss: 0.05641024000942707\n",
      "Epoch 4, Loss: 0.01384721634288629\n",
      "Epoch 5, Loss: 0.047946695781623326\n",
      "Epoch 6, Loss: 0.005234801637319227\n",
      "all_preds shape: (491,)\n",
      "all_labels shape: (491,)\n",
      "all_probs shape: (491, 2)\n",
      "Train labels sample: tensor([0, 0, 0, 1, 0]), Shape: torch.Size([96])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([456])\n",
      "##########################DeepPavlov/rubert-base-cased---bert####################\n",
      "Epoch 1, Loss: 0.41938742250204086\n",
      "Epoch 2, Loss: 0.08174043303976457\n",
      "Epoch 3, Loss: 0.02266792650334537\n",
      "Epoch 4, Loss: 0.0503817416417102\n",
      "Epoch 5, Loss: 0.004491712005498509\n",
      "Epoch 6, Loss: 0.0026556331431493163\n",
      "all_preds shape: (456,)\n",
      "all_labels shape: (456,)\n",
      "all_probs shape: (456, 2)\n",
      "train_Изъяты лексемы с частотой выше 3.csv\n",
      "test_Изъяты лексемы с частотой выше 3.csv\n",
      "Train labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([90])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([700])\n",
      "##########################DeepPavlov/rubert-base-cased---bert####################\n",
      "Epoch 1, Loss: 0.49998505413532257\n",
      "Epoch 2, Loss: 0.15077813590566316\n",
      "Epoch 3, Loss: 0.03659668378531933\n",
      "Epoch 4, Loss: 0.008898871097092828\n",
      "Epoch 5, Loss: 0.004843588258760671\n",
      "Epoch 6, Loss: 0.002335670384733627\n",
      "all_preds shape: (700,)\n",
      "all_labels shape: (700,)\n",
      "all_probs shape: (700, 2)\n",
      "Train labels sample: tensor([0, 1, 0, 0, 0]), Shape: torch.Size([90])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([732])\n",
      "##########################DeepPavlov/rubert-base-cased---bert####################\n",
      "Epoch 1, Loss: 0.4471399436394374\n",
      "Epoch 2, Loss: 0.1750218110779921\n",
      "Epoch 3, Loss: 0.03139512334018946\n",
      "Epoch 4, Loss: 0.005236769987580677\n",
      "Epoch 5, Loss: 0.0020014044906323156\n",
      "Epoch 6, Loss: 0.001207595089605699\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_preds shape: (732,)\n",
      "all_labels shape: (732,)\n",
      "all_probs shape: (732, 2)\n",
      "Train labels sample: tensor([1, 1, 0, 0, 0]), Shape: torch.Size([90])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([739])\n",
      "##########################DeepPavlov/rubert-base-cased---bert####################\n",
      "Epoch 1, Loss: 0.5174157619476318\n",
      "Epoch 2, Loss: 0.1163807703802983\n",
      "Epoch 3, Loss: 0.017386416904628277\n",
      "Epoch 4, Loss: 0.004886568562748532\n",
      "Epoch 5, Loss: 0.0021773793074923256\n",
      "Epoch 6, Loss: 0.0014313068822957575\n",
      "all_preds shape: (739,)\n",
      "all_labels shape: (739,)\n",
      "all_probs shape: (739, 2)\n",
      "Train labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([90])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([718])\n",
      "##########################DeepPavlov/rubert-base-cased---bert####################\n",
      "Epoch 1, Loss: 0.482797568043073\n",
      "Epoch 2, Loss: 0.16951334600647291\n",
      "Epoch 3, Loss: 0.06808806800593932\n",
      "Epoch 4, Loss: 0.027984825273354847\n",
      "Epoch 5, Loss: 0.005579931118215124\n",
      "Epoch 6, Loss: 0.0028461641243969402\n",
      "all_preds shape: (718,)\n",
      "all_labels shape: (718,)\n",
      "all_probs shape: (718, 2)\n",
      "Train labels sample: tensor([0, 0, 1, 0, 0]), Shape: torch.Size([90])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([715])\n",
      "##########################DeepPavlov/rubert-base-cased---bert####################\n",
      "Epoch 1, Loss: 0.5347103377183279\n",
      "Epoch 2, Loss: 0.20085821797450384\n",
      "Epoch 3, Loss: 0.034790968211988606\n",
      "Epoch 4, Loss: 0.007065462103734414\n",
      "Epoch 5, Loss: 0.003566268327025076\n",
      "Epoch 6, Loss: 0.0020808035042136908\n",
      "all_preds shape: (715,)\n",
      "all_labels shape: (715,)\n",
      "all_probs shape: (715, 2)\n",
      "Train labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([90])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([690])\n",
      "##########################DeepPavlov/rubert-base-cased---bert####################\n",
      "Epoch 1, Loss: 0.5870971282323202\n",
      "Epoch 2, Loss: 0.3109488785266876\n",
      "Epoch 3, Loss: 0.086906631787618\n",
      "Epoch 4, Loss: 0.023445135913789272\n",
      "Epoch 5, Loss: 0.008584543208902081\n",
      "Epoch 6, Loss: 0.0042102471537267165\n",
      "all_preds shape: (690,)\n",
      "all_labels shape: (690,)\n",
      "all_probs shape: (690, 2)\n",
      "train_Без прилагательных первый-второй жанр.csv\n",
      "test_Без прилагательных первый-второй жанр.csv\n",
      "Train labels sample: tensor([0, 1, 0, 1, 1]), Shape: torch.Size([828])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([210])\n",
      "##########################DeepPavlov/rubert-base-cased---bert####################\n",
      "Epoch 1, Loss: 0.26191451461412585\n",
      "Epoch 2, Loss: 0.018277013656468347\n",
      "Epoch 3, Loss: 0.005245018177307569\n",
      "Epoch 4, Loss: 0.0016116460409158696\n",
      "all_preds shape: (210,)\n",
      "all_labels shape: (210,)\n",
      "all_probs shape: (210, 2)\n",
      "Train labels sample: tensor([1, 1, 0, 1, 0]), Shape: torch.Size([828])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([196])\n",
      "##########################DeepPavlov/rubert-base-cased---bert####################\n",
      "Epoch 1, Loss: 0.1992589275782498\n",
      "Epoch 2, Loss: 0.08601128972636965\n",
      "Epoch 3, Loss: 0.04370960073832136\n",
      "Epoch 4, Loss: 0.014598485377903741\n",
      "all_preds shape: (196,)\n",
      "all_labels shape: (196,)\n",
      "all_probs shape: (196, 2)\n",
      "Train labels sample: tensor([0, 1, 0, 1, 0]), Shape: torch.Size([828])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([192])\n",
      "##########################DeepPavlov/rubert-base-cased---bert####################\n",
      "Epoch 1, Loss: 0.2377301029717693\n",
      "Epoch 2, Loss: 0.05730683635920286\n",
      "Epoch 3, Loss: 0.013437092151994316\n",
      "Epoch 4, Loss: 0.004151181196973015\n",
      "all_preds shape: (192,)\n",
      "all_labels shape: (192,)\n",
      "all_probs shape: (192, 2)\n",
      "Train labels sample: tensor([1, 1, 1, 0, 1]), Shape: torch.Size([828])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([178])\n",
      "##########################DeepPavlov/rubert-base-cased---bert####################\n",
      "Epoch 1, Loss: 0.3363398958284121\n",
      "Epoch 2, Loss: 0.048109317950617805\n",
      "Epoch 3, Loss: 0.0064654049929231405\n",
      "Epoch 4, Loss: 0.001709449673608805\n",
      "all_preds shape: (178,)\n",
      "all_labels shape: (178,)\n",
      "all_probs shape: (178, 2)\n",
      "Train labels sample: tensor([0, 0, 1, 1, 0]), Shape: torch.Size([828])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([191])\n",
      "##########################DeepPavlov/rubert-base-cased---bert####################\n",
      "Epoch 1, Loss: 0.20854922181640106\n",
      "Epoch 2, Loss: 0.03489810137006526\n",
      "Epoch 3, Loss: 0.020718225752576612\n",
      "Epoch 4, Loss: 0.0022003080543632116\n",
      "all_preds shape: (191,)\n",
      "all_labels shape: (191,)\n",
      "all_probs shape: (191, 2)\n",
      "Train labels sample: tensor([0, 1, 1, 1, 1]), Shape: torch.Size([828])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([196])\n",
      "##########################DeepPavlov/rubert-base-cased---bert####################\n",
      "Epoch 1, Loss: 0.18820726269712815\n",
      "Epoch 2, Loss: 0.040035076869221836\n",
      "Epoch 3, Loss: 0.014211453309354301\n",
      "Epoch 4, Loss: 0.0020460124808148695\n",
      "all_preds shape: (196,)\n",
      "all_labels shape: (196,)\n",
      "all_probs shape: (196, 2)\n",
      "train_1.Первый жанр исходная выборка.csv\n",
      "test_1.Первый жанр исходная выборка.csv\n",
      "Train labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([888])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([175])\n",
      "##########################DeepPavlov/rubert-base-cased---bert####################\n",
      "Epoch 1, Loss: 0.12196030784148856\n",
      "Epoch 2, Loss: 0.013635186667670496\n",
      "Epoch 3, Loss: 0.0006894292257909131\n",
      "Epoch 4, Loss: 0.00042908246541628614\n",
      "Epoch 5, Loss: 0.00030926845179887356\n",
      "Epoch 6, Loss: 0.00023823510309739504\n",
      "all_preds shape: (175,)\n",
      "all_labels shape: (175,)\n",
      "all_probs shape: (175, 2)\n",
      "Train labels sample: tensor([0, 0, 0, 1, 1]), Shape: torch.Size([888])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([166])\n",
      "##########################DeepPavlov/rubert-base-cased---bert####################\n",
      "Epoch 1, Loss: 0.16223356111108192\n",
      "Epoch 2, Loss: 0.0075568778400858195\n",
      "Epoch 3, Loss: 0.0005752081514011868\n",
      "Epoch 4, Loss: 0.00036142049378083484\n",
      "Epoch 5, Loss: 0.00025081737190443424\n",
      "Epoch 6, Loss: 0.00019661381858376053\n",
      "all_preds shape: (166,)\n",
      "all_labels shape: (166,)\n",
      "all_probs shape: (166, 2)\n",
      "Train labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([888])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([165])\n",
      "##########################DeepPavlov/rubert-base-cased---bert####################\n",
      "Epoch 1, Loss: 0.13067138422879257\n",
      "Epoch 2, Loss: 0.024972776410452622\n",
      "Epoch 3, Loss: 0.0458560041068787\n",
      "Epoch 4, Loss: 0.0150663124035678\n",
      "Epoch 5, Loss: 0.0007397581149624395\n",
      "Epoch 6, Loss: 0.002417736854632884\n",
      "all_preds shape: (165,)\n",
      "all_labels shape: (165,)\n",
      "all_probs shape: (165, 2)\n",
      "Train labels sample: tensor([1, 0, 1, 0, 0]), Shape: torch.Size([888])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([165])\n",
      "##########################DeepPavlov/rubert-base-cased---bert####################\n",
      "Epoch 1, Loss: 0.12803605831660597\n",
      "Epoch 2, Loss: 0.015981876844307408\n",
      "Epoch 3, Loss: 0.010734975288089896\n",
      "Epoch 4, Loss: 0.01060758478083049\n",
      "Epoch 5, Loss: 0.0004792941914014851\n",
      "Epoch 6, Loss: 0.0003173121539085904\n",
      "all_preds shape: (165,)\n",
      "all_labels shape: (165,)\n",
      "all_probs shape: (165, 2)\n",
      "Train labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([888])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([165])\n",
      "##########################DeepPavlov/rubert-base-cased---bert####################\n",
      "Epoch 1, Loss: 0.15095829394080543\n",
      "Epoch 2, Loss: 0.016913884724739807\n",
      "Epoch 3, Loss: 0.0466286754776125\n",
      "Epoch 4, Loss: 0.008977118516798197\n",
      "Epoch 5, Loss: 0.0007234193310848371\n",
      "Epoch 6, Loss: 0.0004218341153838472\n",
      "all_preds shape: (165,)\n",
      "all_labels shape: (165,)\n",
      "all_probs shape: (165, 2)\n",
      "Train labels sample: tensor([0, 1, 1, 0, 1]), Shape: torch.Size([888])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([161])\n",
      "##########################DeepPavlov/rubert-base-cased---bert####################\n",
      "Epoch 1, Loss: 0.16552418413838105\n",
      "Epoch 2, Loss: 0.045239841332659125\n",
      "Epoch 3, Loss: 0.020561530820227096\n",
      "Epoch 4, Loss: 0.010290668753441423\n",
      "Epoch 5, Loss: 0.0008289874588496916\n",
      "Epoch 6, Loss: 0.06377346924896951\n",
      "all_preds shape: (161,)\n",
      "all_labels shape: (161,)\n",
      "all_probs shape: (161, 2)\n",
      "train_2.Первый жанр без клауз, включающих наречия.csv\n",
      "test_2.Первый жанр без клауз, включающих наречия.csv\n",
      "Train labels sample: tensor([0, 0, 1, 0, 0]), Shape: torch.Size([876])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([174])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##########################DeepPavlov/rubert-base-cased---bert####################\n",
      "Epoch 1, Loss: 0.11084152314473282\n",
      "Epoch 2, Loss: 0.022410310739227994\n",
      "Epoch 3, Loss: 0.04867012955841016\n",
      "Epoch 4, Loss: 0.056985179262913084\n",
      "Epoch 5, Loss: 0.03266947713511234\n",
      "Epoch 6, Loss: 0.01883034180765125\n",
      "all_preds shape: (174,)\n",
      "all_labels shape: (174,)\n",
      "all_probs shape: (174, 2)\n",
      "Train labels sample: tensor([0, 0, 0, 0, 1]), Shape: torch.Size([876])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([170])\n",
      "##########################DeepPavlov/rubert-base-cased---bert####################\n",
      "Epoch 1, Loss: 0.14496760451319543\n",
      "Epoch 2, Loss: 0.10191575576635924\n",
      "Epoch 3, Loss: 0.025852628183466467\n",
      "Epoch 4, Loss: 0.00232385948871855\n",
      "Epoch 5, Loss: 0.0008716870956546204\n",
      "Epoch 6, Loss: 0.0005625518319323997\n",
      "all_preds shape: (170,)\n",
      "all_labels shape: (170,)\n",
      "all_probs shape: (170, 2)\n",
      "Train labels sample: tensor([0, 0, 0, 1, 0]), Shape: torch.Size([876])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([172])\n",
      "##########################DeepPavlov/rubert-base-cased---bert####################\n",
      "Epoch 1, Loss: 0.10826515311121264\n",
      "Epoch 2, Loss: 0.011178263792217794\n",
      "Epoch 3, Loss: 0.08062369612214917\n",
      "Epoch 4, Loss: 0.03714756640520963\n",
      "Epoch 5, Loss: 0.02846854468595914\n",
      "Epoch 6, Loss: 0.0034177818113345316\n",
      "all_preds shape: (172,)\n",
      "all_labels shape: (172,)\n",
      "all_probs shape: (172, 2)\n",
      "Train labels sample: tensor([0, 0, 0, 1, 0]), Shape: torch.Size([876])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([163])\n",
      "##########################DeepPavlov/rubert-base-cased---bert####################\n",
      "Epoch 1, Loss: 0.11875910133292729\n",
      "Epoch 2, Loss: 0.023960645958273248\n",
      "Epoch 3, Loss: 0.002868460815145888\n",
      "Epoch 4, Loss: 0.017771879052319986\n",
      "Epoch 5, Loss: 0.03239733147519556\n",
      "Epoch 6, Loss: 0.08982946824240075\n",
      "all_preds shape: (163,)\n",
      "all_labels shape: (163,)\n",
      "all_probs shape: (163, 2)\n",
      "Train labels sample: tensor([1, 0, 1, 0, 1]), Shape: torch.Size([876])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([175])\n",
      "##########################DeepPavlov/rubert-base-cased---bert####################\n",
      "Epoch 1, Loss: 0.12432579301636328\n",
      "Epoch 2, Loss: 0.021706061099063267\n",
      "Epoch 3, Loss: 0.001139013953930275\n",
      "Epoch 4, Loss: 0.0005550960068252276\n",
      "Epoch 5, Loss: 0.00035523879235949027\n",
      "Epoch 6, Loss: 0.0002656715715685013\n",
      "all_preds shape: (175,)\n",
      "all_labels shape: (175,)\n",
      "all_probs shape: (175, 2)\n",
      "Train labels sample: tensor([0, 1, 1, 1, 0]), Shape: torch.Size([876])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([165])\n",
      "##########################DeepPavlov/rubert-base-cased---bert####################\n",
      "Epoch 1, Loss: 0.14619496114001693\n",
      "Epoch 2, Loss: 0.044914099815386264\n",
      "Epoch 3, Loss: 0.01555108273274858\n",
      "Epoch 4, Loss: 0.019708419679029084\n",
      "Epoch 5, Loss: 0.001115224301412871\n",
      "Epoch 6, Loss: 0.000349183589622209\n",
      "all_preds shape: (165,)\n",
      "all_labels shape: (165,)\n",
      "all_probs shape: (165, 2)\n",
      "train_3.Первый жанр без клауз, включающих глаголы.csv\n",
      "test_3.Первый жанр без клауз, включающих глаголы.csv\n",
      "Train labels sample: tensor([0, 0, 0, 0, 1]), Shape: torch.Size([820])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([222])\n",
      "##########################DeepPavlov/rubert-base-cased---bert####################\n",
      "Epoch 1, Loss: 0.15830588183150843\n",
      "Epoch 2, Loss: 0.05000719703877202\n",
      "Epoch 3, Loss: 0.012526162206016194\n",
      "Epoch 4, Loss: 0.0008434608249584786\n",
      "Epoch 5, Loss: 0.0005041419790359214\n",
      "Epoch 6, Loss: 0.00035721584796332393\n",
      "all_preds shape: (222,)\n",
      "all_labels shape: (222,)\n",
      "all_probs shape: (222, 2)\n",
      "Train labels sample: tensor([1, 0, 1, 1, 1]), Shape: torch.Size([820])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([216])\n",
      "##########################DeepPavlov/rubert-base-cased---bert####################\n",
      "Epoch 1, Loss: 0.1187322282169659\n",
      "Epoch 2, Loss: 0.02351047471165657\n",
      "Epoch 3, Loss: 0.001207788447992733\n",
      "Epoch 4, Loss: 0.0005864848667093051\n",
      "Epoch 5, Loss: 0.0003970695117739244\n",
      "Epoch 6, Loss: 0.0002922766042712073\n",
      "all_preds shape: (216,)\n",
      "all_labels shape: (216,)\n",
      "all_probs shape: (216, 2)\n",
      "Train labels sample: tensor([0, 0, 0, 1, 1]), Shape: torch.Size([820])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([212])\n",
      "##########################DeepPavlov/rubert-base-cased---bert####################\n",
      "Epoch 1, Loss: 0.2030552189456872\n",
      "Epoch 2, Loss: 0.029005487753938023\n",
      "Epoch 3, Loss: 0.0024087272826223993\n",
      "Epoch 4, Loss: 0.0008953358785500034\n",
      "Epoch 5, Loss: 0.0005603411974824177\n",
      "Epoch 6, Loss: 0.001574937016882289\n",
      "all_preds shape: (212,)\n",
      "all_labels shape: (212,)\n",
      "all_probs shape: (212, 2)\n",
      "Train labels sample: tensor([0, 0, 0, 1, 0]), Shape: torch.Size([820])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([213])\n",
      "##########################DeepPavlov/rubert-base-cased---bert####################\n",
      "Epoch 1, Loss: 0.1715181886505049\n",
      "Epoch 2, Loss: 0.0743032801681413\n",
      "Epoch 3, Loss: 0.0029104679661731306\n",
      "Epoch 4, Loss: 0.005902087586806514\n",
      "Epoch 5, Loss: 0.04934799869582863\n",
      "Epoch 6, Loss: 0.027944832731289074\n",
      "all_preds shape: (213,)\n",
      "all_labels shape: (213,)\n",
      "all_probs shape: (213, 2)\n",
      "Train labels sample: tensor([1, 1, 0, 0, 1]), Shape: torch.Size([820])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([207])\n",
      "##########################DeepPavlov/rubert-base-cased---bert####################\n",
      "Epoch 1, Loss: 0.18627870087332737\n",
      "Epoch 2, Loss: 0.03663805350571728\n",
      "Epoch 3, Loss: 0.002524705160445032\n",
      "Epoch 4, Loss: 0.0008779498267148694\n",
      "Epoch 5, Loss: 0.0005760519975760522\n",
      "Epoch 6, Loss: 0.00042478806818298134\n",
      "all_preds shape: (207,)\n",
      "all_labels shape: (207,)\n",
      "all_probs shape: (207, 2)\n",
      "Train labels sample: tensor([0, 1, 0, 0, 0]), Shape: torch.Size([820])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([222])\n",
      "##########################DeepPavlov/rubert-base-cased---bert####################\n",
      "Epoch 1, Loss: 0.16051167761906981\n",
      "Epoch 2, Loss: 0.02807084693743561\n",
      "Epoch 3, Loss: 0.036336246251056976\n",
      "Epoch 4, Loss: 0.015386930465375861\n",
      "Epoch 5, Loss: 0.0010645037898659492\n",
      "Epoch 6, Loss: 0.0004698739363588035\n",
      "all_preds shape: (222,)\n",
      "all_labels shape: (222,)\n",
      "all_probs shape: (222, 2)\n",
      "train_4.Первый жанр без клауз, включающих глаголы и наречия.csv\n",
      "test_4.Первый жанр без клауз, включающих глаголы и наречия.csv\n",
      "Train labels sample: tensor([1, 0, 0, 1, 1]), Shape: torch.Size([800])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([237])\n",
      "##########################DeepPavlov/rubert-base-cased---bert####################\n",
      "Epoch 1, Loss: 0.09333269025199115\n",
      "Epoch 2, Loss: 0.101826693310868\n",
      "Epoch 3, Loss: 0.056321351286023856\n",
      "Epoch 4, Loss: 0.0024534378689713776\n",
      "Epoch 5, Loss: 0.0008697496715467423\n",
      "Epoch 6, Loss: 0.000570016946294345\n",
      "all_preds shape: (237,)\n",
      "all_labels shape: (237,)\n",
      "all_probs shape: (237, 2)\n",
      "Train labels sample: tensor([0, 1, 1, 0, 0]), Shape: torch.Size([800])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([236])\n",
      "##########################DeepPavlov/rubert-base-cased---bert####################\n",
      "Epoch 1, Loss: 0.14791001744568347\n",
      "Epoch 2, Loss: 0.003353034510510042\n",
      "Epoch 3, Loss: 0.01738383537856862\n",
      "Epoch 4, Loss: 0.044512228833045814\n",
      "Epoch 5, Loss: 0.03510536250658333\n",
      "Epoch 6, Loss: 0.0077803811035119\n",
      "all_preds shape: (236,)\n",
      "all_labels shape: (236,)\n",
      "all_probs shape: (236, 2)\n",
      "Train labels sample: tensor([0, 1, 1, 1, 0]), Shape: torch.Size([800])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([232])\n",
      "##########################DeepPavlov/rubert-base-cased---bert####################\n",
      "Epoch 1, Loss: 0.12728472774848343\n",
      "Epoch 2, Loss: 0.029414938502013682\n",
      "Epoch 3, Loss: 0.015385334056336433\n",
      "Epoch 4, Loss: 0.01678056920878589\n",
      "Epoch 5, Loss: 0.01598584622493945\n",
      "Epoch 6, Loss: 0.0007769729703431949\n",
      "all_preds shape: (232,)\n",
      "all_labels shape: (232,)\n",
      "all_probs shape: (232, 2)\n",
      "Train labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([800])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([231])\n",
      "##########################DeepPavlov/rubert-base-cased---bert####################\n",
      "Epoch 1, Loss: 0.15297315675765277\n",
      "Epoch 2, Loss: 0.06383793843444437\n",
      "Epoch 3, Loss: 0.013173305345699191\n",
      "Epoch 4, Loss: 0.010834946956019848\n",
      "Epoch 5, Loss: 0.0012149086280260236\n",
      "Epoch 6, Loss: 0.000587653312832117\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_preds shape: (231,)\n",
      "all_labels shape: (231,)\n",
      "all_probs shape: (231, 2)\n",
      "Train labels sample: tensor([1, 0, 1, 0, 0]), Shape: torch.Size([800])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([233])\n",
      "##########################DeepPavlov/rubert-base-cased---bert####################\n",
      "Epoch 1, Loss: 0.12751872115768492\n",
      "Epoch 2, Loss: 0.09077453228179365\n",
      "Epoch 3, Loss: 0.02247495409566909\n",
      "Epoch 4, Loss: 0.01459334380691871\n",
      "Epoch 5, Loss: 0.0008715035184286534\n",
      "Epoch 6, Loss: 0.0005545472347876057\n",
      "all_preds shape: (233,)\n",
      "all_labels shape: (233,)\n",
      "all_probs shape: (233, 2)\n",
      "Train labels sample: tensor([0, 1, 1, 1, 1]), Shape: torch.Size([800])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([231])\n",
      "##########################DeepPavlov/rubert-base-cased---bert####################\n",
      "Epoch 1, Loss: 0.13588998161256313\n",
      "Epoch 2, Loss: 0.038162592332810163\n",
      "Epoch 3, Loss: 0.008936250265687704\n",
      "Epoch 4, Loss: 0.0008418009500019252\n",
      "Epoch 5, Loss: 0.0005040671402821317\n",
      "Epoch 6, Loss: 0.0003369171189842746\n",
      "all_preds shape: (231,)\n",
      "all_labels shape: (231,)\n",
      "all_probs shape: (231, 2)\n",
      "train_5.без клауз, включающих местоимения.txt.csv\n",
      "test_5.без клауз, включающих местоимения.txt.csv\n",
      "Train labels sample: tensor([0, 1, 1, 1, 1]), Shape: torch.Size([853])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([189])\n",
      "##########################DeepPavlov/rubert-base-cased---bert####################\n",
      "Epoch 1, Loss: 0.16847050080455286\n",
      "Epoch 2, Loss: 0.027498409126160875\n",
      "Epoch 3, Loss: 0.013934743334108067\n",
      "Epoch 4, Loss: 0.014836886582930607\n",
      "Epoch 5, Loss: 0.0010032288038120088\n",
      "Epoch 6, Loss: 0.0003674217867363175\n",
      "all_preds shape: (189,)\n",
      "all_labels shape: (189,)\n",
      "all_probs shape: (189, 2)\n",
      "Train labels sample: tensor([0, 0, 1, 1, 0]), Shape: torch.Size([853])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([183])\n",
      "##########################DeepPavlov/rubert-base-cased---bert####################\n",
      "Epoch 1, Loss: 0.17147905138079766\n",
      "Epoch 2, Loss: 0.02745044303850995\n",
      "Epoch 3, Loss: 0.013861146061336276\n",
      "Epoch 4, Loss: 0.009274965055131664\n",
      "Epoch 5, Loss: 0.007760998596764963\n",
      "Epoch 6, Loss: 0.000771020522397184\n",
      "all_preds shape: (183,)\n",
      "all_labels shape: (183,)\n",
      "all_probs shape: (183, 2)\n",
      "Train labels sample: tensor([0, 1, 0, 0, 0]), Shape: torch.Size([853])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([192])\n",
      "##########################DeepPavlov/rubert-base-cased---bert####################\n",
      "Epoch 1, Loss: 0.13746727680511497\n",
      "Epoch 2, Loss: 0.028396788553369266\n",
      "Epoch 3, Loss: 0.0205493018169094\n",
      "Epoch 4, Loss: 0.0007298832502716255\n",
      "Epoch 5, Loss: 0.0004293744514817027\n",
      "Epoch 6, Loss: 0.00030846012830604904\n",
      "all_preds shape: (192,)\n",
      "all_labels shape: (192,)\n",
      "all_probs shape: (192, 2)\n",
      "Train labels sample: tensor([0, 0, 0, 1, 0]), Shape: torch.Size([853])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([185])\n",
      "##########################DeepPavlov/rubert-base-cased---bert####################\n",
      "Epoch 1, Loss: 0.13218227434144528\n",
      "Epoch 2, Loss: 0.020136113360489684\n",
      "Epoch 3, Loss: 0.009622373531951948\n",
      "Epoch 4, Loss: 0.0018537135280591126\n",
      "Epoch 5, Loss: 0.0005589717238089415\n",
      "Epoch 6, Loss: 0.0002925318878152649\n",
      "all_preds shape: (185,)\n",
      "all_labels shape: (185,)\n",
      "all_probs shape: (185, 2)\n",
      "Train labels sample: tensor([0, 1, 0, 1, 0]), Shape: torch.Size([853])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([190])\n",
      "##########################DeepPavlov/rubert-base-cased---bert####################\n",
      "Epoch 1, Loss: 0.1556299490750664\n",
      "Epoch 2, Loss: 0.03258790147783994\n",
      "Epoch 3, Loss: 0.02582414792333212\n",
      "Epoch 4, Loss: 0.0009127063558143736\n",
      "Epoch 5, Loss: 0.0004188839402222247\n",
      "Epoch 6, Loss: 0.0002848728003704713\n",
      "all_preds shape: (190,)\n",
      "all_labels shape: (190,)\n",
      "all_probs shape: (190, 2)\n",
      "Train labels sample: tensor([0, 0, 1, 0, 0]), Shape: torch.Size([853])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([188])\n",
      "##########################DeepPavlov/rubert-base-cased---bert####################\n",
      "Epoch 1, Loss: 0.09995033068116754\n",
      "Epoch 2, Loss: 0.031053262215142173\n",
      "Epoch 3, Loss: 0.0021626841324312546\n",
      "Epoch 4, Loss: 0.0005124265881022438\n",
      "Epoch 5, Loss: 0.0003112748678109643\n",
      "Epoch 6, Loss: 0.00022388989438897825\n",
      "all_preds shape: (188,)\n",
      "all_labels shape: (188,)\n",
      "all_probs shape: (188, 2)\n",
      "train_6.без слов функциональных.txt.csv\n",
      "test_6.без слов функциональных.txt.csv\n",
      "Train labels sample: tensor([0, 1, 1, 1, 0]), Shape: torch.Size([916])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([187])\n",
      "##########################DeepPavlov/rubert-base-cased---bert####################\n",
      "Epoch 1, Loss: 0.16581102245053725\n",
      "Epoch 2, Loss: 0.008428783063648334\n",
      "Epoch 3, Loss: 0.0007114965405419533\n",
      "Epoch 4, Loss: 0.0004255752839902737\n",
      "Epoch 5, Loss: 0.0002967011485076188\n",
      "Epoch 6, Loss: 0.0002210060230371992\n",
      "all_preds shape: (187,)\n",
      "all_labels shape: (187,)\n",
      "all_probs shape: (187, 2)\n",
      "Train labels sample: tensor([0, 1, 0, 0, 0]), Shape: torch.Size([916])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([183])\n",
      "##########################DeepPavlov/rubert-base-cased---bert####################\n",
      "Epoch 1, Loss: 0.22763372659040937\n",
      "Epoch 2, Loss: 0.013875880118074089\n",
      "Epoch 3, Loss: 0.0035502745816082663\n",
      "Epoch 4, Loss: 0.0005888220621272922\n",
      "Epoch 5, Loss: 0.04135252960811064\n",
      "Epoch 6, Loss: 0.041340145999003715\n",
      "all_preds shape: (183,)\n",
      "all_labels shape: (183,)\n",
      "all_probs shape: (183, 2)\n",
      "Train labels sample: tensor([0, 0, 0, 1, 1]), Shape: torch.Size([916])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([172])\n",
      "##########################DeepPavlov/rubert-base-cased---bert####################\n",
      "Epoch 1, Loss: 0.13986017987340818\n",
      "Epoch 2, Loss: 0.041484500167104574\n",
      "Epoch 3, Loss: 0.010902075592733535\n",
      "Epoch 4, Loss: 0.023790235232746485\n",
      "Epoch 5, Loss: 0.006949236735918334\n",
      "Epoch 6, Loss: 0.01741926085478867\n",
      "all_preds shape: (172,)\n",
      "all_labels shape: (172,)\n",
      "all_probs shape: (172, 2)\n",
      "Train labels sample: tensor([0, 1, 0, 0, 1]), Shape: torch.Size([916])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([174])\n",
      "##########################DeepPavlov/rubert-base-cased---bert####################\n",
      "Epoch 1, Loss: 0.22937495734317806\n",
      "Epoch 2, Loss: 0.11198067389717646\n",
      "Epoch 3, Loss: 0.047167181619443\n",
      "Epoch 4, Loss: 0.02852674735236335\n",
      "Epoch 5, Loss: 0.010469840863591125\n",
      "Epoch 6, Loss: 0.008719393591083393\n",
      "all_preds shape: (174,)\n",
      "all_labels shape: (174,)\n",
      "all_probs shape: (174, 2)\n",
      "Train labels sample: tensor([0, 1, 1, 0, 0]), Shape: torch.Size([916])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([180])\n",
      "##########################DeepPavlov/rubert-base-cased---bert####################\n",
      "Epoch 1, Loss: 0.12492740107700229\n",
      "Epoch 2, Loss: 0.026496331374048544\n",
      "Epoch 3, Loss: 0.10374162319128337\n",
      "Epoch 4, Loss: 0.04929140522465881\n",
      "Epoch 5, Loss: 0.015599360400489691\n",
      "Epoch 6, Loss: 0.014454435019207925\n",
      "all_preds shape: (180,)\n",
      "all_labels shape: (180,)\n",
      "all_probs shape: (180, 2)\n",
      "Train labels sample: tensor([0, 0, 1, 0, 1]), Shape: torch.Size([916])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([177])\n",
      "##########################DeepPavlov/rubert-base-cased---bert####################\n",
      "Epoch 1, Loss: 0.13136378055085138\n",
      "Epoch 2, Loss: 0.006810331742223031\n",
      "Epoch 3, Loss: 0.030339901036972275\n",
      "Epoch 4, Loss: 0.06351748054871208\n",
      "Epoch 5, Loss: 0.04676147502373326\n",
      "Epoch 6, Loss: 0.007546252861081077\n",
      "all_preds shape: (177,)\n",
      "all_labels shape: (177,)\n",
      "all_probs shape: (177, 2)\n",
      "train_Изъяты лексемы с частотой выше 100.csv\n",
      "test_Изъяты лексемы с частотой выше 100.csv\n",
      "Train labels sample: tensor([1, 1, 1, 0, 0]), Shape: torch.Size([871])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([190])\n",
      "##########################bert-base-multilingual-cased---bert####################\n",
      "Epoch 1, Loss: 0.19777640840038657\n",
      "Epoch 2, Loss: 0.043967488234524024\n",
      "Epoch 3, Loss: 0.04001460912510414\n",
      "Epoch 4, Loss: 0.012944283661305565\n",
      "Epoch 5, Loss: 0.003217146048766815\n",
      "Epoch 6, Loss: 0.0008353803476149386\n",
      "all_preds shape: (190,)\n",
      "all_labels shape: (190,)\n",
      "all_probs shape: (190, 2)\n",
      "Train labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([871])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([192])\n",
      "##########################bert-base-multilingual-cased---bert####################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.20612630752677266\n",
      "Epoch 2, Loss: 0.012403716151179238\n",
      "Epoch 3, Loss: 0.01204355936603282\n",
      "Epoch 4, Loss: 0.0028247689553113145\n",
      "Epoch 5, Loss: 0.006349852772175589\n",
      "Epoch 6, Loss: 0.0013985254452563822\n",
      "all_preds shape: (192,)\n",
      "all_labels shape: (192,)\n",
      "all_probs shape: (192, 2)\n",
      "Train labels sample: tensor([0, 0, 1, 1, 1]), Shape: torch.Size([871])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([190])\n",
      "##########################bert-base-multilingual-cased---bert####################\n",
      "Epoch 1, Loss: 0.13377320380796762\n",
      "Epoch 2, Loss: 0.029056850183670494\n",
      "Epoch 3, Loss: 0.059911348774436525\n",
      "Epoch 4, Loss: 0.048556194657629184\n",
      "Epoch 5, Loss: 0.020925084679302843\n",
      "Epoch 6, Loss: 0.026550593437753955\n",
      "all_preds shape: (190,)\n",
      "all_labels shape: (190,)\n",
      "all_probs shape: (190, 2)\n",
      "Train labels sample: tensor([1, 1, 1, 0, 1]), Shape: torch.Size([871])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([200])\n",
      "##########################bert-base-multilingual-cased---bert####################\n",
      "Epoch 1, Loss: 0.32490632432428274\n",
      "Epoch 2, Loss: 0.04787257916548036\n",
      "Epoch 3, Loss: 0.011807988270778547\n",
      "Epoch 4, Loss: 0.013175617998719892\n",
      "Epoch 5, Loss: 0.020499041683929548\n",
      "Epoch 6, Loss: 0.003304117906372994\n",
      "all_preds shape: (200,)\n",
      "all_labels shape: (200,)\n",
      "all_probs shape: (200, 2)\n",
      "Train labels sample: tensor([0, 0, 0, 0, 1]), Shape: torch.Size([871])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([189])\n",
      "##########################bert-base-multilingual-cased---bert####################\n",
      "Epoch 1, Loss: 0.19439266454851764\n",
      "Epoch 2, Loss: 0.029798260022124105\n",
      "Epoch 3, Loss: 0.023723071392371575\n",
      "Epoch 4, Loss: 0.009267843094527382\n",
      "Epoch 5, Loss: 0.01239222712518478\n",
      "Epoch 6, Loss: 0.13310853823098692\n",
      "all_preds shape: (189,)\n",
      "all_labels shape: (189,)\n",
      "all_probs shape: (189, 2)\n",
      "Train labels sample: tensor([0, 0, 0, 0, 1]), Shape: torch.Size([871])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([191])\n",
      "##########################bert-base-multilingual-cased---bert####################\n",
      "Epoch 1, Loss: 0.20295312275940722\n",
      "Epoch 2, Loss: 0.10237352064048702\n",
      "Epoch 3, Loss: 0.11223274772478775\n",
      "Epoch 4, Loss: 0.25459530061449515\n",
      "Epoch 5, Loss: 0.1594934678213163\n",
      "Epoch 6, Loss: 0.28239000947637993\n",
      "all_preds shape: (191,)\n",
      "all_labels shape: (191,)\n",
      "all_probs shape: (191, 2)\n",
      "train_Изъяты лексемы с частотой выше 49.csv\n",
      "test_Изъяты лексемы с частотой выше 49.csv\n",
      "Train labels sample: tensor([0, 1, 1, 0, 1]), Shape: torch.Size([900])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([176])\n",
      "##########################bert-base-multilingual-cased---bert####################\n",
      "Epoch 1, Loss: 0.16000937049587569\n",
      "Epoch 2, Loss: 0.08861061008320305\n",
      "Epoch 3, Loss: 0.03927751705091316\n",
      "Epoch 4, Loss: 0.019719277620887418\n",
      "Epoch 5, Loss: 0.006303562605018287\n",
      "Epoch 6, Loss: 0.0005894877351493689\n",
      "all_preds shape: (176,)\n",
      "all_labels shape: (176,)\n",
      "all_probs shape: (176, 2)\n",
      "Train labels sample: tensor([1, 1, 0, 0, 1]), Shape: torch.Size([900])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([180])\n",
      "##########################bert-base-multilingual-cased---bert####################\n",
      "Epoch 1, Loss: 0.12411795321263765\n",
      "Epoch 2, Loss: 0.0489162917763583\n",
      "Epoch 3, Loss: 0.08670490501313716\n",
      "Epoch 4, Loss: 0.04421002477031659\n",
      "Epoch 5, Loss: 0.026682411385863497\n",
      "Epoch 6, Loss: 0.015607500675526497\n",
      "all_preds shape: (180,)\n",
      "all_labels shape: (180,)\n",
      "all_probs shape: (180, 2)\n",
      "Train labels sample: tensor([1, 1, 1, 0, 0]), Shape: torch.Size([900])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([184])\n",
      "##########################bert-base-multilingual-cased---bert####################\n",
      "Epoch 1, Loss: 0.13503737404550376\n",
      "Epoch 2, Loss: 0.06938163480076023\n",
      "Epoch 3, Loss: 0.0957719032865083\n",
      "Epoch 4, Loss: 0.1961960875135111\n",
      "Epoch 5, Loss: 0.0095898037175893\n",
      "Epoch 6, Loss: 0.0932289821998494\n",
      "all_preds shape: (184,)\n",
      "all_labels shape: (184,)\n",
      "all_probs shape: (184, 2)\n",
      "Train labels sample: tensor([1, 0, 1, 0, 0]), Shape: torch.Size([900])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([191])\n",
      "##########################bert-base-multilingual-cased---bert####################\n",
      "Epoch 1, Loss: 0.16821632713177487\n",
      "Epoch 2, Loss: 0.08903239629835936\n",
      "Epoch 3, Loss: 0.04586615299871355\n",
      "Epoch 4, Loss: 0.04893325525744442\n",
      "Epoch 5, Loss: 0.040377043116135165\n",
      "Epoch 6, Loss: 0.009388987250675104\n",
      "all_preds shape: (191,)\n",
      "all_labels shape: (191,)\n",
      "all_probs shape: (191, 2)\n",
      "Train labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([900])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([200])\n",
      "##########################bert-base-multilingual-cased---bert####################\n",
      "Epoch 1, Loss: 0.16138051508255957\n",
      "Epoch 2, Loss: 0.03199769887182731\n",
      "Epoch 3, Loss: 0.02353252343049175\n",
      "Epoch 4, Loss: 0.057039109803123496\n",
      "Epoch 5, Loss: 0.0324154730422602\n",
      "Epoch 6, Loss: 0.0052944760352961326\n",
      "all_preds shape: (200,)\n",
      "all_labels shape: (200,)\n",
      "all_probs shape: (200, 2)\n",
      "Train labels sample: tensor([1, 0, 0, 0, 0]), Shape: torch.Size([900])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([196])\n",
      "##########################bert-base-multilingual-cased---bert####################\n",
      "Epoch 1, Loss: 0.16766588956836545\n",
      "Epoch 2, Loss: 0.025464598085371812\n",
      "Epoch 3, Loss: 0.1249000390709721\n",
      "Epoch 4, Loss: 0.1140411458010867\n",
      "Epoch 5, Loss: 0.024675063543805952\n",
      "Epoch 6, Loss: 0.017651878722142755\n",
      "all_preds shape: (196,)\n",
      "all_labels shape: (196,)\n",
      "all_probs shape: (196, 2)\n",
      "train_Изъяты лексемы с частотой выше 29.csv\n",
      "test_Изъяты лексемы с частотой выше 29.csv\n",
      "Train labels sample: tensor([0, 0, 1, 0, 0]), Shape: torch.Size([887])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([197])\n",
      "##########################bert-base-multilingual-cased---bert####################\n",
      "Epoch 1, Loss: 0.20278369967958756\n",
      "Epoch 2, Loss: 0.07867107531222116\n",
      "Epoch 3, Loss: 0.023730254626051255\n",
      "Epoch 4, Loss: 0.030297359890287874\n",
      "Epoch 5, Loss: 0.038003769470378757\n",
      "Epoch 6, Loss: 0.041460277537615706\n",
      "all_preds shape: (197,)\n",
      "all_labels shape: (197,)\n",
      "all_probs shape: (197, 2)\n",
      "Train labels sample: tensor([0, 0, 0, 1, 0]), Shape: torch.Size([887])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([191])\n",
      "##########################bert-base-multilingual-cased---bert####################\n",
      "Epoch 1, Loss: 0.2617054231564647\n",
      "Epoch 2, Loss: 0.06638624955251414\n",
      "Epoch 3, Loss: 0.07649868988664821\n",
      "Epoch 4, Loss: 0.04216558389349042\n",
      "Epoch 5, Loss: 0.03425976718842451\n",
      "Epoch 6, Loss: 0.011241242985956237\n",
      "all_preds shape: (191,)\n",
      "all_labels shape: (191,)\n",
      "all_probs shape: (191, 2)\n",
      "Train labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([887])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([201])\n",
      "##########################bert-base-multilingual-cased---bert####################\n",
      "Epoch 1, Loss: 0.19569852761924267\n",
      "Epoch 2, Loss: 0.0658083550390854\n",
      "Epoch 3, Loss: 0.018456566717109775\n",
      "Epoch 4, Loss: 0.012806747227192059\n",
      "Epoch 5, Loss: 0.020066855708137155\n",
      "Epoch 6, Loss: 0.0023958555123369607\n",
      "all_preds shape: (201,)\n",
      "all_labels shape: (201,)\n",
      "all_probs shape: (201, 2)\n",
      "Train labels sample: tensor([0, 1, 0, 0, 0]), Shape: torch.Size([887])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([189])\n",
      "##########################bert-base-multilingual-cased---bert####################\n",
      "Epoch 1, Loss: 0.1873456335659804\n",
      "Epoch 2, Loss: 0.031488713035027364\n",
      "Epoch 3, Loss: 0.018462508542662754\n",
      "Epoch 4, Loss: 0.0007359882952836674\n",
      "Epoch 5, Loss: 0.0004217304693676332\n",
      "Epoch 6, Loss: 0.0003105261078287315\n",
      "all_preds shape: (189,)\n",
      "all_labels shape: (189,)\n",
      "all_probs shape: (189, 2)\n",
      "Train labels sample: tensor([0, 1, 0, 0, 0]), Shape: torch.Size([887])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([204])\n",
      "##########################bert-base-multilingual-cased---bert####################\n",
      "Epoch 1, Loss: 0.22483294680049376\n",
      "Epoch 2, Loss: 0.05353439847073917\n",
      "Epoch 3, Loss: 0.012721040017952743\n",
      "Epoch 4, Loss: 0.001771017981809564\n",
      "Epoch 5, Loss: 0.0004667455240061307\n",
      "Epoch 6, Loss: 0.000358098549830694\n",
      "all_preds shape: (204,)\n",
      "all_labels shape: (204,)\n",
      "all_probs shape: (204, 2)\n",
      "Train labels sample: tensor([1, 1, 1, 0, 0]), Shape: torch.Size([887])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([188])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##########################bert-base-multilingual-cased---bert####################\n",
      "Epoch 1, Loss: 0.14494097511383838\n",
      "Epoch 2, Loss: 0.04649744718335569\n",
      "Epoch 3, Loss: 0.034784541689857305\n",
      "Epoch 4, Loss: 0.07507709202971975\n",
      "Epoch 5, Loss: 0.02726793298539373\n",
      "Epoch 6, Loss: 0.18769457517191768\n",
      "all_preds shape: (188,)\n",
      "all_labels shape: (188,)\n",
      "all_probs shape: (188, 2)\n",
      "train_Изъяты лексемы с частотой выше 9.csv\n",
      "test_Изъяты лексемы с частотой выше 9.csv\n",
      "Train labels sample: tensor([0, 0, 0, 0, 1]), Shape: torch.Size([766])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([350])\n",
      "##########################bert-base-multilingual-cased---bert####################\n",
      "Epoch 1, Loss: 0.2969627445563674\n",
      "Epoch 2, Loss: 0.09221231774426997\n",
      "Epoch 3, Loss: 0.04156389813094089\n",
      "Epoch 4, Loss: 0.013756452205901345\n",
      "all_preds shape: (350,)\n",
      "all_labels shape: (350,)\n",
      "all_probs shape: (350, 2)\n",
      "Train labels sample: tensor([0, 1, 0, 1, 1]), Shape: torch.Size([766])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([343])\n",
      "##########################bert-base-multilingual-cased---bert####################\n",
      "Epoch 1, Loss: 0.4286726502080758\n",
      "Epoch 2, Loss: 0.15229894748578468\n",
      "Epoch 3, Loss: 0.10242425991843145\n",
      "Epoch 4, Loss: 0.061080312627988555\n",
      "all_preds shape: (343,)\n",
      "all_labels shape: (343,)\n",
      "all_probs shape: (343, 2)\n",
      "Train labels sample: tensor([1, 1, 0, 0, 0]), Shape: torch.Size([766])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([259])\n",
      "##########################bert-base-multilingual-cased---bert####################\n",
      "Epoch 1, Loss: 0.27987992065027356\n",
      "Epoch 2, Loss: 0.04986202703245605\n",
      "Epoch 3, Loss: 0.021606425774128486\n",
      "Epoch 4, Loss: 0.029699361582364265\n",
      "all_preds shape: (259,)\n",
      "all_labels shape: (259,)\n",
      "all_probs shape: (259, 2)\n",
      "Train labels sample: tensor([1, 0, 1, 0, 1]), Shape: torch.Size([766])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([274])\n",
      "##########################bert-base-multilingual-cased---bert####################\n",
      "Epoch 1, Loss: 0.34991270148505765\n",
      "Epoch 2, Loss: 0.0736477817214715\n",
      "Epoch 3, Loss: 0.08460203212841104\n",
      "Epoch 4, Loss: 0.039082244775878884\n",
      "all_preds shape: (274,)\n",
      "all_labels shape: (274,)\n",
      "all_probs shape: (274, 2)\n",
      "Train labels sample: tensor([0, 0, 0, 0, 1]), Shape: torch.Size([766])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([261])\n",
      "##########################bert-base-multilingual-cased---bert####################\n",
      "Epoch 1, Loss: 0.4319517278733353\n",
      "Epoch 2, Loss: 0.12766196803810695\n",
      "Epoch 3, Loss: 0.04949411759541059\n",
      "Epoch 4, Loss: 0.007937891302087033\n",
      "all_preds shape: (261,)\n",
      "all_labels shape: (261,)\n",
      "all_probs shape: (261, 2)\n",
      "Train labels sample: tensor([0, 0, 0, 0, 1]), Shape: torch.Size([766])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([264])\n",
      "##########################bert-base-multilingual-cased---bert####################\n",
      "Epoch 1, Loss: 0.2621637642538796\n",
      "Epoch 2, Loss: 0.06665074444996814\n",
      "Epoch 3, Loss: 0.04519887489732355\n",
      "Epoch 4, Loss: 0.029207394632976502\n",
      "all_preds shape: (264,)\n",
      "all_labels shape: (264,)\n",
      "all_probs shape: (264, 2)\n",
      "train_Изъяты лексемы с частотой выше 5.csv\n",
      "test_Изъяты лексемы с частотой выше 5.csv\n",
      "Train labels sample: tensor([0, 0, 1, 0, 0]), Shape: torch.Size([96])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([528])\n",
      "##########################bert-base-multilingual-cased---bert####################\n",
      "Epoch 1, Loss: 0.4784973586599032\n",
      "Epoch 2, Loss: 0.13094096910208464\n",
      "Epoch 3, Loss: 0.06018984550610185\n",
      "Epoch 4, Loss: 0.009076086959491173\n",
      "Epoch 5, Loss: 0.014216398975501457\n",
      "Epoch 6, Loss: 0.5628291442990303\n",
      "all_preds shape: (528,)\n",
      "all_labels shape: (528,)\n",
      "all_probs shape: (528, 2)\n",
      "Train labels sample: tensor([1, 0, 0, 1, 1]), Shape: torch.Size([96])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([507])\n",
      "##########################bert-base-multilingual-cased---bert####################\n",
      "Epoch 1, Loss: 0.48607971767584485\n",
      "Epoch 2, Loss: 0.22270664076010385\n",
      "Epoch 3, Loss: 0.07294444118936856\n",
      "Epoch 4, Loss: 0.062203638876477875\n",
      "Epoch 5, Loss: 0.06822614775349696\n",
      "Epoch 6, Loss: 0.025562459758172434\n",
      "all_preds shape: (507,)\n",
      "all_labels shape: (507,)\n",
      "all_probs shape: (507, 2)\n",
      "Train labels sample: tensor([0, 0, 0, 1, 1]), Shape: torch.Size([96])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([513])\n",
      "##########################bert-base-multilingual-cased---bert####################\n",
      "Epoch 1, Loss: 0.5963945885499319\n",
      "Epoch 2, Loss: 0.3233761514226596\n",
      "Epoch 3, Loss: 0.2439992701013883\n",
      "Epoch 4, Loss: 0.10648456091682117\n",
      "Epoch 5, Loss: 0.04546555100629727\n",
      "Epoch 6, Loss: 0.03175989491865039\n",
      "all_preds shape: (513,)\n",
      "all_labels shape: (513,)\n",
      "all_probs shape: (513, 2)\n",
      "Train labels sample: tensor([0, 0, 0, 1, 0]), Shape: torch.Size([96])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([576])\n",
      "##########################bert-base-multilingual-cased---bert####################\n",
      "Epoch 1, Loss: 0.6118281781673431\n",
      "Epoch 2, Loss: 0.36074374864498776\n",
      "Epoch 3, Loss: 0.13434211164712906\n",
      "Epoch 4, Loss: 0.017260062508285046\n",
      "Epoch 5, Loss: 0.08303744617539148\n",
      "Epoch 6, Loss: 0.21349594579078257\n",
      "all_preds shape: (576,)\n",
      "all_labels shape: (576,)\n",
      "all_probs shape: (576, 2)\n",
      "Train labels sample: tensor([0, 0, 0, 0, 1]), Shape: torch.Size([96])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([491])\n",
      "##########################bert-base-multilingual-cased---bert####################\n",
      "Epoch 1, Loss: 0.6050250927607218\n",
      "Epoch 2, Loss: 0.28809074809153873\n",
      "Epoch 3, Loss: 0.07527191968013842\n",
      "Epoch 4, Loss: 0.018515893413374823\n",
      "Epoch 5, Loss: 0.007349995197728276\n",
      "Epoch 6, Loss: 0.005374764907173812\n",
      "all_preds shape: (491,)\n",
      "all_labels shape: (491,)\n",
      "all_probs shape: (491, 2)\n",
      "Train labels sample: tensor([0, 0, 0, 1, 0]), Shape: torch.Size([96])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([456])\n",
      "##########################bert-base-multilingual-cased---bert####################\n",
      "Epoch 1, Loss: 0.5903976658980051\n",
      "Epoch 2, Loss: 0.26868894696235657\n",
      "Epoch 3, Loss: 0.05609374555448691\n",
      "Epoch 4, Loss: 0.011115800201271972\n",
      "Epoch 5, Loss: 0.003565784931803743\n",
      "Epoch 6, Loss: 0.0019579684982697168\n",
      "all_preds shape: (456,)\n",
      "all_labels shape: (456,)\n",
      "all_probs shape: (456, 2)\n",
      "train_Изъяты лексемы с частотой выше 3.csv\n",
      "test_Изъяты лексемы с частотой выше 3.csv\n",
      "Train labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([90])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([700])\n",
      "##########################bert-base-multilingual-cased---bert####################\n",
      "Epoch 1, Loss: 0.5395708034435908\n",
      "Epoch 2, Loss: 0.35716143250465393\n",
      "Epoch 3, Loss: 0.050185694359242916\n",
      "Epoch 4, Loss: 0.18029358851102492\n",
      "Epoch 5, Loss: 0.14664367361304662\n",
      "Epoch 6, Loss: 0.011858559679239988\n",
      "all_preds shape: (700,)\n",
      "all_labels shape: (700,)\n",
      "all_probs shape: (700, 2)\n",
      "Train labels sample: tensor([0, 1, 0, 0, 0]), Shape: torch.Size([90])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([732])\n",
      "##########################bert-base-multilingual-cased---bert####################\n",
      "Epoch 1, Loss: 0.5078713794549307\n",
      "Epoch 2, Loss: 0.23147482114533582\n",
      "Epoch 3, Loss: 0.20276948933800062\n",
      "Epoch 4, Loss: 0.27764067985117435\n",
      "Epoch 5, Loss: 0.057915277779102325\n",
      "Epoch 6, Loss: 0.07589956504913668\n",
      "all_preds shape: (732,)\n",
      "all_labels shape: (732,)\n",
      "all_probs shape: (732, 2)\n",
      "Train labels sample: tensor([1, 1, 0, 0, 0]), Shape: torch.Size([90])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([739])\n",
      "##########################bert-base-multilingual-cased---bert####################\n",
      "Epoch 1, Loss: 0.5139186630646387\n",
      "Epoch 2, Loss: 0.18880020454525948\n",
      "Epoch 3, Loss: 0.07772529435654481\n",
      "Epoch 4, Loss: 0.036466251437862716\n",
      "Epoch 5, Loss: 0.005341544126470883\n",
      "Epoch 6, Loss: 0.00324111501686275\n",
      "all_preds shape: (739,)\n",
      "all_labels shape: (739,)\n",
      "all_probs shape: (739, 2)\n",
      "Train labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([90])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([720])\n",
      "##########################bert-base-multilingual-cased---bert####################\n",
      "Epoch 1, Loss: 0.4852629601955414\n",
      "Epoch 2, Loss: 0.11397374793887138\n",
      "Epoch 3, Loss: 0.016721514674524467\n",
      "Epoch 4, Loss: 0.004228069408175846\n",
      "Epoch 5, Loss: 0.0021339241648092866\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Loss: 0.0013584729167632759\n",
      "all_preds shape: (720,)\n",
      "all_labels shape: (720,)\n",
      "all_probs shape: (720, 2)\n",
      "Train labels sample: tensor([0, 0, 1, 0, 0]), Shape: torch.Size([90])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([715])\n",
      "##########################bert-base-multilingual-cased---bert####################\n",
      "Epoch 1, Loss: 0.5337005307277044\n",
      "Epoch 2, Loss: 0.13796362156669298\n",
      "Epoch 3, Loss: 0.041755043591062226\n",
      "Epoch 4, Loss: 0.09080953158748646\n",
      "Epoch 5, Loss: 0.004733639885671437\n",
      "Epoch 6, Loss: 0.009332983172498643\n",
      "all_preds shape: (715,)\n",
      "all_labels shape: (715,)\n",
      "all_probs shape: (715, 2)\n",
      "Train labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([90])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([691])\n",
      "##########################bert-base-multilingual-cased---bert####################\n",
      "Epoch 1, Loss: 0.4827040359377861\n",
      "Epoch 2, Loss: 0.16726451801757017\n",
      "Epoch 3, Loss: 0.0323668965138495\n",
      "Epoch 4, Loss: 0.06055594988477727\n",
      "Epoch 5, Loss: 0.012497741651410857\n",
      "Epoch 6, Loss: 0.004664718095834057\n",
      "all_preds shape: (691,)\n",
      "all_labels shape: (691,)\n",
      "all_probs shape: (691, 2)\n",
      "train_Без прилагательных первый-второй жанр.csv\n",
      "test_Без прилагательных первый-второй жанр.csv\n",
      "Train labels sample: tensor([1, 1, 0, 0, 0]), Shape: torch.Size([846])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([193])\n",
      "##########################bert-base-multilingual-cased---bert####################\n",
      "Epoch 1, Loss: 0.2666535331281247\n",
      "Epoch 2, Loss: 0.0394669322779885\n",
      "Epoch 3, Loss: 0.014290666250787952\n",
      "Epoch 4, Loss: 0.004585165677040264\n",
      "all_preds shape: (193,)\n",
      "all_labels shape: (193,)\n",
      "all_probs shape: (193, 2)\n",
      "Train labels sample: tensor([0, 0, 1, 1, 0]), Shape: torch.Size([846])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([171])\n",
      "##########################bert-base-multilingual-cased---bert####################\n",
      "Epoch 1, Loss: 0.23820883966982365\n",
      "Epoch 2, Loss: 0.03808570877407436\n",
      "Epoch 3, Loss: 0.033212775002337165\n",
      "Epoch 4, Loss: 0.007478099208566602\n",
      "all_preds shape: (171,)\n",
      "all_labels shape: (171,)\n",
      "all_probs shape: (171, 2)\n",
      "Train labels sample: tensor([0, 1, 1, 0, 0]), Shape: torch.Size([846])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([183])\n",
      "##########################bert-base-multilingual-cased---bert####################\n",
      "Epoch 1, Loss: 0.24925090403606495\n",
      "Epoch 2, Loss: 0.03718510499500014\n",
      "Epoch 3, Loss: 0.01022300731252741\n",
      "Epoch 4, Loss: 0.0052861318043950535\n",
      "all_preds shape: (183,)\n",
      "all_labels shape: (183,)\n",
      "all_probs shape: (183, 2)\n",
      "Train labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([846])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([178])\n",
      "##########################bert-base-multilingual-cased---bert####################\n",
      "Epoch 1, Loss: 0.20800361216620164\n",
      "Epoch 2, Loss: 0.0289637070770065\n",
      "Epoch 3, Loss: 0.013332713059046201\n",
      "Epoch 4, Loss: 0.025596919266886457\n",
      "all_preds shape: (178,)\n",
      "all_labels shape: (178,)\n",
      "all_probs shape: (178, 2)\n",
      "Train labels sample: tensor([0, 0, 0, 0, 1]), Shape: torch.Size([846])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([173])\n",
      "##########################bert-base-multilingual-cased---bert####################\n",
      "Epoch 1, Loss: 0.17322041111549846\n",
      "Epoch 2, Loss: 0.03671937258224244\n",
      "Epoch 3, Loss: 0.012389533816733293\n",
      "Epoch 4, Loss: 0.0018289877895127844\n",
      "all_preds shape: (173,)\n",
      "all_labels shape: (173,)\n",
      "all_probs shape: (173, 2)\n",
      "Train labels sample: tensor([0, 1, 1, 1, 0]), Shape: torch.Size([846])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([171])\n",
      "##########################bert-base-multilingual-cased---bert####################\n",
      "Epoch 1, Loss: 0.22807890397531014\n",
      "Epoch 2, Loss: 0.06065606386228292\n",
      "Epoch 3, Loss: 0.031051555424238795\n",
      "Epoch 4, Loss: 0.0041640690631336635\n",
      "all_preds shape: (171,)\n",
      "all_labels shape: (171,)\n",
      "all_probs shape: (171, 2)\n",
      "train_1.Первый жанр исходная выборка.csv\n",
      "test_1.Первый жанр исходная выборка.csv\n",
      "Train labels sample: tensor([1, 1, 1, 0, 0]), Shape: torch.Size([893])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([169])\n",
      "##########################bert-base-multilingual-cased---bert####################\n",
      "Epoch 1, Loss: 0.1654090553389064\n",
      "Epoch 2, Loss: 0.12404653053714096\n",
      "Epoch 3, Loss: 0.05455232782073186\n",
      "Epoch 4, Loss: 0.020316061233253486\n",
      "Epoch 5, Loss: 0.008395416301417364\n",
      "Epoch 6, Loss: 0.00830818903029597\n",
      "all_preds shape: (169,)\n",
      "all_labels shape: (169,)\n",
      "all_probs shape: (169, 2)\n",
      "Train labels sample: tensor([1, 0, 1, 0, 0]), Shape: torch.Size([893])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([164])\n",
      "##########################bert-base-multilingual-cased---bert####################\n",
      "Epoch 1, Loss: 0.1151479520693621\n",
      "Epoch 2, Loss: 0.09675918067971777\n",
      "Epoch 3, Loss: 0.01402758309060508\n",
      "Epoch 4, Loss: 0.019536262705514673\n",
      "Epoch 5, Loss: 0.015893631329942894\n",
      "Epoch 6, Loss: 0.02076496729984813\n",
      "all_preds shape: (164,)\n",
      "all_labels shape: (164,)\n",
      "all_probs shape: (164, 2)\n",
      "Train labels sample: tensor([1, 0, 1, 0, 0]), Shape: torch.Size([893])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([164])\n",
      "##########################bert-base-multilingual-cased---bert####################\n",
      "Epoch 1, Loss: 0.17189904950958276\n",
      "Epoch 2, Loss: 0.05731167149081427\n",
      "Epoch 3, Loss: 0.017555136551631483\n",
      "Epoch 4, Loss: 0.00842141961766174\n",
      "Epoch 5, Loss: 0.04527904467457639\n",
      "Epoch 6, Loss: 0.021101976999489125\n",
      "all_preds shape: (164,)\n",
      "all_labels shape: (164,)\n",
      "all_probs shape: (164, 2)\n",
      "Train labels sample: tensor([0, 0, 0, 1, 1]), Shape: torch.Size([893])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([169])\n",
      "##########################bert-base-multilingual-cased---bert####################\n",
      "Epoch 1, Loss: 0.11557154266795676\n",
      "Epoch 2, Loss: 0.038906293838018816\n",
      "Epoch 3, Loss: 0.0626566567932189\n",
      "Epoch 4, Loss: 0.01821762766381393\n",
      "Epoch 5, Loss: 0.0022679131527963492\n",
      "Epoch 6, Loss: 0.0007484742033869095\n",
      "all_preds shape: (169,)\n",
      "all_labels shape: (169,)\n",
      "all_probs shape: (169, 2)\n",
      "Train labels sample: tensor([0, 0, 1, 0, 1]), Shape: torch.Size([893])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([158])\n",
      "##########################bert-base-multilingual-cased---bert####################\n",
      "Epoch 1, Loss: 0.10928680663762082\n",
      "Epoch 2, Loss: 0.029300259099857482\n",
      "Epoch 3, Loss: 0.05378498442379558\n",
      "Epoch 4, Loss: 0.0016318201087415218\n",
      "Epoch 5, Loss: 0.0005366292986894093\n",
      "Epoch 6, Loss: 0.00034613110515887717\n",
      "all_preds shape: (158,)\n",
      "all_labels shape: (158,)\n",
      "all_probs shape: (158, 2)\n",
      "Train labels sample: tensor([1, 0, 0, 1, 0]), Shape: torch.Size([893])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([160])\n",
      "##########################bert-base-multilingual-cased---bert####################\n",
      "Epoch 1, Loss: 0.16376206277969427\n",
      "Epoch 2, Loss: 0.03298109802459034\n",
      "Epoch 3, Loss: 0.04617844298731403\n",
      "Epoch 4, Loss: 0.02262056068970456\n",
      "Epoch 5, Loss: 0.0019845965673864286\n",
      "Epoch 6, Loss: 0.000511174897318207\n",
      "all_preds shape: (160,)\n",
      "all_labels shape: (160,)\n",
      "all_probs shape: (160, 2)\n",
      "train_2.Первый жанр без клауз, включающих наречия.csv\n",
      "test_2.Первый жанр без клауз, включающих наречия.csv\n",
      "Train labels sample: tensor([1, 1, 0, 0, 0]), Shape: torch.Size([880])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([169])\n",
      "##########################bert-base-multilingual-cased---bert####################\n",
      "Epoch 1, Loss: 0.1762515326369215\n",
      "Epoch 2, Loss: 0.02359481534327973\n",
      "Epoch 3, Loss: 0.008380682809828696\n",
      "Epoch 4, Loss: 0.0006047330098226666\n",
      "Epoch 5, Loss: 0.00042700923143208704\n",
      "Epoch 6, Loss: 0.00031850500725506044\n",
      "all_preds shape: (169,)\n",
      "all_labels shape: (169,)\n",
      "all_probs shape: (169, 2)\n",
      "Train labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([880])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([163])\n",
      "##########################bert-base-multilingual-cased---bert####################\n",
      "Epoch 1, Loss: 0.19816247563470493\n",
      "Epoch 2, Loss: 0.044909262856129895\n",
      "Epoch 3, Loss: 0.042634008390913636\n",
      "Epoch 4, Loss: 0.00964848378630863\n",
      "Epoch 5, Loss: 0.010783663253426891\n",
      "Epoch 6, Loss: 0.07735220912674612\n",
      "all_preds shape: (163,)\n",
      "all_labels shape: (163,)\n",
      "all_probs shape: (163, 2)\n",
      "Train labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([880])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([173])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##########################bert-base-multilingual-cased---bert####################\n",
      "Epoch 1, Loss: 0.14589556004344062\n",
      "Epoch 2, Loss: 0.05720130875706673\n",
      "Epoch 3, Loss: 0.027947148409756747\n",
      "Epoch 4, Loss: 0.024640222774310546\n",
      "Epoch 5, Loss: 0.01005970505066216\n",
      "Epoch 6, Loss: 0.0012594380998052657\n",
      "all_preds shape: (173,)\n",
      "all_labels shape: (173,)\n",
      "all_probs shape: (173, 2)\n",
      "Train labels sample: tensor([0, 1, 1, 1, 0]), Shape: torch.Size([880])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([168])\n",
      "##########################bert-base-multilingual-cased---bert####################\n",
      "Epoch 1, Loss: 0.27852047038349237\n",
      "Epoch 2, Loss: 0.08920111935585737\n",
      "Epoch 3, Loss: 0.09645292176441712\n",
      "Epoch 4, Loss: 0.08314299061894417\n",
      "Epoch 5, Loss: 0.15537064707076007\n",
      "Epoch 6, Loss: 0.04797839630733837\n",
      "all_preds shape: (168,)\n",
      "all_labels shape: (168,)\n",
      "all_probs shape: (168, 2)\n",
      "Train labels sample: tensor([1, 1, 0, 0, 0]), Shape: torch.Size([880])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([167])\n",
      "##########################bert-base-multilingual-cased---bert####################\n",
      "Epoch 1, Loss: 0.16557209605181758\n",
      "Epoch 2, Loss: 0.09656419992785562\n",
      "Epoch 3, Loss: 0.032856057017025625\n",
      "Epoch 4, Loss: 0.010283084453972564\n",
      "Epoch 5, Loss: 0.009077903020872989\n",
      "Epoch 6, Loss: 0.008713997912127524\n",
      "all_preds shape: (167,)\n",
      "all_labels shape: (167,)\n",
      "all_probs shape: (167, 2)\n",
      "Train labels sample: tensor([1, 0, 0, 1, 0]), Shape: torch.Size([880])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([180])\n",
      "##########################bert-base-multilingual-cased---bert####################\n",
      "Epoch 1, Loss: 0.1592229224402796\n",
      "Epoch 2, Loss: 0.03525198721326887\n",
      "Epoch 3, Loss: 0.04670536246743392\n",
      "Epoch 4, Loss: 0.03187449179293418\n",
      "Epoch 5, Loss: 0.021106309052133426\n",
      "Epoch 6, Loss: 0.029585950412067838\n",
      "all_preds shape: (180,)\n",
      "all_labels shape: (180,)\n",
      "all_probs shape: (180, 2)\n",
      "train_3.Первый жанр без клауз, включающих глаголы.csv\n",
      "test_3.Первый жанр без клауз, включающих глаголы.csv\n",
      "Train labels sample: tensor([1, 1, 1, 0, 1]), Shape: torch.Size([824])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([228])\n",
      "##########################bert-base-multilingual-cased---bert####################\n",
      "Epoch 1, Loss: 0.147631074131753\n",
      "Epoch 2, Loss: 0.04866390474713766\n",
      "Epoch 3, Loss: 0.020513486032051824\n",
      "Epoch 4, Loss: 0.006146318138165113\n",
      "Epoch 5, Loss: 0.017546561097753093\n",
      "Epoch 6, Loss: 0.04693252875138289\n",
      "all_preds shape: (228,)\n",
      "all_labels shape: (228,)\n",
      "all_probs shape: (228, 2)\n",
      "Train labels sample: tensor([1, 0, 0, 1, 0]), Shape: torch.Size([824])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([219])\n",
      "##########################bert-base-multilingual-cased---bert####################\n",
      "Epoch 1, Loss: 0.16039442279949212\n",
      "Epoch 2, Loss: 0.07227210897522476\n",
      "Epoch 3, Loss: 0.045834671737303816\n",
      "Epoch 4, Loss: 0.008219589553146552\n",
      "Epoch 5, Loss: 0.00762610966362095\n",
      "Epoch 6, Loss: 0.01335905326413922\n",
      "all_preds shape: (219,)\n",
      "all_labels shape: (219,)\n",
      "all_probs shape: (219, 2)\n",
      "Train labels sample: tensor([0, 0, 0, 1, 0]), Shape: torch.Size([824])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([211])\n",
      "##########################bert-base-multilingual-cased---bert####################\n",
      "Epoch 1, Loss: 0.2214324134043776\n",
      "Epoch 2, Loss: 0.03067423459679748\n",
      "Epoch 3, Loss: 0.010770864666063482\n",
      "Epoch 4, Loss: 0.008737168062138014\n",
      "Epoch 5, Loss: 0.02183431466087663\n",
      "Epoch 6, Loss: 0.10023818911017421\n",
      "all_preds shape: (211,)\n",
      "all_labels shape: (211,)\n",
      "all_probs shape: (211, 2)\n",
      "Train labels sample: tensor([0, 0, 1, 0, 1]), Shape: torch.Size([824])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([220])\n",
      "##########################bert-base-multilingual-cased---bert####################\n",
      "Epoch 1, Loss: 0.3159250220230136\n",
      "Epoch 2, Loss: 0.06406445548726389\n",
      "Epoch 3, Loss: 0.021682521811901376\n",
      "Epoch 4, Loss: 0.002832454593422321\n",
      "Epoch 5, Loss: 0.0010671761847333983\n",
      "Epoch 6, Loss: 0.0007186314693311802\n",
      "all_preds shape: (220,)\n",
      "all_labels shape: (220,)\n",
      "all_probs shape: (220, 2)\n",
      "Train labels sample: tensor([1, 0, 0, 0, 0]), Shape: torch.Size([824])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([216])\n",
      "##########################bert-base-multilingual-cased---bert####################\n",
      "Epoch 1, Loss: 0.18640762207528147\n",
      "Epoch 2, Loss: 0.04141037233281308\n",
      "Epoch 3, Loss: 0.007036607512138569\n",
      "Epoch 4, Loss: 0.0017393424428659133\n",
      "Epoch 5, Loss: 0.0007029503579430569\n",
      "Epoch 6, Loss: 0.006158898590701238\n",
      "all_preds shape: (216,)\n",
      "all_labels shape: (216,)\n",
      "all_probs shape: (216, 2)\n",
      "Train labels sample: tensor([1, 0, 1, 0, 1]), Shape: torch.Size([824])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([220])\n",
      "##########################bert-base-multilingual-cased---bert####################\n",
      "Epoch 1, Loss: 0.19448424253362015\n",
      "Epoch 2, Loss: 0.029136129131074995\n",
      "Epoch 3, Loss: 0.013615223254489068\n",
      "Epoch 4, Loss: 0.01059110051406046\n",
      "Epoch 5, Loss: 0.06704851391483456\n",
      "Epoch 6, Loss: 0.012572911741489615\n",
      "all_preds shape: (220,)\n",
      "all_labels shape: (220,)\n",
      "all_probs shape: (220, 2)\n",
      "train_4.Первый жанр без клауз, включающих глаголы и наречия.csv\n",
      "test_4.Первый жанр без клауз, включающих глаголы и наречия.csv\n",
      "Train labels sample: tensor([1, 1, 1, 0, 0]), Shape: torch.Size([805])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([239])\n",
      "##########################bert-base-multilingual-cased---bert####################\n",
      "Epoch 1, Loss: 0.13699698905624888\n",
      "Epoch 2, Loss: 0.06412351827420221\n",
      "Epoch 3, Loss: 0.030514926544628014\n",
      "Epoch 4, Loss: 0.12339961991243649\n",
      "Epoch 5, Loss: 0.03442732131053858\n",
      "Epoch 6, Loss: 0.010427619011013531\n",
      "all_preds shape: (239,)\n",
      "all_labels shape: (239,)\n",
      "all_probs shape: (239, 2)\n",
      "Train labels sample: tensor([1, 1, 0, 0, 1]), Shape: torch.Size([805])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([240])\n",
      "##########################bert-base-multilingual-cased---bert####################\n",
      "Epoch 1, Loss: 0.23972595147058076\n",
      "Epoch 2, Loss: 0.15880730059728318\n",
      "Epoch 3, Loss: 0.051711436087156046\n",
      "Epoch 4, Loss: 0.011021729273374612\n",
      "Epoch 5, Loss: 0.018361606783525764\n",
      "Epoch 6, Loss: 0.009634522256651418\n",
      "all_preds shape: (240,)\n",
      "all_labels shape: (240,)\n",
      "all_probs shape: (240, 2)\n",
      "Train labels sample: tensor([1, 0, 1, 0, 0]), Shape: torch.Size([805])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([248])\n",
      "##########################bert-base-multilingual-cased---bert####################\n",
      "Epoch 1, Loss: 0.16275578258814766\n",
      "Epoch 2, Loss: 0.0452912956677085\n",
      "Epoch 3, Loss: 0.032426800619920385\n",
      "Epoch 4, Loss: 0.0014573938279485732\n",
      "Epoch 5, Loss: 0.0007520489201780554\n",
      "Epoch 6, Loss: 0.0004287739227270233\n",
      "all_preds shape: (248,)\n",
      "all_labels shape: (248,)\n",
      "all_probs shape: (248, 2)\n",
      "Train labels sample: tensor([1, 0, 1, 1, 0]), Shape: torch.Size([805])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([233])\n",
      "##########################bert-base-multilingual-cased---bert####################\n",
      "Epoch 1, Loss: 0.13784983534110234\n",
      "Epoch 2, Loss: 0.03102992882029902\n",
      "Epoch 3, Loss: 0.005410551597985129\n",
      "Epoch 4, Loss: 0.0405581755410679\n",
      "Epoch 5, Loss: 0.047258278133585026\n",
      "Epoch 6, Loss: 0.007931611670738123\n",
      "all_preds shape: (233,)\n",
      "all_labels shape: (233,)\n",
      "all_probs shape: (233, 2)\n",
      "Train labels sample: tensor([0, 0, 0, 1, 1]), Shape: torch.Size([805])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([233])\n",
      "##########################bert-base-multilingual-cased---bert####################\n",
      "Epoch 1, Loss: 0.12677849317882575\n",
      "Epoch 2, Loss: 0.03312967929477785\n",
      "Epoch 3, Loss: 0.011541528150201867\n",
      "Epoch 4, Loss: 0.0401007560990276\n",
      "Epoch 5, Loss: 0.01875915099163631\n",
      "Epoch 6, Loss: 0.023969096127057485\n",
      "all_preds shape: (233,)\n",
      "all_labels shape: (233,)\n",
      "all_probs shape: (233, 2)\n",
      "Train labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([805])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([236])\n",
      "##########################bert-base-multilingual-cased---bert####################\n",
      "Epoch 1, Loss: 0.1373676533865578\n",
      "Epoch 2, Loss: 0.06038108169941195\n",
      "Epoch 3, Loss: 0.013279339311160512\n",
      "Epoch 4, Loss: 0.009789725811238967\n",
      "Epoch 5, Loss: 0.0023461862446685485\n",
      "Epoch 6, Loss: 0.0004289500602502741\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_preds shape: (236,)\n",
      "all_labels shape: (236,)\n",
      "all_probs shape: (236, 2)\n",
      "train_5.без клауз, включающих местоимения.txt.csv\n",
      "test_5.без клауз, включающих местоимения.txt.csv\n",
      "Train labels sample: tensor([0, 1, 0, 0, 1]), Shape: torch.Size([858])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([188])\n",
      "##########################bert-base-multilingual-cased---bert####################\n",
      "Epoch 1, Loss: 0.15790559868845674\n",
      "Epoch 2, Loss: 0.0958284289162192\n",
      "Epoch 3, Loss: 0.047068889763775386\n",
      "Epoch 4, Loss: 0.03353180811110953\n",
      "Epoch 5, Loss: 0.009424913217555042\n",
      "Epoch 6, Loss: 0.008975536356619731\n",
      "all_preds shape: (188,)\n",
      "all_labels shape: (188,)\n",
      "all_probs shape: (188, 2)\n",
      "Train labels sample: tensor([1, 0, 0, 1, 1]), Shape: torch.Size([858])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([181])\n",
      "##########################bert-base-multilingual-cased---bert####################\n",
      "Epoch 1, Loss: 0.14943502394103067\n",
      "Epoch 2, Loss: 0.02671787822705314\n",
      "Epoch 3, Loss: 0.01908200219299437\n",
      "Epoch 4, Loss: 0.036144443996750784\n",
      "Epoch 5, Loss: 0.04282536652560035\n",
      "Epoch 6, Loss: 0.08568951337063616\n",
      "all_preds shape: (181,)\n",
      "all_labels shape: (181,)\n",
      "all_probs shape: (181, 2)\n",
      "Train labels sample: tensor([1, 0, 0, 1, 0]), Shape: torch.Size([858])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([189])\n",
      "##########################bert-base-multilingual-cased---bert####################\n",
      "Epoch 1, Loss: 0.1612366525525296\n",
      "Epoch 2, Loss: 0.04366893674833355\n",
      "Epoch 3, Loss: 0.06611499185587659\n",
      "Epoch 4, Loss: 0.06198025075287593\n",
      "Epoch 5, Loss: 0.026563697046151868\n",
      "Epoch 6, Loss: 0.01700126518564368\n",
      "all_preds shape: (189,)\n",
      "all_labels shape: (189,)\n",
      "all_probs shape: (189, 2)\n",
      "Train labels sample: tensor([0, 1, 0, 0, 0]), Shape: torch.Size([858])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([178])\n",
      "##########################bert-base-multilingual-cased---bert####################\n",
      "Epoch 1, Loss: 0.24267117097904836\n",
      "Epoch 2, Loss: 0.020246424776915874\n",
      "Epoch 3, Loss: 0.009820664691721537\n",
      "Epoch 4, Loss: 0.014329180202265788\n",
      "Epoch 5, Loss: 0.014136678645930564\n",
      "Epoch 6, Loss: 0.08436836129058739\n",
      "all_preds shape: (178,)\n",
      "all_labels shape: (178,)\n",
      "all_probs shape: (178, 2)\n",
      "Train labels sample: tensor([1, 1, 1, 1, 1]), Shape: torch.Size([858])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([170])\n",
      "##########################bert-base-multilingual-cased---bert####################\n",
      "Epoch 1, Loss: 0.19665060920157917\n",
      "Epoch 2, Loss: 0.02750562941353699\n",
      "Epoch 3, Loss: 0.008189697905133167\n",
      "Epoch 4, Loss: 0.009999636923937403\n",
      "Epoch 5, Loss: 0.0006126445169448507\n",
      "Epoch 6, Loss: 0.0003989968902681506\n",
      "all_preds shape: (170,)\n",
      "all_labels shape: (170,)\n",
      "all_probs shape: (170, 2)\n",
      "Train labels sample: tensor([1, 1, 0, 0, 0]), Shape: torch.Size([858])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([187])\n",
      "##########################bert-base-multilingual-cased---bert####################\n",
      "Epoch 1, Loss: 0.13738453832317005\n",
      "Epoch 2, Loss: 0.013191661101127803\n",
      "Epoch 3, Loss: 0.0014795043421650513\n",
      "Epoch 4, Loss: 0.0006107544667665261\n",
      "Epoch 5, Loss: 0.0003992232129719384\n",
      "Epoch 6, Loss: 0.0002924561922554858\n",
      "all_preds shape: (187,)\n",
      "all_labels shape: (187,)\n",
      "all_probs shape: (187, 2)\n",
      "train_6.без слов функциональных.txt.csv\n",
      "test_6.без слов функциональных.txt.csv\n",
      "Train labels sample: tensor([0, 1, 1, 1, 1]), Shape: torch.Size([922])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([182])\n",
      "##########################bert-base-multilingual-cased---bert####################\n",
      "Epoch 1, Loss: 0.1332156995054463\n",
      "Epoch 2, Loss: 0.02113953798182373\n",
      "Epoch 3, Loss: 0.00911568963683435\n",
      "Epoch 4, Loss: 0.008277430541307569\n",
      "Epoch 5, Loss: 0.0005289165058237469\n",
      "Epoch 6, Loss: 0.027318095575600606\n",
      "all_preds shape: (182,)\n",
      "all_labels shape: (182,)\n",
      "all_probs shape: (182, 2)\n",
      "Train labels sample: tensor([0, 1, 0, 1, 0]), Shape: torch.Size([922])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([177])\n",
      "##########################bert-base-multilingual-cased---bert####################\n",
      "Epoch 1, Loss: 0.13327034423930634\n",
      "Epoch 2, Loss: 0.02940419563975442\n",
      "Epoch 3, Loss: 0.008779677242273465\n",
      "Epoch 4, Loss: 0.0008514910240874401\n",
      "Epoch 5, Loss: 0.0003427684129966455\n",
      "Epoch 6, Loss: 0.00025412734173406877\n",
      "all_preds shape: (177,)\n",
      "all_labels shape: (177,)\n",
      "all_probs shape: (177, 2)\n",
      "Train labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([922])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([183])\n",
      "##########################bert-base-multilingual-cased---bert####################\n",
      "Epoch 1, Loss: 0.1374763681489075\n",
      "Epoch 2, Loss: 0.09054944867364548\n",
      "Epoch 3, Loss: 0.1307100584441475\n",
      "Epoch 4, Loss: 0.024603471432908856\n",
      "Epoch 5, Loss: 0.009788759796406496\n",
      "Epoch 6, Loss: 0.0015386717578653119\n",
      "all_preds shape: (183,)\n",
      "all_labels shape: (183,)\n",
      "all_probs shape: (183, 2)\n",
      "Train labels sample: tensor([1, 0, 0, 0, 0]), Shape: torch.Size([922])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([179])\n",
      "##########################bert-base-multilingual-cased---bert####################\n",
      "Epoch 1, Loss: 0.13335752199757203\n",
      "Epoch 2, Loss: 0.03218315825757474\n",
      "Epoch 3, Loss: 0.0010428575824962222\n",
      "Epoch 4, Loss: 0.0005055000139440506\n",
      "Epoch 5, Loss: 0.0003355784963410958\n",
      "Epoch 6, Loss: 0.00025469548413168704\n",
      "all_preds shape: (179,)\n",
      "all_labels shape: (179,)\n",
      "all_probs shape: (179, 2)\n",
      "Train labels sample: tensor([0, 1, 0, 0, 1]), Shape: torch.Size([922])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([177])\n",
      "##########################bert-base-multilingual-cased---bert####################\n",
      "Epoch 1, Loss: 0.15525312402992156\n",
      "Epoch 2, Loss: 0.04302709864187536\n",
      "Epoch 3, Loss: 0.04193951370764588\n",
      "Epoch 4, Loss: 0.0023560025167233987\n",
      "Epoch 5, Loss: 0.01535339286432457\n",
      "Epoch 6, Loss: 0.007554852403198561\n",
      "all_preds shape: (177,)\n",
      "all_labels shape: (177,)\n",
      "all_probs shape: (177, 2)\n",
      "Train labels sample: tensor([1, 1, 1, 0, 1]), Shape: torch.Size([922])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([179])\n",
      "##########################bert-base-multilingual-cased---bert####################\n",
      "Epoch 1, Loss: 0.14859418787768688\n",
      "Epoch 2, Loss: 0.03912727855515249\n",
      "Epoch 3, Loss: 0.025436138477304887\n",
      "Epoch 4, Loss: 0.001409071594966447\n",
      "Epoch 5, Loss: 0.03151326265651733\n",
      "Epoch 6, Loss: 0.012731843693222016\n",
      "all_preds shape: (179,)\n",
      "all_labels shape: (179,)\n",
      "all_probs shape: (179, 2)\n",
      "train_Изъяты лексемы с частотой выше 100.csv\n",
      "test_Изъяты лексемы с частотой выше 100.csv\n",
      "Train labels sample: tensor([1, 1, 1, 0, 0]), Shape: torch.Size([871])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([190])\n",
      "##########################distilbert-base-multilingual-cased---bert####################\n",
      "Epoch 1, Loss: 0.6915189629251307\n",
      "Epoch 2, Loss: 0.6699216479604895\n",
      "Epoch 3, Loss: 0.5544146088036623\n",
      "Epoch 4, Loss: 0.21503251371058552\n",
      "Epoch 5, Loss: 0.09680828438140451\n",
      "Epoch 6, Loss: 0.03775701184587722\n",
      "all_preds shape: (190,)\n",
      "all_labels shape: (190,)\n",
      "all_probs shape: (190, 2)\n",
      "Train labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([871])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([192])\n",
      "##########################distilbert-base-multilingual-cased---bert####################\n",
      "Epoch 1, Loss: 0.6992646710439162\n",
      "Epoch 2, Loss: 0.6880718643015081\n",
      "Epoch 3, Loss: 0.6369028915058482\n",
      "Epoch 4, Loss: 0.30887421088462524\n",
      "Epoch 5, Loss: 0.19845714897594668\n",
      "Epoch 6, Loss: 0.14754793374714525\n",
      "all_preds shape: (192,)\n",
      "all_labels shape: (192,)\n",
      "all_probs shape: (192, 2)\n",
      "Train labels sample: tensor([0, 0, 1, 1, 1]), Shape: torch.Size([871])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([190])\n",
      "##########################distilbert-base-multilingual-cased---bert####################\n",
      "Epoch 1, Loss: 0.7195826839316976\n",
      "Epoch 2, Loss: 0.6667111862789501\n",
      "Epoch 3, Loss: 0.6830004610798576\n",
      "Epoch 4, Loss: 0.676432565125552\n",
      "Epoch 5, Loss: 0.6768464565277099\n",
      "Epoch 6, Loss: 0.6717487535693428\n",
      "all_preds shape: (190,)\n",
      "all_labels shape: (190,)\n",
      "all_probs shape: (190, 2)\n",
      "Train labels sample: tensor([1, 1, 1, 0, 1]), Shape: torch.Size([871])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([200])\n",
      "##########################distilbert-base-multilingual-cased---bert####################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.7310380805622447\n",
      "Epoch 2, Loss: 0.6726383577693592\n",
      "Epoch 3, Loss: 0.6489462131803686\n",
      "Epoch 4, Loss: 0.6502423405647277\n",
      "Epoch 5, Loss: 0.6972581045194106\n",
      "Epoch 6, Loss: 0.6702541790225289\n",
      "all_preds shape: (200,)\n",
      "all_labels shape: (200,)\n",
      "all_probs shape: (200, 2)\n",
      "Train labels sample: tensor([0, 0, 0, 0, 1]), Shape: torch.Size([871])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([189])\n",
      "##########################distilbert-base-multilingual-cased---bert####################\n",
      "Epoch 1, Loss: 0.7364589523185383\n",
      "Epoch 2, Loss: 0.6736237731846896\n",
      "Epoch 3, Loss: 0.6712869969281283\n",
      "Epoch 4, Loss: 0.6776438718492335\n",
      "Epoch 5, Loss: 0.6763587799939242\n",
      "Epoch 6, Loss: 0.6290424392981963\n",
      "all_preds shape: (189,)\n",
      "all_labels shape: (189,)\n",
      "all_probs shape: (189, 2)\n",
      "Train labels sample: tensor([0, 0, 0, 0, 1]), Shape: torch.Size([871])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([191])\n",
      "##########################distilbert-base-multilingual-cased---bert####################\n",
      "Epoch 1, Loss: 0.710695353421298\n",
      "Epoch 2, Loss: 0.6913637898185037\n",
      "Epoch 3, Loss: 0.44200412278825585\n",
      "Epoch 4, Loss: 0.27741086333990095\n",
      "Epoch 5, Loss: 0.3593869641423225\n",
      "Epoch 6, Loss: 0.34322895895351063\n",
      "all_preds shape: (191,)\n",
      "all_labels shape: (191,)\n",
      "all_probs shape: (191, 2)\n",
      "train_Изъяты лексемы с частотой выше 49.csv\n",
      "test_Изъяты лексемы с частотой выше 49.csv\n",
      "Train labels sample: tensor([0, 1, 1, 0, 1]), Shape: torch.Size([900])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([176])\n",
      "##########################distilbert-base-multilingual-cased---bert####################\n",
      "Epoch 1, Loss: 0.6930964301552689\n",
      "Epoch 2, Loss: 0.6660957911558318\n",
      "Epoch 3, Loss: 0.5034878018655276\n",
      "Epoch 4, Loss: 0.16292250496253632\n",
      "Epoch 5, Loss: 0.0704327789625447\n",
      "Epoch 6, Loss: 0.027228148494798102\n",
      "all_preds shape: (176,)\n",
      "all_labels shape: (176,)\n",
      "all_probs shape: (176, 2)\n",
      "Train labels sample: tensor([1, 1, 0, 0, 1]), Shape: torch.Size([900])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([180])\n",
      "##########################distilbert-base-multilingual-cased---bert####################\n",
      "Epoch 1, Loss: 0.7208839657536724\n",
      "Epoch 2, Loss: 0.671241780644969\n",
      "Epoch 3, Loss: 0.6596986421367579\n",
      "Epoch 4, Loss: 0.5283629072078487\n",
      "Epoch 5, Loss: 0.33442360345731703\n",
      "Epoch 6, Loss: 0.32902239812047857\n",
      "all_preds shape: (180,)\n",
      "all_labels shape: (180,)\n",
      "all_probs shape: (180, 2)\n",
      "Train labels sample: tensor([1, 1, 1, 0, 0]), Shape: torch.Size([900])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([184])\n",
      "##########################distilbert-base-multilingual-cased---bert####################\n",
      "Epoch 1, Loss: 0.683371176845149\n",
      "Epoch 2, Loss: 0.5620879316539095\n",
      "Epoch 3, Loss: 0.2549544046714641\n",
      "Epoch 4, Loss: 0.13997008097603134\n",
      "Epoch 5, Loss: 0.06760283154966473\n",
      "Epoch 6, Loss: 0.03108462756254563\n",
      "all_preds shape: (184,)\n",
      "all_labels shape: (184,)\n",
      "all_probs shape: (184, 2)\n",
      "Train labels sample: tensor([1, 0, 1, 0, 0]), Shape: torch.Size([900])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([191])\n",
      "##########################distilbert-base-multilingual-cased---bert####################\n",
      "Epoch 1, Loss: 0.7195583398927722\n",
      "Epoch 2, Loss: 0.6718943908549192\n",
      "Epoch 3, Loss: 0.6636724210622018\n",
      "Epoch 4, Loss: 0.6248926823599297\n",
      "Epoch 5, Loss: 0.6632421194461354\n",
      "Epoch 6, Loss: 0.6695941331093771\n",
      "all_preds shape: (191,)\n",
      "all_labels shape: (191,)\n",
      "all_probs shape: (191, 2)\n",
      "Train labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([900])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([200])\n",
      "##########################distilbert-base-multilingual-cased---bert####################\n",
      "Epoch 1, Loss: 0.675324959713116\n",
      "Epoch 2, Loss: 0.5821417536129031\n",
      "Epoch 3, Loss: 0.33100814411514684\n",
      "Epoch 4, Loss: 0.29498761853105143\n",
      "Epoch 5, Loss: 0.18852724775410534\n",
      "Epoch 6, Loss: 0.03830117437776113\n",
      "all_preds shape: (200,)\n",
      "all_labels shape: (200,)\n",
      "all_probs shape: (200, 2)\n",
      "Train labels sample: tensor([1, 0, 0, 0, 0]), Shape: torch.Size([900])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([196])\n",
      "##########################distilbert-base-multilingual-cased---bert####################\n",
      "Epoch 1, Loss: 0.716635779330605\n",
      "Epoch 2, Loss: 0.6585791220790461\n",
      "Epoch 3, Loss: 0.6569790474155492\n",
      "Epoch 4, Loss: 0.6731894230633452\n",
      "Epoch 5, Loss: 0.4826934043514101\n",
      "Epoch 6, Loss: 0.31954256066104825\n",
      "all_preds shape: (196,)\n",
      "all_labels shape: (196,)\n",
      "all_probs shape: (196, 2)\n",
      "train_Изъяты лексемы с частотой выше 29.csv\n",
      "test_Изъяты лексемы с частотой выше 29.csv\n",
      "Train labels sample: tensor([0, 0, 1, 0, 0]), Shape: torch.Size([887])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([197])\n",
      "##########################distilbert-base-multilingual-cased---bert####################\n",
      "Epoch 1, Loss: 0.6856640518776008\n",
      "Epoch 2, Loss: 0.6403009008084025\n",
      "Epoch 3, Loss: 0.4874461571952062\n",
      "Epoch 4, Loss: 0.3419045912367957\n",
      "Epoch 5, Loss: 0.3430042498345886\n",
      "Epoch 6, Loss: 0.3245097856436457\n",
      "all_preds shape: (197,)\n",
      "all_labels shape: (197,)\n",
      "all_probs shape: (197, 2)\n",
      "Train labels sample: tensor([0, 0, 0, 1, 0]), Shape: torch.Size([887])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([191])\n",
      "##########################distilbert-base-multilingual-cased---bert####################\n",
      "Epoch 1, Loss: 0.6908214496714729\n",
      "Epoch 2, Loss: 0.6601978151925972\n",
      "Epoch 3, Loss: 0.6483789889940194\n",
      "Epoch 4, Loss: 0.6159813691462789\n",
      "Epoch 5, Loss: 0.35588355229369234\n",
      "Epoch 6, Loss: 0.2837393607145974\n",
      "all_preds shape: (191,)\n",
      "all_labels shape: (191,)\n",
      "all_probs shape: (191, 2)\n",
      "Train labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([887])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([201])\n",
      "##########################distilbert-base-multilingual-cased---bert####################\n",
      "Epoch 1, Loss: 0.6857407614588737\n",
      "Epoch 2, Loss: 0.654425365052053\n",
      "Epoch 3, Loss: 0.3936153756720679\n",
      "Epoch 4, Loss: 0.11146440363622137\n",
      "Epoch 5, Loss: 0.0455858779418382\n",
      "Epoch 6, Loss: 0.057974446939104904\n",
      "all_preds shape: (201,)\n",
      "all_labels shape: (201,)\n",
      "all_probs shape: (201, 2)\n",
      "Train labels sample: tensor([0, 1, 0, 0, 0]), Shape: torch.Size([887])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([189])\n",
      "##########################distilbert-base-multilingual-cased---bert####################\n",
      "Epoch 1, Loss: 0.6838919690677098\n",
      "Epoch 2, Loss: 0.6499879152647087\n",
      "Epoch 3, Loss: 0.6789877813841615\n",
      "Epoch 4, Loss: 0.5407144115971667\n",
      "Epoch 5, Loss: 0.15796572583661014\n",
      "Epoch 6, Loss: 0.06237240960555417\n",
      "all_preds shape: (189,)\n",
      "all_labels shape: (189,)\n",
      "all_probs shape: (189, 2)\n",
      "Train labels sample: tensor([0, 1, 0, 0, 0]), Shape: torch.Size([887])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([204])\n",
      "##########################distilbert-base-multilingual-cased---bert####################\n",
      "Epoch 1, Loss: 0.697046941944531\n",
      "Epoch 2, Loss: 0.6430275716951915\n",
      "Epoch 3, Loss: 0.6497710011899471\n",
      "Epoch 4, Loss: 0.6223933193832636\n",
      "Epoch 5, Loss: 0.6357744092653904\n",
      "Epoch 6, Loss: 0.6469604223966599\n",
      "all_preds shape: (204,)\n",
      "all_labels shape: (204,)\n",
      "all_probs shape: (204, 2)\n",
      "Train labels sample: tensor([1, 1, 1, 0, 0]), Shape: torch.Size([887])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([188])\n",
      "##########################distilbert-base-multilingual-cased---bert####################\n",
      "Epoch 1, Loss: 0.67115122665252\n",
      "Epoch 2, Loss: 0.671699301472732\n",
      "Epoch 3, Loss: 0.4122965708374977\n",
      "Epoch 4, Loss: 0.37386660490717205\n",
      "Epoch 5, Loss: 0.3569854587050421\n",
      "Epoch 6, Loss: 0.3428304788789579\n",
      "all_preds shape: (188,)\n",
      "all_labels shape: (188,)\n",
      "all_probs shape: (188, 2)\n",
      "train_Изъяты лексемы с частотой выше 9.csv\n",
      "test_Изъяты лексемы с частотой выше 9.csv\n",
      "Train labels sample: tensor([0, 0, 0, 0, 1]), Shape: torch.Size([766])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([350])\n",
      "##########################distilbert-base-multilingual-cased---bert####################\n",
      "Epoch 1, Loss: 0.7250087683399519\n",
      "Epoch 2, Loss: 0.6549934446811676\n",
      "Epoch 3, Loss: 0.6075754016637802\n",
      "Epoch 4, Loss: 0.4676560287674268\n",
      "all_preds shape: (350,)\n",
      "all_labels shape: (350,)\n",
      "all_probs shape: (350, 2)\n",
      "Train labels sample: tensor([0, 1, 0, 1, 1]), Shape: torch.Size([766])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([343])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##########################distilbert-base-multilingual-cased---bert####################\n",
      "Epoch 1, Loss: 0.6919596468408903\n",
      "Epoch 2, Loss: 0.6479602431257566\n",
      "Epoch 3, Loss: 0.48217381288607913\n",
      "Epoch 4, Loss: 0.3518905902747065\n",
      "all_preds shape: (343,)\n",
      "all_labels shape: (343,)\n",
      "all_probs shape: (343, 2)\n",
      "Train labels sample: tensor([1, 1, 0, 0, 0]), Shape: torch.Size([766])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([259])\n",
      "##########################distilbert-base-multilingual-cased---bert####################\n",
      "Epoch 1, Loss: 0.6705007056395212\n",
      "Epoch 2, Loss: 0.5856146762768427\n",
      "Epoch 3, Loss: 0.4607573424776395\n",
      "Epoch 4, Loss: 0.33634144129852456\n",
      "all_preds shape: (259,)\n",
      "all_labels shape: (259,)\n",
      "all_probs shape: (259, 2)\n",
      "Train labels sample: tensor([1, 0, 1, 0, 1]), Shape: torch.Size([766])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([274])\n",
      "##########################distilbert-base-multilingual-cased---bert####################\n",
      "Epoch 1, Loss: 0.6919119395315647\n",
      "Epoch 2, Loss: 0.6194683387875557\n",
      "Epoch 3, Loss: 0.47271804076929885\n",
      "Epoch 4, Loss: 0.3036939278244972\n",
      "all_preds shape: (274,)\n",
      "all_labels shape: (274,)\n",
      "all_probs shape: (274, 2)\n",
      "Train labels sample: tensor([0, 0, 0, 0, 1]), Shape: torch.Size([766])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([261])\n",
      "##########################distilbert-base-multilingual-cased---bert####################\n",
      "Epoch 1, Loss: 0.7116320878267288\n",
      "Epoch 2, Loss: 0.6462342490752538\n",
      "Epoch 3, Loss: 0.5077506843954325\n",
      "Epoch 4, Loss: 0.2982681716481845\n",
      "all_preds shape: (261,)\n",
      "all_labels shape: (261,)\n",
      "all_probs shape: (261, 2)\n",
      "Train labels sample: tensor([0, 0, 0, 0, 1]), Shape: torch.Size([766])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([264])\n",
      "##########################distilbert-base-multilingual-cased---bert####################\n",
      "Epoch 1, Loss: 0.7083421076337496\n",
      "Epoch 2, Loss: 0.6441958770155907\n",
      "Epoch 3, Loss: 0.48988110696276027\n",
      "Epoch 4, Loss: 0.3539999198789398\n",
      "all_preds shape: (264,)\n",
      "all_labels shape: (264,)\n",
      "all_probs shape: (264, 2)\n",
      "train_Изъяты лексемы с частотой выше 5.csv\n",
      "test_Изъяты лексемы с частотой выше 5.csv\n",
      "Train labels sample: tensor([0, 0, 1, 0, 0]), Shape: torch.Size([96])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([528])\n",
      "##########################distilbert-base-multilingual-cased---bert####################\n",
      "Epoch 1, Loss: 0.8187201172113419\n",
      "Epoch 2, Loss: 0.5768818557262421\n",
      "Epoch 3, Loss: 0.579841802517573\n",
      "Epoch 4, Loss: 0.6137574861447016\n",
      "Epoch 5, Loss: 0.5629774332046509\n",
      "Epoch 6, Loss: 0.5551439026991526\n",
      "all_preds shape: (528,)\n",
      "all_labels shape: (528,)\n",
      "all_probs shape: (528, 2)\n",
      "Train labels sample: tensor([1, 0, 0, 1, 1]), Shape: torch.Size([96])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([507])\n",
      "##########################distilbert-base-multilingual-cased---bert####################\n",
      "Epoch 1, Loss: 0.7099832048018774\n",
      "Epoch 2, Loss: 0.5925471584002177\n",
      "Epoch 3, Loss: 0.5117195397615433\n",
      "Epoch 4, Loss: 0.5164746840794882\n",
      "Epoch 5, Loss: 0.5454481840133667\n",
      "Epoch 6, Loss: 0.4961111346880595\n",
      "all_preds shape: (507,)\n",
      "all_labels shape: (507,)\n",
      "all_probs shape: (507, 2)\n",
      "Train labels sample: tensor([0, 0, 0, 1, 1]), Shape: torch.Size([96])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([513])\n",
      "##########################distilbert-base-multilingual-cased---bert####################\n",
      "Epoch 1, Loss: 0.8547002772490183\n",
      "Epoch 2, Loss: 0.706156055132548\n",
      "Epoch 3, Loss: 0.6883099377155304\n",
      "Epoch 4, Loss: 0.6006129185358683\n",
      "Epoch 5, Loss: 0.6090273608764013\n",
      "Epoch 6, Loss: 0.6144838929176331\n",
      "all_preds shape: (513,)\n",
      "all_labels shape: (513,)\n",
      "all_probs shape: (513, 2)\n",
      "Train labels sample: tensor([0, 0, 0, 1, 0]), Shape: torch.Size([96])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([576])\n",
      "##########################distilbert-base-multilingual-cased---bert####################\n",
      "Epoch 1, Loss: 0.6001568585634232\n",
      "Epoch 2, Loss: 0.5631852721174558\n",
      "Epoch 3, Loss: 0.5552133470773697\n",
      "Epoch 4, Loss: 0.5368624627590179\n",
      "Epoch 5, Loss: 0.5128334611654282\n",
      "Epoch 6, Loss: 0.5302148660024008\n",
      "all_preds shape: (576,)\n",
      "all_labels shape: (576,)\n",
      "all_probs shape: (576, 2)\n",
      "Train labels sample: tensor([0, 0, 0, 0, 1]), Shape: torch.Size([96])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([491])\n",
      "##########################distilbert-base-multilingual-cased---bert####################\n",
      "Epoch 1, Loss: 0.6355783591667811\n",
      "Epoch 2, Loss: 0.6644522845745087\n",
      "Epoch 3, Loss: 0.6095551252365112\n",
      "Epoch 4, Loss: 0.6179212828477224\n",
      "Epoch 5, Loss: 0.5787299424409866\n",
      "Epoch 6, Loss: 0.5815698504447937\n",
      "all_preds shape: (491,)\n",
      "all_labels shape: (491,)\n",
      "all_probs shape: (491, 2)\n",
      "Train labels sample: tensor([0, 0, 0, 1, 0]), Shape: torch.Size([96])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([456])\n",
      "##########################distilbert-base-multilingual-cased---bert####################\n",
      "Epoch 1, Loss: 0.9511480927467346\n",
      "Epoch 2, Loss: 0.6253163814544678\n",
      "Epoch 3, Loss: 0.6208968808253607\n",
      "Epoch 4, Loss: 0.6063225070635477\n",
      "Epoch 5, Loss: 0.607589840888977\n",
      "Epoch 6, Loss: 0.6310249169667562\n",
      "all_preds shape: (456,)\n",
      "all_labels shape: (456,)\n",
      "all_probs shape: (456, 2)\n",
      "train_Изъяты лексемы с частотой выше 3.csv\n",
      "test_Изъяты лексемы с частотой выше 3.csv\n",
      "Train labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([90])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([700])\n",
      "##########################distilbert-base-multilingual-cased---bert####################\n",
      "Epoch 1, Loss: 0.7700301309426626\n",
      "Epoch 2, Loss: 0.7489319245020548\n",
      "Epoch 3, Loss: 0.5607372671365738\n",
      "Epoch 4, Loss: 0.539681002497673\n",
      "Epoch 5, Loss: 0.5436507562796274\n",
      "Epoch 6, Loss: 0.527255117893219\n",
      "all_preds shape: (700,)\n",
      "all_labels shape: (700,)\n",
      "all_probs shape: (700, 2)\n",
      "Train labels sample: tensor([0, 1, 0, 0, 0]), Shape: torch.Size([90])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([732])\n",
      "##########################distilbert-base-multilingual-cased---bert####################\n",
      "Epoch 1, Loss: 0.5894714097181956\n",
      "Epoch 2, Loss: 0.5365230590105057\n",
      "Epoch 3, Loss: 0.5454661597808202\n",
      "Epoch 4, Loss: 0.4975168506304423\n",
      "Epoch 5, Loss: 0.5072778215010961\n",
      "Epoch 6, Loss: 0.4977049082517624\n",
      "all_preds shape: (732,)\n",
      "all_labels shape: (732,)\n",
      "all_probs shape: (732, 2)\n",
      "Train labels sample: tensor([1, 1, 0, 0, 0]), Shape: torch.Size([90])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([739])\n",
      "##########################distilbert-base-multilingual-cased---bert####################\n",
      "Epoch 1, Loss: 0.6456686158974966\n",
      "Epoch 2, Loss: 0.6048138439655304\n",
      "Epoch 3, Loss: 0.6383374035358429\n",
      "Epoch 4, Loss: 0.5954040884971619\n",
      "Epoch 5, Loss: 0.5834068655967712\n",
      "Epoch 6, Loss: 0.5187372316916784\n",
      "all_preds shape: (739,)\n",
      "all_labels shape: (739,)\n",
      "all_probs shape: (739, 2)\n",
      "Train labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([90])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([720])\n",
      "##########################distilbert-base-multilingual-cased---bert####################\n",
      "Epoch 1, Loss: 0.7929919958114624\n",
      "Epoch 2, Loss: 0.5010006676117579\n",
      "Epoch 3, Loss: 0.5099531908830007\n",
      "Epoch 4, Loss: 0.5206814805666605\n",
      "Epoch 5, Loss: 0.49136247237523395\n",
      "Epoch 6, Loss: 0.49475044508775073\n",
      "all_preds shape: (720,)\n",
      "all_labels shape: (720,)\n",
      "all_probs shape: (720, 2)\n",
      "Train labels sample: tensor([0, 0, 1, 0, 0]), Shape: torch.Size([90])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([715])\n",
      "##########################distilbert-base-multilingual-cased---bert####################\n",
      "Epoch 1, Loss: 0.6976541429758072\n",
      "Epoch 2, Loss: 0.6635757138331732\n",
      "Epoch 3, Loss: 0.6413034896055857\n",
      "Epoch 4, Loss: 0.5698171555995941\n",
      "Epoch 5, Loss: 0.5711771845817566\n",
      "Epoch 6, Loss: 0.5601929575204849\n",
      "all_preds shape: (715,)\n",
      "all_labels shape: (715,)\n",
      "all_probs shape: (715, 2)\n",
      "Train labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([90])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([691])\n",
      "##########################distilbert-base-multilingual-cased---bert####################\n",
      "Epoch 1, Loss: 0.8660176893075308\n",
      "Epoch 2, Loss: 0.5402687328557173\n",
      "Epoch 3, Loss: 0.5730711966753006\n",
      "Epoch 4, Loss: 0.5773320843776067\n",
      "Epoch 5, Loss: 0.6089138090610504\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Loss: 0.546919564406077\n",
      "all_preds shape: (691,)\n",
      "all_labels shape: (691,)\n",
      "all_probs shape: (691, 2)\n",
      "train_Без прилагательных первый-второй жанр.csv\n",
      "test_Без прилагательных первый-второй жанр.csv\n",
      "Train labels sample: tensor([1, 1, 0, 0, 0]), Shape: torch.Size([846])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([193])\n",
      "##########################distilbert-base-multilingual-cased---bert####################\n",
      "Epoch 1, Loss: 0.6314993379292665\n",
      "Epoch 2, Loss: 0.40989771568112904\n",
      "Epoch 3, Loss: 0.1521568557040559\n",
      "Epoch 4, Loss: 0.11062968656834629\n",
      "all_preds shape: (193,)\n",
      "all_labels shape: (193,)\n",
      "all_probs shape: (193, 2)\n",
      "Train labels sample: tensor([0, 0, 1, 1, 0]), Shape: torch.Size([846])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([171])\n",
      "##########################distilbert-base-multilingual-cased---bert####################\n",
      "Epoch 1, Loss: 0.7990227098818179\n",
      "Epoch 2, Loss: 0.6722382373279996\n",
      "Epoch 3, Loss: 0.6218731116365503\n",
      "Epoch 4, Loss: 0.3712526907523473\n",
      "all_preds shape: (171,)\n",
      "all_labels shape: (171,)\n",
      "all_probs shape: (171, 2)\n",
      "Train labels sample: tensor([0, 1, 1, 0, 0]), Shape: torch.Size([846])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([183])\n",
      "##########################distilbert-base-multilingual-cased---bert####################\n",
      "Epoch 1, Loss: 0.627666856403704\n",
      "Epoch 2, Loss: 0.4191480306563554\n",
      "Epoch 3, Loss: 0.15135038575088536\n",
      "Epoch 4, Loss: 0.06212662460489406\n",
      "all_preds shape: (183,)\n",
      "all_labels shape: (183,)\n",
      "all_probs shape: (183, 2)\n",
      "Train labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([846])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([178])\n",
      "##########################distilbert-base-multilingual-cased---bert####################\n",
      "Epoch 1, Loss: 0.7123663557900323\n",
      "Epoch 2, Loss: 0.5878358726148252\n",
      "Epoch 3, Loss: 0.2776415048650018\n",
      "Epoch 4, Loss: 0.10866663532538547\n",
      "all_preds shape: (178,)\n",
      "all_labels shape: (178,)\n",
      "all_probs shape: (178, 2)\n",
      "Train labels sample: tensor([0, 0, 0, 0, 1]), Shape: torch.Size([846])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([173])\n",
      "##########################distilbert-base-multilingual-cased---bert####################\n",
      "Epoch 1, Loss: 0.7010830839474996\n",
      "Epoch 2, Loss: 0.515014652300764\n",
      "Epoch 3, Loss: 0.26247032331647696\n",
      "Epoch 4, Loss: 0.10262788666619195\n",
      "all_preds shape: (173,)\n",
      "all_labels shape: (173,)\n",
      "all_probs shape: (173, 2)\n",
      "Train labels sample: tensor([0, 1, 1, 1, 0]), Shape: torch.Size([846])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([171])\n",
      "##########################distilbert-base-multilingual-cased---bert####################\n",
      "Epoch 1, Loss: 0.7302788738851194\n",
      "Epoch 2, Loss: 0.6247419229260197\n",
      "Epoch 3, Loss: 0.41057561172379387\n",
      "Epoch 4, Loss: 0.1595100268928541\n",
      "all_preds shape: (171,)\n",
      "all_labels shape: (171,)\n",
      "all_probs shape: (171, 2)\n",
      "train_1.Первый жанр исходная выборка.csv\n",
      "test_1.Первый жанр исходная выборка.csv\n",
      "Train labels sample: tensor([1, 1, 1, 0, 0]), Shape: torch.Size([893])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([169])\n",
      "##########################distilbert-base-multilingual-cased---bert####################\n",
      "Epoch 1, Loss: 0.7430349577750478\n",
      "Epoch 2, Loss: 0.6787226301218782\n",
      "Epoch 3, Loss: 0.687946042312043\n",
      "Epoch 4, Loss: 0.681934792548418\n",
      "Epoch 5, Loss: 0.5125289370438882\n",
      "Epoch 6, Loss: 0.36086417149220196\n",
      "all_preds shape: (169,)\n",
      "all_labels shape: (169,)\n",
      "all_probs shape: (169, 2)\n",
      "Train labels sample: tensor([1, 0, 1, 0, 0]), Shape: torch.Size([893])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([164])\n",
      "##########################distilbert-base-multilingual-cased---bert####################\n",
      "Epoch 1, Loss: 0.7030398803097861\n",
      "Epoch 2, Loss: 0.6899076317037854\n",
      "Epoch 3, Loss: 0.36311051302722525\n",
      "Epoch 4, Loss: 0.11701287822298971\n",
      "Epoch 5, Loss: 0.06290038171989311\n",
      "Epoch 6, Loss: 0.07102270883374981\n",
      "all_preds shape: (164,)\n",
      "all_labels shape: (164,)\n",
      "all_probs shape: (164, 2)\n",
      "Train labels sample: tensor([1, 0, 1, 0, 0]), Shape: torch.Size([893])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([164])\n",
      "##########################distilbert-base-multilingual-cased---bert####################\n",
      "Epoch 1, Loss: 0.7165046515209335\n",
      "Epoch 2, Loss: 0.6770931615361145\n",
      "Epoch 3, Loss: 0.4928105026483536\n",
      "Epoch 4, Loss: 0.2631242601200938\n",
      "Epoch 5, Loss: 0.09246388737145546\n",
      "Epoch 6, Loss: 0.036017613826386095\n",
      "all_preds shape: (164,)\n",
      "all_labels shape: (164,)\n",
      "all_probs shape: (164, 2)\n",
      "Train labels sample: tensor([0, 0, 0, 1, 1]), Shape: torch.Size([893])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([169])\n",
      "##########################distilbert-base-multilingual-cased---bert####################\n",
      "Epoch 1, Loss: 0.6663375683128834\n",
      "Epoch 2, Loss: 0.3208768701713\n",
      "Epoch 3, Loss: 0.3524756736255118\n",
      "Epoch 4, Loss: 0.27634098868916873\n",
      "Epoch 5, Loss: 0.34120220025735243\n",
      "Epoch 6, Loss: 0.3153450504344489\n",
      "all_preds shape: (169,)\n",
      "all_labels shape: (169,)\n",
      "all_probs shape: (169, 2)\n",
      "Train labels sample: tensor([0, 0, 1, 0, 1]), Shape: torch.Size([893])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([158])\n",
      "##########################distilbert-base-multilingual-cased---bert####################\n",
      "Epoch 1, Loss: 0.7215231348361287\n",
      "Epoch 2, Loss: 0.6753668620118073\n",
      "Epoch 3, Loss: 0.44841071364602875\n",
      "Epoch 4, Loss: 0.3013587784121877\n",
      "Epoch 5, Loss: 0.11816300480027817\n",
      "Epoch 6, Loss: 0.12697265808570332\n",
      "all_preds shape: (158,)\n",
      "all_labels shape: (158,)\n",
      "all_probs shape: (158, 2)\n",
      "Train labels sample: tensor([1, 0, 0, 1, 0]), Shape: torch.Size([893])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([160])\n",
      "##########################distilbert-base-multilingual-cased---bert####################\n",
      "Epoch 1, Loss: 0.71485088127\n",
      "Epoch 2, Loss: 0.6673469692468643\n",
      "Epoch 3, Loss: 0.43335846944579054\n",
      "Epoch 4, Loss: 0.3566126880635108\n",
      "Epoch 5, Loss: 0.3466824126828994\n",
      "Epoch 6, Loss: 0.3486584990418383\n",
      "all_preds shape: (160,)\n",
      "all_labels shape: (160,)\n",
      "all_probs shape: (160, 2)\n",
      "train_2.Первый жанр без клауз, включающих наречия.csv\n",
      "test_2.Первый жанр без клауз, включающих наречия.csv\n",
      "Train labels sample: tensor([1, 1, 0, 0, 0]), Shape: torch.Size([880])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([169])\n",
      "##########################distilbert-base-multilingual-cased---bert####################\n",
      "Epoch 1, Loss: 0.6613185871731151\n",
      "Epoch 2, Loss: 0.2672842865809798\n",
      "Epoch 3, Loss: 0.26265371159057727\n",
      "Epoch 4, Loss: 0.33085482635281305\n",
      "Epoch 5, Loss: 0.15315054811706597\n",
      "Epoch 6, Loss: 0.17251563155176966\n",
      "all_preds shape: (169,)\n",
      "all_labels shape: (169,)\n",
      "all_probs shape: (169, 2)\n",
      "Train labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([880])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([163])\n",
      "##########################distilbert-base-multilingual-cased---bert####################\n",
      "Epoch 1, Loss: 0.7023855566978454\n",
      "Epoch 2, Loss: 0.4192353445020589\n",
      "Epoch 3, Loss: 0.2838019605133344\n",
      "Epoch 4, Loss: 0.1047606583388353\n",
      "Epoch 5, Loss: 0.10699303782629696\n",
      "Epoch 6, Loss: 0.07460584516891024\n",
      "all_preds shape: (163,)\n",
      "all_labels shape: (163,)\n",
      "all_probs shape: (163, 2)\n",
      "Train labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([880])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([173])\n",
      "##########################distilbert-base-multilingual-cased---bert####################\n",
      "Epoch 1, Loss: 0.7371443678032268\n",
      "Epoch 2, Loss: 0.6622514302080328\n",
      "Epoch 3, Loss: 0.3062751914797859\n",
      "Epoch 4, Loss: 0.661411542784084\n",
      "Epoch 5, Loss: 0.6762393084439364\n",
      "Epoch 6, Loss: 0.6831293268637224\n",
      "all_preds shape: (173,)\n",
      "all_labels shape: (173,)\n",
      "all_probs shape: (173, 2)\n",
      "Train labels sample: tensor([0, 1, 1, 1, 0]), Shape: torch.Size([880])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([168])\n",
      "##########################distilbert-base-multilingual-cased---bert####################\n",
      "Epoch 1, Loss: 0.7201346316120841\n",
      "Epoch 2, Loss: 0.6911491773345254\n",
      "Epoch 3, Loss: 0.604675986550071\n",
      "Epoch 4, Loss: 0.21423316614871676\n",
      "Epoch 5, Loss: 0.068678970601071\n",
      "Epoch 6, Loss: 0.03893997208638625\n",
      "all_preds shape: (168,)\n",
      "all_labels shape: (168,)\n",
      "all_probs shape: (168, 2)\n",
      "Train labels sample: tensor([1, 1, 0, 0, 0]), Shape: torch.Size([880])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([167])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##########################distilbert-base-multilingual-cased---bert####################\n",
      "Epoch 1, Loss: 0.7193352867256512\n",
      "Epoch 2, Loss: 0.6712603059681979\n",
      "Epoch 3, Loss: 0.6776172388683666\n",
      "Epoch 4, Loss: 0.6765077385035428\n",
      "Epoch 5, Loss: 0.425696587562561\n",
      "Epoch 6, Loss: 0.3471831906925548\n",
      "all_preds shape: (167,)\n",
      "all_labels shape: (167,)\n",
      "all_probs shape: (167, 2)\n",
      "Train labels sample: tensor([1, 0, 0, 1, 0]), Shape: torch.Size([880])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([180])\n",
      "##########################distilbert-base-multilingual-cased---bert####################\n",
      "Epoch 1, Loss: 0.7171259349042719\n",
      "Epoch 2, Loss: 0.6865696473555132\n",
      "Epoch 3, Loss: 0.6789821863174439\n",
      "Epoch 4, Loss: 0.6739152052185752\n",
      "Epoch 5, Loss: 0.43497487841682003\n",
      "Epoch 6, Loss: 0.11483573841608384\n",
      "all_preds shape: (180,)\n",
      "all_labels shape: (180,)\n",
      "all_probs shape: (180, 2)\n",
      "train_3.Первый жанр без клауз, включающих глаголы.csv\n",
      "test_3.Первый жанр без клауз, включающих глаголы.csv\n",
      "Train labels sample: tensor([1, 1, 1, 0, 1]), Shape: torch.Size([824])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([228])\n",
      "##########################distilbert-base-multilingual-cased---bert####################\n",
      "Epoch 1, Loss: 0.7241380684650861\n",
      "Epoch 2, Loss: 0.6725676036798037\n",
      "Epoch 3, Loss: 0.5609218214566891\n",
      "Epoch 4, Loss: 0.33502760300269496\n",
      "Epoch 5, Loss: 0.3469335845170113\n",
      "Epoch 6, Loss: 0.3757245456083463\n",
      "all_preds shape: (228,)\n",
      "all_labels shape: (228,)\n",
      "all_probs shape: (228, 2)\n",
      "Train labels sample: tensor([1, 0, 0, 1, 0]), Shape: torch.Size([824])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([219])\n",
      "##########################distilbert-base-multilingual-cased---bert####################\n",
      "Epoch 1, Loss: 0.7170548840210988\n",
      "Epoch 2, Loss: 0.6293824779299589\n",
      "Epoch 3, Loss: 0.3466492845103718\n",
      "Epoch 4, Loss: 0.2150474798399955\n",
      "Epoch 5, Loss: 0.08473458118700924\n",
      "Epoch 6, Loss: 0.047557911674420424\n",
      "all_preds shape: (219,)\n",
      "all_labels shape: (219,)\n",
      "all_probs shape: (219, 2)\n",
      "Train labels sample: tensor([0, 0, 0, 1, 0]), Shape: torch.Size([824])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([211])\n",
      "##########################distilbert-base-multilingual-cased---bert####################\n",
      "Epoch 1, Loss: 0.7613874971866608\n",
      "Epoch 2, Loss: 0.7123619713462316\n",
      "Epoch 3, Loss: 0.6935301583546859\n",
      "Epoch 4, Loss: 0.6827356609014364\n",
      "Epoch 5, Loss: 0.6836145222187042\n",
      "Epoch 6, Loss: 0.6856604654055375\n",
      "all_preds shape: (211,)\n",
      "all_labels shape: (211,)\n",
      "all_probs shape: (211, 2)\n",
      "Train labels sample: tensor([0, 0, 1, 0, 1]), Shape: torch.Size([824])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([220])\n",
      "##########################distilbert-base-multilingual-cased---bert####################\n",
      "Epoch 1, Loss: 0.7201813551095816\n",
      "Epoch 2, Loss: 0.646317950808085\n",
      "Epoch 3, Loss: 0.26227253428302133\n",
      "Epoch 4, Loss: 0.19565984699875116\n",
      "Epoch 5, Loss: 0.15781110737365311\n",
      "Epoch 6, Loss: 0.1237541258496304\n",
      "all_preds shape: (220,)\n",
      "all_labels shape: (220,)\n",
      "all_probs shape: (220, 2)\n",
      "Train labels sample: tensor([1, 0, 0, 0, 0]), Shape: torch.Size([824])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([216])\n",
      "##########################distilbert-base-multilingual-cased---bert####################\n",
      "Epoch 1, Loss: 0.7256767073502908\n",
      "Epoch 2, Loss: 0.4683324393386451\n",
      "Epoch 3, Loss: 0.23501226515509188\n",
      "Epoch 4, Loss: 0.06742871047194618\n",
      "Epoch 5, Loss: 0.15440104691347536\n",
      "Epoch 6, Loss: 0.02565113028797966\n",
      "all_preds shape: (216,)\n",
      "all_labels shape: (216,)\n",
      "all_probs shape: (216, 2)\n",
      "Train labels sample: tensor([1, 0, 1, 0, 1]), Shape: torch.Size([824])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([220])\n",
      "##########################distilbert-base-multilingual-cased---bert####################\n",
      "Epoch 1, Loss: 0.7378012927678915\n",
      "Epoch 2, Loss: 0.6969057355935757\n",
      "Epoch 3, Loss: 0.5339900963008404\n",
      "Epoch 4, Loss: 0.09654690634208517\n",
      "Epoch 5, Loss: 0.016629549296339974\n",
      "Epoch 6, Loss: 0.1928215833210673\n",
      "all_preds shape: (220,)\n",
      "all_labels shape: (220,)\n",
      "all_probs shape: (220, 2)\n",
      "train_4.Первый жанр без клауз, включающих глаголы и наречия.csv\n",
      "test_4.Первый жанр без клауз, включающих глаголы и наречия.csv\n",
      "Train labels sample: tensor([1, 1, 1, 0, 0]), Shape: torch.Size([805])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([239])\n",
      "##########################distilbert-base-multilingual-cased---bert####################\n",
      "Epoch 1, Loss: 0.7578073751692679\n",
      "Epoch 2, Loss: 0.6866667843332478\n",
      "Epoch 3, Loss: 0.6866330597914901\n",
      "Epoch 4, Loss: 0.6817593258969924\n",
      "Epoch 5, Loss: 0.41951945139204755\n",
      "Epoch 6, Loss: 0.3556477393881947\n",
      "all_preds shape: (239,)\n",
      "all_labels shape: (239,)\n",
      "all_probs shape: (239, 2)\n",
      "Train labels sample: tensor([1, 1, 0, 0, 1]), Shape: torch.Size([805])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([240])\n",
      "##########################distilbert-base-multilingual-cased---bert####################\n",
      "Epoch 1, Loss: 0.7530389509949029\n",
      "Epoch 2, Loss: 0.7014032987987294\n",
      "Epoch 3, Loss: 0.6967179074006922\n",
      "Epoch 4, Loss: 0.7004929792647269\n",
      "Epoch 5, Loss: 0.6887236588141498\n",
      "Epoch 6, Loss: 0.46216720313418147\n",
      "all_preds shape: (240,)\n",
      "all_labels shape: (240,)\n",
      "all_probs shape: (240, 2)\n",
      "Train labels sample: tensor([1, 0, 1, 0, 0]), Shape: torch.Size([805])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([248])\n",
      "##########################distilbert-base-multilingual-cased---bert####################\n",
      "Epoch 1, Loss: 0.6967932348157845\n",
      "Epoch 2, Loss: 0.4212851866933645\n",
      "Epoch 3, Loss: 0.10342454153350462\n",
      "Epoch 4, Loss: 0.11009148757119536\n",
      "Epoch 5, Loss: 0.03334579819028138\n",
      "Epoch 6, Loss: 0.024170602685497963\n",
      "all_preds shape: (248,)\n",
      "all_labels shape: (248,)\n",
      "all_probs shape: (248, 2)\n",
      "Train labels sample: tensor([1, 0, 1, 1, 0]), Shape: torch.Size([805])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([233])\n",
      "##########################distilbert-base-multilingual-cased---bert####################\n",
      "Epoch 1, Loss: 0.7452343451041802\n",
      "Epoch 2, Loss: 0.7016050020853678\n",
      "Epoch 3, Loss: 0.6589480176860211\n",
      "Epoch 4, Loss: 0.6818646242221197\n",
      "Epoch 5, Loss: 0.6914027531941732\n",
      "Epoch 6, Loss: 0.6951125217419044\n",
      "all_preds shape: (233,)\n",
      "all_labels shape: (233,)\n",
      "all_probs shape: (233, 2)\n",
      "Train labels sample: tensor([0, 0, 0, 1, 1]), Shape: torch.Size([805])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([233])\n",
      "##########################distilbert-base-multilingual-cased---bert####################\n",
      "Epoch 1, Loss: 0.7257534043461669\n",
      "Epoch 2, Loss: 0.6723258051217771\n",
      "Epoch 3, Loss: 0.46480388194322586\n",
      "Epoch 4, Loss: 0.26050425269732286\n",
      "Epoch 5, Loss: 0.15039696851197412\n",
      "Epoch 6, Loss: 0.11065807155169108\n",
      "all_preds shape: (233,)\n",
      "all_labels shape: (233,)\n",
      "all_probs shape: (233, 2)\n",
      "Train labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([805])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([236])\n",
      "##########################distilbert-base-multilingual-cased---bert####################\n",
      "Epoch 1, Loss: 0.7155153389070549\n",
      "Epoch 2, Loss: 0.5291008302101902\n",
      "Epoch 3, Loss: 0.2340371801937912\n",
      "Epoch 4, Loss: 0.22570592510130474\n",
      "Epoch 5, Loss: 0.41393960900056886\n",
      "Epoch 6, Loss: 0.33228493496483447\n",
      "all_preds shape: (236,)\n",
      "all_labels shape: (236,)\n",
      "all_probs shape: (236, 2)\n",
      "train_5.без клауз, включающих местоимения.txt.csv\n",
      "test_5.без клауз, включающих местоимения.txt.csv\n",
      "Train labels sample: tensor([0, 1, 0, 0, 1]), Shape: torch.Size([858])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([188])\n",
      "##########################distilbert-base-multilingual-cased---bert####################\n",
      "Epoch 1, Loss: 0.6191497411992815\n",
      "Epoch 2, Loss: 0.27792277304386653\n",
      "Epoch 3, Loss: 0.21727489740415304\n",
      "Epoch 4, Loss: 0.17340874482222177\n",
      "Epoch 5, Loss: 0.245602380398109\n",
      "Epoch 6, Loss: 0.13475273561629433\n",
      "all_preds shape: (188,)\n",
      "all_labels shape: (188,)\n",
      "all_probs shape: (188, 2)\n",
      "Train labels sample: tensor([1, 0, 0, 1, 1]), Shape: torch.Size([858])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([181])\n",
      "##########################distilbert-base-multilingual-cased---bert####################\n",
      "Epoch 1, Loss: 0.7315934868874373\n",
      "Epoch 2, Loss: 0.6813684304555258\n",
      "Epoch 3, Loss: 0.6665119639149418\n",
      "Epoch 4, Loss: 0.46434078903661835\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Loss: 0.3641974981184359\n",
      "Epoch 6, Loss: 0.35265219818662713\n",
      "all_preds shape: (181,)\n",
      "all_labels shape: (181,)\n",
      "all_probs shape: (181, 2)\n",
      "Train labels sample: tensor([1, 0, 0, 1, 0]), Shape: torch.Size([858])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([189])\n",
      "##########################distilbert-base-multilingual-cased---bert####################\n",
      "Epoch 1, Loss: 0.6323789164975837\n",
      "Epoch 2, Loss: 0.248795852297917\n",
      "Epoch 3, Loss: 0.13469804476739633\n",
      "Epoch 4, Loss: 0.08884060495808997\n",
      "Epoch 5, Loss: 0.05162642190784768\n",
      "Epoch 6, Loss: 0.03460912036071359\n",
      "all_preds shape: (189,)\n",
      "all_labels shape: (189,)\n",
      "all_probs shape: (189, 2)\n",
      "Train labels sample: tensor([0, 1, 0, 0, 0]), Shape: torch.Size([858])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([178])\n",
      "##########################distilbert-base-multilingual-cased---bert####################\n",
      "Epoch 1, Loss: 0.7141429031336749\n",
      "Epoch 2, Loss: 0.3868784810916555\n",
      "Epoch 3, Loss: 0.10757636948902574\n",
      "Epoch 4, Loss: 0.10166350816790429\n",
      "Epoch 5, Loss: 0.041704344416589094\n",
      "Epoch 6, Loss: 0.01759323713809459\n",
      "all_preds shape: (178,)\n",
      "all_labels shape: (178,)\n",
      "all_probs shape: (178, 2)\n",
      "Train labels sample: tensor([1, 1, 1, 1, 1]), Shape: torch.Size([858])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([170])\n",
      "##########################distilbert-base-multilingual-cased---bert####################\n",
      "Epoch 1, Loss: 0.7131606483900989\n",
      "Epoch 2, Loss: 0.628871997749364\n",
      "Epoch 3, Loss: 0.3325559315789077\n",
      "Epoch 4, Loss: 0.32282293305076937\n",
      "Epoch 5, Loss: 0.2201671606550614\n",
      "Epoch 6, Loss: 0.09680396436575663\n",
      "all_preds shape: (170,)\n",
      "all_labels shape: (170,)\n",
      "all_probs shape: (170, 2)\n",
      "Train labels sample: tensor([1, 1, 0, 0, 0]), Shape: torch.Size([858])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([187])\n",
      "##########################distilbert-base-multilingual-cased---bert####################\n",
      "Epoch 1, Loss: 0.733792675866021\n",
      "Epoch 2, Loss: 0.6850275640134458\n",
      "Epoch 3, Loss: 0.6750750376118554\n",
      "Epoch 4, Loss: 0.6827198697461022\n",
      "Epoch 5, Loss: 0.5135262182189358\n",
      "Epoch 6, Loss: 0.3577621794409222\n",
      "all_preds shape: (187,)\n",
      "all_labels shape: (187,)\n",
      "all_probs shape: (187, 2)\n",
      "train_6.без слов функциональных.txt.csv\n",
      "test_6.без слов функциональных.txt.csv\n",
      "Train labels sample: tensor([0, 1, 1, 1, 1]), Shape: torch.Size([922])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([182])\n",
      "##########################distilbert-base-multilingual-cased---bert####################\n",
      "Epoch 1, Loss: 0.716814676235462\n",
      "Epoch 2, Loss: 0.6708905152205763\n",
      "Epoch 3, Loss: 0.6712312374649376\n",
      "Epoch 4, Loss: 0.5910313979818903\n",
      "Epoch 5, Loss: 0.15092143028621272\n",
      "Epoch 6, Loss: 0.0732277318642571\n",
      "all_preds shape: (182,)\n",
      "all_labels shape: (182,)\n",
      "all_probs shape: (182, 2)\n",
      "Train labels sample: tensor([0, 1, 0, 1, 0]), Shape: torch.Size([922])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([177])\n",
      "##########################distilbert-base-multilingual-cased---bert####################\n",
      "Epoch 1, Loss: 0.6975048040521556\n",
      "Epoch 2, Loss: 0.6687179279738459\n",
      "Epoch 3, Loss: 0.6880052839887554\n",
      "Epoch 4, Loss: 0.4009997607690507\n",
      "Epoch 5, Loss: 0.34823858095654125\n",
      "Epoch 6, Loss: 0.347547576602163\n",
      "all_preds shape: (177,)\n",
      "all_labels shape: (177,)\n",
      "all_probs shape: (177, 2)\n",
      "Train labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([922])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([183])\n",
      "##########################distilbert-base-multilingual-cased---bert####################\n",
      "Epoch 1, Loss: 0.6796815523813511\n",
      "Epoch 2, Loss: 0.4428984459874959\n",
      "Epoch 3, Loss: 0.39897006384000694\n",
      "Epoch 4, Loss: 0.33434963566732817\n",
      "Epoch 5, Loss: 0.26878698966626463\n",
      "Epoch 6, Loss: 0.13167017241458184\n",
      "all_preds shape: (183,)\n",
      "all_labels shape: (183,)\n",
      "all_probs shape: (183, 2)\n",
      "Train labels sample: tensor([1, 0, 0, 0, 0]), Shape: torch.Size([922])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([179])\n",
      "##########################distilbert-base-multilingual-cased---bert####################\n",
      "Epoch 1, Loss: 0.7136827542864043\n",
      "Epoch 2, Loss: 0.6654108510962848\n",
      "Epoch 3, Loss: 0.642709387273624\n",
      "Epoch 4, Loss: 0.34948295576433686\n",
      "Epoch 5, Loss: 0.3321863180989849\n",
      "Epoch 6, Loss: 0.32825622868178217\n",
      "all_preds shape: (179,)\n",
      "all_labels shape: (179,)\n",
      "all_probs shape: (179, 2)\n",
      "Train labels sample: tensor([0, 1, 0, 0, 1]), Shape: torch.Size([922])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([177])\n",
      "##########################distilbert-base-multilingual-cased---bert####################\n",
      "Epoch 1, Loss: 0.7241328399756859\n",
      "Epoch 2, Loss: 0.6821137656425608\n",
      "Epoch 3, Loss: 0.45713295747429644\n",
      "Epoch 4, Loss: 0.12944758078083396\n",
      "Epoch 5, Loss: 0.04238347657193462\n",
      "Epoch 6, Loss: 0.050987949699227667\n",
      "all_preds shape: (177,)\n",
      "all_labels shape: (177,)\n",
      "all_probs shape: (177, 2)\n",
      "Train labels sample: tensor([1, 1, 1, 0, 1]), Shape: torch.Size([922])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([179])\n",
      "##########################distilbert-base-multilingual-cased---bert####################\n",
      "Epoch 1, Loss: 0.7167160469910194\n",
      "Epoch 2, Loss: 0.6014196374293032\n",
      "Epoch 3, Loss: 0.3389241859188368\n",
      "Epoch 4, Loss: 0.31296883150935173\n",
      "Epoch 5, Loss: 0.35104997905677765\n",
      "Epoch 6, Loss: 0.32659706344892236\n",
      "all_preds shape: (179,)\n",
      "all_labels shape: (179,)\n",
      "all_probs shape: (179, 2)\n",
      "train_Изъяты лексемы с частотой выше 100.csv\n",
      "test_Изъяты лексемы с частотой выше 100.csv\n",
      "Train labels sample: tensor([0, 0, 1, 0, 0]), Shape: torch.Size([887])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([200])\n",
      "##########################roberta-base---bert####################\n",
      "Epoch 1, Loss: 0.6922949110823018\n",
      "Epoch 2, Loss: 0.6648120539528983\n",
      "Epoch 3, Loss: 0.6661526965243476\n",
      "Epoch 4, Loss: 0.5999675478254046\n",
      "Epoch 5, Loss: 0.3511678003706038\n",
      "Epoch 6, Loss: 0.28147642547264695\n",
      "all_preds shape: (200,)\n",
      "all_labels shape: (200,)\n",
      "all_probs shape: (200, 2)\n",
      "Train labels sample: tensor([0, 0, 0, 1, 0]), Shape: torch.Size([887])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([203])\n",
      "##########################roberta-base---bert####################\n",
      "Epoch 1, Loss: 0.7044272023652282\n",
      "Epoch 2, Loss: 0.6794179646032197\n",
      "Epoch 3, Loss: 0.6734493582376412\n",
      "Epoch 4, Loss: 0.6712216048368386\n",
      "Epoch 5, Loss: 0.6955852210521698\n",
      "Epoch 6, Loss: 0.6699924394488335\n",
      "all_preds shape: (203,)\n",
      "all_labels shape: (203,)\n",
      "all_probs shape: (203, 2)\n",
      "Train labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([887])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([199])\n",
      "##########################roberta-base---bert####################\n",
      "Epoch 1, Loss: 0.707718760307346\n",
      "Epoch 2, Loss: 0.6713520155421325\n",
      "Epoch 3, Loss: 0.6903460605868271\n",
      "Epoch 4, Loss: 0.6684150291340691\n",
      "Epoch 5, Loss: 0.683566582522222\n",
      "Epoch 6, Loss: 0.666852131485939\n",
      "all_preds shape: (199,)\n",
      "all_labels shape: (199,)\n",
      "all_probs shape: (199, 2)\n",
      "Train labels sample: tensor([0, 1, 0, 0, 0]), Shape: torch.Size([887])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([194])\n",
      "##########################roberta-base---bert####################\n",
      "Epoch 1, Loss: 0.6936433139656272\n",
      "Epoch 2, Loss: 0.6862825458603246\n",
      "Epoch 3, Loss: 0.6759811815406594\n",
      "Epoch 4, Loss: 0.678635665348598\n",
      "Epoch 5, Loss: 0.6678809151053429\n",
      "Epoch 6, Loss: 0.3965729832915323\n",
      "all_preds shape: (194,)\n",
      "all_labels shape: (194,)\n",
      "all_probs shape: (194, 2)\n",
      "Train labels sample: tensor([0, 1, 0, 0, 0]), Shape: torch.Size([887])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([183])\n",
      "##########################roberta-base---bert####################\n",
      "Epoch 1, Loss: 0.7071849011949131\n",
      "Epoch 2, Loss: 0.673839230622564\n",
      "Epoch 3, Loss: 0.668581947684288\n",
      "Epoch 4, Loss: 0.6696096254246575\n",
      "Epoch 5, Loss: 0.5934729195599046\n",
      "Epoch 6, Loss: 0.6751758658460209\n",
      "all_preds shape: (183,)\n",
      "all_labels shape: (183,)\n",
      "all_probs shape: (183, 2)\n",
      "Train labels sample: tensor([1, 1, 1, 0, 0]), Shape: torch.Size([887])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([189])\n",
      "##########################roberta-base---bert####################\n",
      "Epoch 1, Loss: 0.7134618588856289\n",
      "Epoch 2, Loss: 0.6718797492129462\n",
      "Epoch 3, Loss: 0.683442969407354\n",
      "Epoch 4, Loss: 0.6924178360828331\n",
      "Epoch 5, Loss: 0.6874057847474303\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Loss: 0.6780258523566383\n",
      "all_preds shape: (189,)\n",
      "all_labels shape: (189,)\n",
      "all_probs shape: (189, 2)\n",
      "train_Изъяты лексемы с частотой выше 49.csv\n",
      "test_Изъяты лексемы с частотой выше 49.csv\n",
      "Train labels sample: tensor([1, 1, 1, 0, 0]), Shape: torch.Size([916])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([195])\n",
      "##########################roberta-base---bert####################\n",
      "Epoch 1, Loss: 0.6781338401909532\n",
      "Epoch 2, Loss: 0.6504219960549782\n",
      "Epoch 3, Loss: 0.6540960494814247\n",
      "Epoch 4, Loss: 0.6500619115500614\n",
      "Epoch 5, Loss: 0.662700323195293\n",
      "Epoch 6, Loss: 0.6500117624628132\n",
      "all_preds shape: (195,)\n",
      "all_labels shape: (195,)\n",
      "all_probs shape: (195, 2)\n",
      "Train labels sample: tensor([0, 0, 1, 0, 0]), Shape: torch.Size([916])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([187])\n",
      "##########################roberta-base---bert####################\n",
      "Epoch 1, Loss: 0.6943585276603699\n",
      "Epoch 2, Loss: 0.6771119252361101\n",
      "Epoch 3, Loss: 0.6600651078183075\n",
      "Epoch 4, Loss: 0.648534730590623\n",
      "Epoch 5, Loss: 0.4780215037793949\n",
      "Epoch 6, Loss: 0.2964594944155422\n",
      "all_preds shape: (187,)\n",
      "all_labels shape: (187,)\n",
      "all_probs shape: (187, 2)\n",
      "Train labels sample: tensor([0, 0, 1, 1, 1]), Shape: torch.Size([916])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([190])\n",
      "##########################roberta-base---bert####################\n",
      "Epoch 1, Loss: 0.6904531501490494\n",
      "Epoch 2, Loss: 0.6720570372096424\n",
      "Epoch 3, Loss: 0.6847413994114975\n",
      "Epoch 4, Loss: 0.663541888882374\n",
      "Epoch 5, Loss: 0.6686068865759619\n",
      "Epoch 6, Loss: 0.6535689995206636\n",
      "all_preds shape: (190,)\n",
      "all_labels shape: (190,)\n",
      "all_probs shape: (190, 2)\n",
      "Train labels sample: tensor([0, 0, 1, 1, 0]), Shape: torch.Size([916])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([179])\n",
      "##########################roberta-base---bert####################\n",
      "Epoch 1, Loss: 0.6902117862783629\n",
      "Epoch 2, Loss: 0.6676568501982195\n",
      "Epoch 3, Loss: 0.6317837089300156\n",
      "Epoch 4, Loss: 0.6527570969071882\n",
      "Epoch 5, Loss: 0.5038686501311844\n",
      "Epoch 6, Loss: 0.3929555381423441\n",
      "all_preds shape: (179,)\n",
      "all_labels shape: (179,)\n",
      "all_probs shape: (179, 2)\n",
      "Train labels sample: tensor([1, 1, 0, 0, 0]), Shape: torch.Size([916])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([195])\n",
      "##########################roberta-base---bert####################\n",
      "Epoch 1, Loss: 0.6914037974744007\n",
      "Epoch 2, Loss: 0.6906224561148676\n",
      "Epoch 3, Loss: 0.6679525909752682\n",
      "Epoch 4, Loss: 0.6439897418022156\n",
      "Epoch 5, Loss: 0.6054399691779038\n",
      "Epoch 6, Loss: 0.4228889726359269\n",
      "all_preds shape: (195,)\n",
      "all_labels shape: (195,)\n",
      "all_probs shape: (195, 2)\n",
      "Train labels sample: tensor([0, 1, 0, 1, 0]), Shape: torch.Size([916])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([186])\n",
      "##########################roberta-base---bert####################\n",
      "Epoch 1, Loss: 0.6914026850256426\n",
      "Epoch 2, Loss: 0.6583460610488365\n",
      "Epoch 3, Loss: 0.6608161736151268\n",
      "Epoch 4, Loss: 0.6178341990914838\n",
      "Epoch 5, Loss: 0.3917577665556094\n",
      "Epoch 6, Loss: 0.3189611780489313\n",
      "all_preds shape: (186,)\n",
      "all_labels shape: (186,)\n",
      "all_probs shape: (186, 2)\n",
      "train_Изъяты лексемы с частотой выше 29.csv\n",
      "test_Изъяты лексемы с частотой выше 29.csv\n",
      "Train labels sample: tensor([0, 0, 0, 0, 1]), Shape: torch.Size([904])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([191])\n",
      "##########################roberta-base---bert####################\n",
      "Epoch 1, Loss: 0.683749948154416\n",
      "Epoch 2, Loss: 0.6554405208219561\n",
      "Epoch 3, Loss: 0.5726719158783293\n",
      "Epoch 4, Loss: 0.6854871145465917\n",
      "Epoch 5, Loss: 0.6645727288304714\n",
      "Epoch 6, Loss: 0.6468444429991538\n",
      "all_preds shape: (191,)\n",
      "all_labels shape: (191,)\n",
      "all_probs shape: (191, 2)\n",
      "Train labels sample: tensor([0, 1, 0, 0, 1]), Shape: torch.Size([904])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([205])\n",
      "##########################roberta-base---bert####################\n",
      "Epoch 1, Loss: 0.6687703833245394\n",
      "Epoch 2, Loss: 0.6708028332183236\n",
      "Epoch 3, Loss: 0.6599350629145639\n",
      "Epoch 4, Loss: 0.650768859867464\n",
      "Epoch 5, Loss: 0.667845808100282\n",
      "Epoch 6, Loss: 0.6553590104245303\n",
      "all_preds shape: (205,)\n",
      "all_labels shape: (205,)\n",
      "all_probs shape: (205, 2)\n",
      "Train labels sample: tensor([1, 1, 0, 0, 0]), Shape: torch.Size([904])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([186])\n",
      "##########################roberta-base---bert####################\n",
      "Epoch 1, Loss: 0.6842734520895439\n",
      "Epoch 2, Loss: 0.6503025889396667\n",
      "Epoch 3, Loss: 0.6374210762350183\n",
      "Epoch 4, Loss: 0.446097552057421\n",
      "Epoch 5, Loss: 0.3284061680498876\n",
      "Epoch 6, Loss: 0.2472179314415706\n",
      "all_preds shape: (186,)\n",
      "all_labels shape: (186,)\n",
      "all_probs shape: (186, 2)\n",
      "Train labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([904])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([200])\n",
      "##########################roberta-base---bert####################\n",
      "Epoch 1, Loss: 0.7060097764458573\n",
      "Epoch 2, Loss: 0.655059232000719\n",
      "Epoch 3, Loss: 0.6548645862361842\n",
      "Epoch 4, Loss: 0.6564052554599026\n",
      "Epoch 5, Loss: 0.6583715849801114\n",
      "Epoch 6, Loss: 0.6475087231711337\n",
      "all_preds shape: (200,)\n",
      "all_labels shape: (200,)\n",
      "all_probs shape: (200, 2)\n",
      "Train labels sample: tensor([0, 0, 1, 1, 0]), Shape: torch.Size([904])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([202])\n",
      "##########################roberta-base---bert####################\n",
      "Epoch 1, Loss: 0.6790584937522286\n",
      "Epoch 2, Loss: 0.6405346858919713\n",
      "Epoch 3, Loss: 0.6297467152277628\n",
      "Epoch 4, Loss: 0.42837763773767573\n",
      "Epoch 5, Loss: 0.396101025635736\n",
      "Epoch 6, Loss: 0.2697815793125253\n",
      "all_preds shape: (202,)\n",
      "all_labels shape: (202,)\n",
      "all_probs shape: (202, 2)\n",
      "Train labels sample: tensor([1, 0, 0, 0, 0]), Shape: torch.Size([904])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([193])\n",
      "##########################roberta-base---bert####################\n",
      "Epoch 1, Loss: 0.6749682217313532\n",
      "Epoch 2, Loss: 0.6508592926619345\n",
      "Epoch 3, Loss: 0.6335426067051134\n",
      "Epoch 4, Loss: 0.6020213020475287\n",
      "Epoch 5, Loss: 0.6641484033643154\n",
      "Epoch 6, Loss: 0.6695022284984589\n",
      "all_preds shape: (193,)\n",
      "all_labels shape: (193,)\n",
      "all_probs shape: (193, 2)\n",
      "train_Изъяты лексемы с частотой выше 9.csv\n",
      "test_Изъяты лексемы с частотой выше 9.csv\n",
      "Train labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([773])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([336])\n",
      "##########################roberta-base---bert####################\n",
      "Epoch 1, Loss: 0.6888160014152527\n",
      "Epoch 2, Loss: 0.6502899646759033\n",
      "Epoch 3, Loss: 0.6227393770217895\n",
      "Epoch 4, Loss: 0.49703412055969237\n",
      "all_preds shape: (336,)\n",
      "all_labels shape: (336,)\n",
      "all_probs shape: (336, 2)\n",
      "Train labels sample: tensor([1, 0, 0, 1, 1]), Shape: torch.Size([773])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([345])\n",
      "##########################roberta-base---bert####################\n",
      "Epoch 1, Loss: 0.7257808530330658\n",
      "Epoch 2, Loss: 0.6684027802944184\n",
      "Epoch 3, Loss: 0.6549297034740448\n",
      "Epoch 4, Loss: 0.6493203949928283\n",
      "all_preds shape: (345,)\n",
      "all_labels shape: (345,)\n",
      "all_probs shape: (345, 2)\n",
      "Train labels sample: tensor([1, 0, 0, 1, 0]), Shape: torch.Size([773])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([281])\n",
      "##########################roberta-base---bert####################\n",
      "Epoch 1, Loss: 0.7078790926933288\n",
      "Epoch 2, Loss: 0.6611658430099487\n",
      "Epoch 3, Loss: 0.6484151196479797\n",
      "Epoch 4, Loss: 0.6212001276016236\n",
      "all_preds shape: (281,)\n",
      "all_labels shape: (281,)\n",
      "all_probs shape: (281, 2)\n",
      "Train labels sample: tensor([1, 0, 0, 0, 1]), Shape: torch.Size([773])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([289])\n",
      "##########################roberta-base---bert####################\n",
      "Epoch 1, Loss: 0.7108653783798218\n",
      "Epoch 2, Loss: 0.642555320262909\n",
      "Epoch 3, Loss: 0.5904149687290192\n",
      "Epoch 4, Loss: 0.5471612393856049\n",
      "all_preds shape: (289,)\n",
      "all_labels shape: (289,)\n",
      "all_probs shape: (289, 2)\n",
      "Train labels sample: tensor([0, 0, 0, 0, 1]), Shape: torch.Size([773])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([278])\n",
      "##########################roberta-base---bert####################\n",
      "Epoch 1, Loss: 0.740160448551178\n",
      "Epoch 2, Loss: 0.655183048248291\n",
      "Epoch 3, Loss: 0.6731147265434265\n",
      "Epoch 4, Loss: 0.6558566451072693\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_preds shape: (278,)\n",
      "all_labels shape: (278,)\n",
      "all_probs shape: (278, 2)\n",
      "Train labels sample: tensor([0, 0, 1, 1, 0]), Shape: torch.Size([773])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([273])\n",
      "##########################roberta-base---bert####################\n",
      "Epoch 1, Loss: 0.7128013753890992\n",
      "Epoch 2, Loss: 0.6529311108589172\n",
      "Epoch 3, Loss: 0.6551114296913148\n",
      "Epoch 4, Loss: 0.5644444066286087\n",
      "all_preds shape: (273,)\n",
      "all_labels shape: (273,)\n",
      "all_probs shape: (273, 2)\n",
      "train_Изъяты лексемы с частотой выше 5.csv\n",
      "test_Изъяты лексемы с частотой выше 5.csv\n",
      "Train labels sample: tensor([0, 1, 0, 0, 0]), Shape: torch.Size([99])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([524])\n",
      "##########################roberta-base---bert####################\n",
      "Epoch 1, Loss: 0.6290360923324313\n",
      "Epoch 2, Loss: 0.645839090858187\n",
      "Epoch 3, Loss: 0.6379866685186114\n",
      "Epoch 4, Loss: 0.5795302774224963\n",
      "Epoch 5, Loss: 0.5895850637129375\n",
      "Epoch 6, Loss: 0.5733184899602618\n",
      "all_preds shape: (524,)\n",
      "all_labels shape: (524,)\n",
      "all_probs shape: (524, 2)\n",
      "Train labels sample: tensor([0, 0, 0, 0, 1]), Shape: torch.Size([99])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([530])\n",
      "##########################roberta-base---bert####################\n",
      "Epoch 1, Loss: 0.6903100950377328\n",
      "Epoch 2, Loss: 0.608743450471333\n",
      "Epoch 3, Loss: 0.5434532548700061\n",
      "Epoch 4, Loss: 0.5004136392048427\n",
      "Epoch 5, Loss: 0.569045711840902\n",
      "Epoch 6, Loss: 0.5428082176617214\n",
      "all_preds shape: (530,)\n",
      "all_labels shape: (530,)\n",
      "all_probs shape: (530, 2)\n",
      "Train labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([99])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([573])\n",
      "##########################roberta-base---bert####################\n",
      "Epoch 1, Loss: 0.7415073428835187\n",
      "Epoch 2, Loss: 0.6518194121973855\n",
      "Epoch 3, Loss: 0.5936833322048187\n",
      "Epoch 4, Loss: 0.56544429063797\n",
      "Epoch 5, Loss: 0.5765471501009805\n",
      "Epoch 6, Loss: 0.5589440677847181\n",
      "all_preds shape: (573,)\n",
      "all_labels shape: (573,)\n",
      "all_probs shape: (573, 2)\n",
      "Train labels sample: tensor([0, 0, 0, 0, 1]), Shape: torch.Size([99])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([475])\n",
      "##########################roberta-base---bert####################\n",
      "Epoch 1, Loss: 0.7353918360812324\n",
      "Epoch 2, Loss: 0.5768670333283288\n",
      "Epoch 3, Loss: 0.5450437877859388\n",
      "Epoch 4, Loss: 0.5748486561434609\n",
      "Epoch 5, Loss: 0.6136157384940556\n",
      "Epoch 6, Loss: 0.5294459462165833\n",
      "all_preds shape: (475,)\n",
      "all_labels shape: (475,)\n",
      "all_probs shape: (475, 2)\n",
      "Train labels sample: tensor([0, 1, 0, 0, 0]), Shape: torch.Size([99])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([519])\n",
      "##########################roberta-base---bert####################\n",
      "Epoch 1, Loss: 0.810793685061591\n",
      "Epoch 2, Loss: 0.5778803399630955\n",
      "Epoch 3, Loss: 0.5956511071750096\n",
      "Epoch 4, Loss: 0.5850808279854911\n",
      "Epoch 5, Loss: 0.6160435506275722\n",
      "Epoch 6, Loss: 0.5978298613003322\n",
      "all_preds shape: (519,)\n",
      "all_labels shape: (519,)\n",
      "all_probs shape: (519, 2)\n",
      "Train labels sample: tensor([0, 0, 0, 1, 0]), Shape: torch.Size([99])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([468])\n",
      "##########################roberta-base---bert####################\n",
      "Epoch 1, Loss: 0.7867132765906197\n",
      "Epoch 2, Loss: 0.5525633011545453\n",
      "Epoch 3, Loss: 0.6226205229759216\n",
      "Epoch 4, Loss: 0.552561994109835\n",
      "Epoch 5, Loss: 0.5214496042047229\n",
      "Epoch 6, Loss: 0.5889643728733063\n",
      "all_preds shape: (468,)\n",
      "all_labels shape: (468,)\n",
      "all_probs shape: (468, 2)\n",
      "train_Изъяты лексемы с частотой выше 3.csv\n",
      "test_Изъяты лексемы с частотой выше 3.csv\n",
      "Train labels sample: tensor([0, 1, 1, 1, 0]), Shape: torch.Size([92])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([722])\n",
      "##########################roberta-base---bert####################\n",
      "Epoch 1, Loss: 0.7491646707057953\n",
      "Epoch 2, Loss: 0.5528553997476896\n",
      "Epoch 3, Loss: 0.5670712093512217\n",
      "Epoch 4, Loss: 0.5559595127900442\n",
      "Epoch 5, Loss: 0.5613300452629725\n",
      "Epoch 6, Loss: 0.5425686836242676\n",
      "all_preds shape: (722,)\n",
      "all_labels shape: (722,)\n",
      "all_probs shape: (722, 2)\n",
      "Train labels sample: tensor([1, 0, 0, 0, 0]), Shape: torch.Size([92])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([735])\n",
      "##########################roberta-base---bert####################\n",
      "Epoch 1, Loss: 0.5410218685865402\n",
      "Epoch 2, Loss: 0.500717282295227\n",
      "Epoch 3, Loss: 0.49099720021088916\n",
      "Epoch 4, Loss: 0.4851585477590561\n",
      "Epoch 5, Loss: 0.5234323044617971\n",
      "Epoch 6, Loss: 0.5051634510358175\n",
      "all_preds shape: (735,)\n",
      "all_labels shape: (735,)\n",
      "all_probs shape: (735, 2)\n",
      "Train labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([92])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([714])\n",
      "##########################roberta-base---bert####################\n",
      "Epoch 1, Loss: 0.8527617702881495\n",
      "Epoch 2, Loss: 0.6060484399398168\n",
      "Epoch 3, Loss: 0.6151427179574966\n",
      "Epoch 4, Loss: 0.5815789699554443\n",
      "Epoch 5, Loss: 0.5685065537691116\n",
      "Epoch 6, Loss: 0.5521337489287058\n",
      "all_preds shape: (714,)\n",
      "all_labels shape: (714,)\n",
      "all_probs shape: (714, 2)\n",
      "Train labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([92])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([736])\n",
      "##########################roberta-base---bert####################\n",
      "Epoch 1, Loss: 0.650348981221517\n",
      "Epoch 2, Loss: 0.5118281443913778\n",
      "Epoch 3, Loss: 0.519312838713328\n",
      "Epoch 4, Loss: 0.4886348446210225\n",
      "Epoch 5, Loss: 0.4831288605928421\n",
      "Epoch 6, Loss: 0.492530624071757\n",
      "all_preds shape: (736,)\n",
      "all_labels shape: (736,)\n",
      "all_probs shape: (736, 2)\n",
      "Train labels sample: tensor([1, 0, 1, 0, 0]), Shape: torch.Size([92])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([699])\n",
      "##########################roberta-base---bert####################\n",
      "Epoch 1, Loss: 0.8408565521240234\n",
      "Epoch 2, Loss: 0.624950552980105\n",
      "Epoch 3, Loss: 0.570304681857427\n",
      "Epoch 4, Loss: 0.5533795356750488\n",
      "Epoch 5, Loss: 0.5556914210319519\n",
      "Epoch 6, Loss: 0.5558331062396368\n",
      "all_preds shape: (699,)\n",
      "all_labels shape: (699,)\n",
      "all_probs shape: (699, 2)\n",
      "Train labels sample: tensor([0, 0, 0, 0, 1]), Shape: torch.Size([92])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([706])\n",
      "##########################roberta-base---bert####################\n",
      "Epoch 1, Loss: 0.7124125535289446\n",
      "Epoch 2, Loss: 0.5731897801160812\n",
      "Epoch 3, Loss: 0.5577015231053034\n",
      "Epoch 4, Loss: 0.5391450275977453\n",
      "Epoch 5, Loss: 0.5650424212217331\n",
      "Epoch 6, Loss: 0.5577254990736643\n",
      "all_preds shape: (706,)\n",
      "all_labels shape: (706,)\n",
      "all_probs shape: (706, 2)\n",
      "train_Без прилагательных первый-второй жанр.csv\n",
      "test_Без прилагательных первый-второй жанр.csv\n",
      "Train labels sample: tensor([0, 0, 0, 1, 1]), Shape: torch.Size([872])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([159])\n",
      "##########################roberta-base---bert####################\n",
      "Epoch 1, Loss: 0.6861955257398742\n",
      "Epoch 2, Loss: 0.5576735681721142\n",
      "Epoch 3, Loss: 0.5632023087569645\n",
      "Epoch 4, Loss: 0.3757847137749195\n",
      "all_preds shape: (159,)\n",
      "all_labels shape: (159,)\n",
      "all_probs shape: (159, 2)\n",
      "Train labels sample: tensor([1, 0, 1, 0, 0]), Shape: torch.Size([872])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([159])\n",
      "##########################roberta-base---bert####################\n",
      "Epoch 1, Loss: 0.7321860087769372\n",
      "Epoch 2, Loss: 0.6771638414689473\n",
      "Epoch 3, Loss: 0.6207447679979461\n",
      "Epoch 4, Loss: 0.5388381385377475\n",
      "all_preds shape: (159,)\n",
      "all_labels shape: (159,)\n",
      "all_probs shape: (159, 2)\n",
      "Train labels sample: tensor([0, 1, 1, 0, 0]), Shape: torch.Size([872])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([161])\n",
      "##########################roberta-base---bert####################\n",
      "Epoch 1, Loss: 0.7376441529818943\n",
      "Epoch 2, Loss: 0.6644532765660968\n",
      "Epoch 3, Loss: 0.5566329242927688\n",
      "Epoch 4, Loss: 0.4640681568000998\n",
      "all_preds shape: (161,)\n",
      "all_labels shape: (161,)\n",
      "all_probs shape: (161, 2)\n",
      "Train labels sample: tensor([1, 1, 0, 1, 1]), Shape: torch.Size([872])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([153])\n",
      "##########################roberta-base---bert####################\n",
      "Epoch 1, Loss: 0.6711187426533017\n",
      "Epoch 2, Loss: 0.5592865028551647\n",
      "Epoch 3, Loss: 0.5058511442371777\n",
      "Epoch 4, Loss: 0.38495107899819103\n",
      "all_preds shape: (153,)\n",
      "all_labels shape: (153,)\n",
      "all_probs shape: (153, 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train labels sample: tensor([0, 0, 0, 0, 1]), Shape: torch.Size([872])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([174])\n",
      "##########################roberta-base---bert####################\n",
      "Epoch 1, Loss: 0.6765413635543415\n",
      "Epoch 2, Loss: 0.5852961997900691\n",
      "Epoch 3, Loss: 0.488286737884794\n",
      "Epoch 4, Loss: 0.4536716586777142\n",
      "all_preds shape: (174,)\n",
      "all_labels shape: (174,)\n",
      "all_probs shape: (174, 2)\n",
      "Train labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([872])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([162])\n",
      "##########################roberta-base---bert####################\n",
      "Epoch 1, Loss: 0.6360957697033882\n",
      "Epoch 2, Loss: 0.5490794777870178\n",
      "Epoch 3, Loss: 0.4037646842854364\n",
      "Epoch 4, Loss: 0.41505269919122967\n",
      "all_preds shape: (162,)\n",
      "all_labels shape: (162,)\n",
      "all_probs shape: (162, 2)\n",
      "train_1.Первый жанр исходная выборка.csv\n",
      "test_1.Первый жанр исходная выборка.csv\n",
      "Train labels sample: tensor([1, 0, 0, 1, 1]), Shape: torch.Size([912])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([169])\n",
      "##########################roberta-base---bert####################\n",
      "Epoch 1, Loss: 0.7019408993553697\n",
      "Epoch 2, Loss: 0.6687546586781218\n",
      "Epoch 3, Loss: 0.6593036871207388\n",
      "Epoch 4, Loss: 0.654554688093955\n",
      "Epoch 5, Loss: 0.6617098408832884\n",
      "Epoch 6, Loss: 0.6968882763594911\n",
      "all_preds shape: (169,)\n",
      "all_labels shape: (169,)\n",
      "all_probs shape: (169, 2)\n",
      "Train labels sample: tensor([0, 0, 0, 1, 1]), Shape: torch.Size([912])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([169])\n",
      "##########################roberta-base---bert####################\n",
      "Epoch 1, Loss: 0.6920336192114311\n",
      "Epoch 2, Loss: 0.6933401441364958\n",
      "Epoch 3, Loss: 0.6698828203636303\n",
      "Epoch 4, Loss: 0.6672619173401281\n",
      "Epoch 5, Loss: 0.6813753127006063\n",
      "Epoch 6, Loss: 0.6735874487642657\n",
      "all_preds shape: (169,)\n",
      "all_labels shape: (169,)\n",
      "all_probs shape: (169, 2)\n",
      "Train labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([912])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([168])\n",
      "##########################roberta-base---bert####################\n",
      "Epoch 1, Loss: 0.6854288457778462\n",
      "Epoch 2, Loss: 0.6645610572998983\n",
      "Epoch 3, Loss: 0.6715015340269658\n",
      "Epoch 4, Loss: 0.6411453715541906\n",
      "Epoch 5, Loss: 0.5924085227021\n",
      "Epoch 6, Loss: 0.513001709915044\n",
      "all_preds shape: (168,)\n",
      "all_labels shape: (168,)\n",
      "all_probs shape: (168, 2)\n",
      "Train labels sample: tensor([1, 1, 1, 1, 0]), Shape: torch.Size([912])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([167])\n",
      "##########################roberta-base---bert####################\n",
      "Epoch 1, Loss: 0.7171692811606223\n",
      "Epoch 2, Loss: 0.6595541217870879\n",
      "Epoch 3, Loss: 0.6835046807924906\n",
      "Epoch 4, Loss: 0.6634966438276726\n",
      "Epoch 5, Loss: 0.6632492981458965\n",
      "Epoch 6, Loss: 0.6610466179094816\n",
      "all_preds shape: (167,)\n",
      "all_labels shape: (167,)\n",
      "all_probs shape: (167, 2)\n",
      "Train labels sample: tensor([0, 1, 0, 0, 0]), Shape: torch.Size([912])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([168])\n",
      "##########################roberta-base---bert####################\n",
      "Epoch 1, Loss: 0.6996496424340365\n",
      "Epoch 2, Loss: 0.6708843587783345\n",
      "Epoch 3, Loss: 0.6330993745410651\n",
      "Epoch 4, Loss: 0.6044138751009054\n",
      "Epoch 5, Loss: 0.38931626983379064\n",
      "Epoch 6, Loss: 0.2799985299638489\n",
      "all_preds shape: (168,)\n",
      "all_labels shape: (168,)\n",
      "all_probs shape: (168, 2)\n",
      "Train labels sample: tensor([1, 0, 0, 0, 1]), Shape: torch.Size([912])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([152])\n",
      "##########################roberta-base---bert####################\n",
      "Epoch 1, Loss: 0.7323789345590692\n",
      "Epoch 2, Loss: 0.6842043551436642\n",
      "Epoch 3, Loss: 0.671782674496634\n",
      "Epoch 4, Loss: 0.6662497337450061\n",
      "Epoch 5, Loss: 0.6692966923379061\n",
      "Epoch 6, Loss: 0.6628712844430354\n",
      "all_preds shape: (152,)\n",
      "all_labels shape: (152,)\n",
      "all_probs shape: (152, 2)\n",
      "train_2.Первый жанр без клауз, включающих наречия.csv\n",
      "test_2.Первый жанр без клауз, включающих наречия.csv\n",
      "Train labels sample: tensor([0, 1, 1, 0, 1]), Shape: torch.Size([900])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([167])\n",
      "##########################roberta-base---bert####################\n",
      "Epoch 1, Loss: 0.6987539163806982\n",
      "Epoch 2, Loss: 0.6781476150479233\n",
      "Epoch 3, Loss: 0.6350018889234778\n",
      "Epoch 4, Loss: 0.49573419596019547\n",
      "Epoch 5, Loss: 0.4209459953402218\n",
      "Epoch 6, Loss: 0.25469888531063734\n",
      "all_preds shape: (167,)\n",
      "all_labels shape: (167,)\n",
      "all_probs shape: (167, 2)\n",
      "Train labels sample: tensor([1, 1, 0, 0, 1]), Shape: torch.Size([900])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([168])\n",
      "##########################roberta-base---bert####################\n",
      "Epoch 1, Loss: 0.710288709715793\n",
      "Epoch 2, Loss: 0.6782529416837191\n",
      "Epoch 3, Loss: 0.6680882541756881\n",
      "Epoch 4, Loss: 0.6851472133084348\n",
      "Epoch 5, Loss: 0.6512362585778821\n",
      "Epoch 6, Loss: 0.6119128664334615\n",
      "all_preds shape: (168,)\n",
      "all_labels shape: (168,)\n",
      "all_probs shape: (168, 2)\n",
      "Train labels sample: tensor([1, 1, 1, 0, 0]), Shape: torch.Size([900])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([163])\n",
      "##########################roberta-base---bert####################\n",
      "Epoch 1, Loss: 0.7028838103277641\n",
      "Epoch 2, Loss: 0.6754460193608937\n",
      "Epoch 3, Loss: 0.5932948113533488\n",
      "Epoch 4, Loss: 0.5639666449605373\n",
      "Epoch 5, Loss: 0.30207337171100734\n",
      "Epoch 6, Loss: 0.3354368381071509\n",
      "all_preds shape: (163,)\n",
      "all_labels shape: (163,)\n",
      "all_probs shape: (163, 2)\n",
      "Train labels sample: tensor([1, 0, 1, 0, 0]), Shape: torch.Size([900])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([170])\n",
      "##########################roberta-base---bert####################\n",
      "Epoch 1, Loss: 0.7139937783542433\n",
      "Epoch 2, Loss: 0.6702904183613626\n",
      "Epoch 3, Loss: 0.6715386509895325\n",
      "Epoch 4, Loss: 0.6648477127677516\n",
      "Epoch 5, Loss: 0.6716082137927675\n",
      "Epoch 6, Loss: 0.5650093563293156\n",
      "all_preds shape: (170,)\n",
      "all_labels shape: (170,)\n",
      "all_probs shape: (170, 2)\n",
      "Train labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([900])\n",
      "Test labels sample: tensor([0, 0, 0, 0, 0]), Shape: torch.Size([170])\n",
      "##########################roberta-base---bert####################\n",
      "Epoch 1, Loss: 0.7192807887729845\n",
      "Epoch 2, Loss: 0.6759958267211914\n",
      "Epoch 3, Loss: 0.6699742821224949\n",
      "Epoch 4, Loss: 0.6675417784013247\n"
     ]
    }
   ],
   "source": [
    "import funciones\n",
    "from utils import train_wrapper\n",
    "import warnings\n",
    "import os\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "from tqdm import tqdm\n",
    "from contextlib import redirect_stderr\n",
    "import multiprocessing as mp\n",
    "import numpy as np\n",
    "#import wandb\n",
    "import nbformat\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import gc\n",
    "import re\n",
    "import nltk\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import BertForSequenceClassification, AdamW\n",
    "from razdel import sentenize\n",
    "import numpy as np\n",
    "\n",
    "# Suprimir warnings específicos\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "mp.set_start_method('spawn', force=True)\n",
    "\n",
    "\n",
    "import json\n",
    "\n",
    "\n",
    "def convert_numpy(obj):\n",
    "    if isinstance(obj, np.ndarray):\n",
    "        return obj.tolist()\n",
    "    if isinstance(obj, (np.float32, np.float64, np.int32, np.int64)):\n",
    "        return obj.item()\n",
    "    return obj\n",
    "\n",
    "def save_results(results, filename):\n",
    "    with open(filename, 'w', encoding='utf-8') as f:\n",
    "        json.dump(results, f, indent=4, ensure_ascii=False, default=convert_numpy)\n",
    "\n",
    "        \n",
    "def create_custom_config(model_name, model_type, dataset):\n",
    "    \"\"\"Crea configuración de entrenamiento adaptativa\"\"\"\n",
    "    common_config = {\n",
    "#         'dataset_name':dataset.get('name', ''),\n",
    "        'model_name': model_name,\n",
    "        'model_type': model_type,\n",
    "        'num_repeats': 6,\n",
    "        'test_size': 0.2,\n",
    "        'threshold': 0.5\n",
    "    }\n",
    "\n",
    "    # Configuración específica para GPT\n",
    "#     if model_type == 'gpt':\n",
    "#         return funciones.TrainingConfig(\n",
    "#             **common_config,\n",
    "#             max_length=52,\n",
    "#             batch_size=64,\n",
    "#             epochs=6,\n",
    "#             learning_rate=1e-5\n",
    "#         )\n",
    "\n",
    "#         # Configuración por nombre de dataset\n",
    "#         dataset_name = dataset.get('name', '')\n",
    "#         if any(x in dataset_name for x in ['1', '2', '3', '4']):\n",
    "#             return funciones.TrainingConfig(\n",
    "#                 **common_config,\n",
    "#                 max_length=60,\n",
    "#                 batch_size=128,\n",
    "#                 epochs=6,\n",
    "#                 learning_rate=5e-5\n",
    "#             )\n",
    "\n",
    "\n",
    "    # Configuraciones basadas en frecuencia\n",
    "    freq_threshold = dataset.get('freq_threshold')\n",
    "    if freq_threshold in [100, 49, 29, 9, 5, 3]:\n",
    "        configs = {\n",
    "            100: (52, 16, 6, 2e-5),\n",
    "            49: (60, 16, 6, 3e-5),\n",
    "            29: (51, 16, 6, 3e-5),\n",
    "            9: (45, 16, 6, 4e-5),\n",
    "            5: (150, 16, 6, 5e-5),\n",
    "            3: (150, 16, 6, 5e-5)\n",
    "        }\n",
    "        max_len, batch, epochs, lr = configs[freq_threshold]\n",
    "        return funciones.TrainingConfig(\n",
    "            **common_config,\n",
    "            max_length=max_len,\n",
    "            batch_size=batch,\n",
    "            epochs=epochs,\n",
    "            learning_rate=lr\n",
    "        )\n",
    "\n",
    "    # Configuración por nombre de dataset\n",
    "    dataset_name = dataset.get('name', '')\n",
    "    for x in ['1', '2', '3', '4', '5', '6']:\n",
    "        if x in dataset_name:\n",
    "            configs = {\n",
    "                '1': (60, 16, 6, 5e-5),\n",
    "                '2': (60, 16, 6, 5e-5),\n",
    "                '3': (60, 16, 6, 5e-5),\n",
    "                '4': (60, 16, 6, 5e-5),\n",
    "                '5': (60, 16, 6, 5e-5),\n",
    "                '6': (60, 16, 6, 5e-5)\n",
    "            }\n",
    "            max_len, batch, epochs, lr = configs[x]\n",
    "            return funciones.TrainingConfig(\n",
    "                **common_config,\n",
    "                max_length=max_len,\n",
    "                batch_size=batch,\n",
    "                epochs=epochs,\n",
    "                learning_rate=lr\n",
    "            )\n",
    "\n",
    "\n",
    "    # Configuración por defecto\n",
    "    return funciones.TrainingConfig(\n",
    "        **common_config,\n",
    "        max_length=60,\n",
    "        batch_size=32,\n",
    "        epochs=4,\n",
    "        learning_rate=3e-5\n",
    "    )\n",
    "\n",
    "models = [\n",
    "    {'model':'DeepPavlov/rubert-base-cased',\n",
    "     'name':'DeepPavlov-rubert-base',\n",
    "     'type': 'bert'}, # Modelo original (ruso)\n",
    "    {'model':'bert-base-multilingual-cased',\n",
    "     'name':'BERT multilingual',\n",
    "     'type': 'bert'}, # BERT multilingüe\n",
    "    {'model':'distilbert-base-multilingual-cased',\n",
    "     'name':'distilbert-base-multilingual',\n",
    "     'type': 'bert'}, # Versión ligera de BERT multilingüe\n",
    "    {'model':'roberta-base',\n",
    "     'name':'roberta-base',\n",
    "     'type': 'bert'}, # RoBERTa (principalmente inglés)\n",
    "\n",
    "    {'model':'xlnet-base-cased',\n",
    "     'name':'XLNet Base',\n",
    "     'type': 'bert'}, # XLNet (multilingüe efectivo)\n",
    "    {'model':'xlm-roberta-base',\n",
    "     'name':'XLM-RoBERTa Base',\n",
    "     'type': 'bert'}, # XLM-RoBERTa (multilingüe)\n",
    "#     {'model':'google/rembert',\n",
    "#      'name':'RemBERT',\n",
    "#      'type': 'bert'}, # RemBERT (énfasis en lenguajes individuales)\n",
    "\n",
    "    {'model': 'gpt2',\n",
    "     'name': 'gpt2',\n",
    "     'type': 'gpt'},  # GPT model\n",
    "    {'model': 'facebook/opt-125m',\n",
    "     'name': 'facebook/opt-125m',\n",
    "     'type': 'gpt'},  # GPT model\n",
    "    {'model': 'sberbank-ai/rugpt3small_based_on_gpt2',\n",
    "     'name': 'rugpt3small',\n",
    "     'type': 'gpt'}, # GPT model (ruso)\n",
    "    {'model':'facebook/mbart-large-cc25',\n",
    "     'name':'mBART Large',\n",
    "     'type': 'gpt'} # mBART (generativo, multilingüe)\n",
    "    ]\n",
    "# [\n",
    "#         {'model':'DeepPavlov/rubert-base-cased',\n",
    "#          'name':'DeepPavlov-rubert-base',\n",
    "#          'type': 'bert'},# Modelo original\n",
    "#         {'model':'bert-base-multilingual-cased',\n",
    "#          'name':'BERT multilingual',\n",
    "#          'type': 'bert'},# BERT multilingüe\n",
    "#         {'model':'distilbert-base-multilingual-cased',\n",
    "#          'name':'distilbert-base-multilingual',\n",
    "#          'type': 'bert'},# Versión ligera de BERT\n",
    "#         {'model':'roberta-base',\n",
    "#          'name':'roberta-base', \n",
    "#         'type': 'bert'}, # RoBERTa \n",
    "#         {'model': 'gpt2',\n",
    "#          'name': 'gpt2',\n",
    "#          'type': 'gpt'},  #  GPT model\n",
    "#         {'model': 'facebook/opt-125m',\n",
    "#          'name': 'facebook',\n",
    "#          'type': 'gpt'},  #  GPT model\n",
    "#         {'model': 'sberbank-ai/rugpt3small_based_on_gpt2',\n",
    "#          'name': 'rugpt3',\n",
    "#          'type': 'gpt'}\n",
    "#     ]\n",
    "\n",
    "datasets = [\n",
    "    #deberia adicionar el set original?\n",
    "        {\n",
    "            'path1': '../dataset/сокращение по частотности/1б_Изъяты лексемы с частотой выше 100.txt',\n",
    "            'path2': '../dataset/сокращение по частотности/2б_Изъяты лексемы с частотой выше 100.txt',\n",
    "            'name': 'Изъяты лексемы с частотой выше 100',\n",
    "            'type': 'freq',\n",
    "            'freq': 100\n",
    "        },\n",
    "        {\n",
    "            'path1': '../dataset/сокращение по частотности/1в_Изъяты лексемы с частотой выше 49.txt',\n",
    "            'path2': '../dataset/сокращение по частотности/2в_Изъяты лексемы с частотой выше 49.txt',\n",
    "            'name': 'Изъяты лексемы с частотой выше 49',\n",
    "            'type': 'freq',\n",
    "            'freq': 49\n",
    "        },\n",
    "        {\n",
    "            'path1': '../dataset/сокращение по частотности/1г_Изъяты лексемы с частотой выше 29.txt',\n",
    "            'path2': '../dataset/сокращение по частотности/2г_Изъяты лексемы с частотой выше 29.txt',\n",
    "            'name': 'Изъяты лексемы с частотой выше 29',\n",
    "            'type': 'freq',\n",
    "            'freq': 29\n",
    "        },\n",
    "        {\n",
    "            'path1': '../dataset/сокращение по частотности/1д_Изъяты лексемы с частотой выше 9.txt',\n",
    "            'path2': '../dataset/сокращение по частотности/2д_Изъяты лексемы с частотой выше 9.txt',\n",
    "            'name': 'Изъяты лексемы с частотой выше 9',\n",
    "            'type': 'freq',\n",
    "            'freq': 9\n",
    "        },\n",
    "        {\n",
    "            'path1': '../dataset/сокращение по частотности/1е_Изъяты лексемы с частотой выше 5.txt',\n",
    "            'path2': '../dataset/сокращение по частотности/2е_Изъяты лексемы с частотой выше 5.txt',\n",
    "            'name': 'Изъяты лексемы с частотой выше 5',\n",
    "            'type': 'freq',\n",
    "            'freq': 5\n",
    "        },\n",
    "        {\n",
    "            'path1': '../dataset/сокращение по частотности/1ё_Изъяты лексемы с частотой выше 3.txt',\n",
    "            'path2': '../dataset/сокращение по частотности/2ё_Изъяты лексемы с частотой выше 3.txt',\n",
    "            'name': 'Изъяты лексемы с частотой выше 3',\n",
    "            'type': 'freq',\n",
    "            'freq': 3\n",
    "        },\n",
    "\n",
    "            {\n",
    "            'path1': '../dataset/Сокращение по частям речи/Без прилагательных первый жанр.txt',\n",
    "            'path2': '../dataset/Сокращение по частям речи/Без прилагательных второй жанр.txt',\n",
    "            'name': 'Без прилагательных первый-второй жанр',#litle correction\n",
    "            'type': 'pos',\n",
    "            'freq': None\n",
    "            },\n",
    "          {\n",
    "            'path1': '../dataset/Сокращение по частям речи/1.Первый жанр исходная выборка.txt',\n",
    "            'path2': '../dataset/Второй_жанр_исходная.txt',\n",
    "            'name': '1.Первый жанр исходная выборка',# este el el orignal\n",
    "            'type': 'pos',\n",
    "            'freq': None\n",
    "\n",
    "        },\n",
    "        {\n",
    "            'path1': '../dataset/Сокращение по частям речи/2.Первый жанр без клауз, включающих наречия.txt',\n",
    "            'path2': '../dataset/Второй_жанр_исходная.txt',\n",
    "            'name': '2.Первый жанр без клауз, включающих наречия',\n",
    "            'type': 'pos',\n",
    "            'freq': None\n",
    "        },\n",
    "        {\n",
    "            'path1': '../dataset/Сокращение по частям речи/3.Первый жанр без клауз, включающих глаголы.txt',\n",
    "            'path2': '../dataset/Второй_жанр_исходная.txt',\n",
    "            'name': '3.Первый жанр без клауз, включающих глаголы',\n",
    "            'type': 'pos',\n",
    "            'freq': None\n",
    "        },\n",
    "        {\n",
    "            'path1': '../dataset/Сокращение по частям речи/4.Первый жанр без клауз, включающих глаголы и наречия.txt',\n",
    "            'path2': '../dataset/Второй_жанр_исходная.txt',\n",
    "            'name': '4.Первый жанр без клауз, включающих глаголы и наречия',\n",
    "            'type': 'pos',\n",
    "            'freq': None\n",
    "        },\n",
    "        {\n",
    "            'path1': '../dataset/Сокращение по частям речи/5.без клауз, включающих местоимения.txt',\n",
    "            'path2': '../dataset/Второй_жанр_исходная.txt',\n",
    "            'name': '5.без клауз, включающих местоимения.txt',\n",
    "            'type': 'pos',\n",
    "            'freq': None\n",
    "        },\n",
    "        {\n",
    "            'path1': '../dataset/Сокращение по частям речи/6.без слов функциональных.txt',\n",
    "            'path2': '../dataset/Второй_жанр_исходная.txt',\n",
    "            'name': '6.без слов функциональных.txt',\n",
    "            'type': 'pos',\n",
    "            'freq': None\n",
    "        },\n",
    "    \n",
    "    ]\n",
    "\n",
    "\n",
    "\n",
    "russian_templates = [\n",
    "    \"Этот литературный фрагмент принадлежит к жанру {}.\",\n",
    "    \"Данный текст является примером жанра {}.\",\n",
    "    \"Стилистические особенности указывают на жанр {}.\",\n",
    "    \"Жанровая принадлежность этого текста - {}.\",\n",
    "    \"Эксперты классифицируют этот текст как жанр {}.\",\n",
    "    \"Это типичный пример жанра {} в русской литературе.\",\n",
    "    \"По ключевым характеристикам это текст жанра {}.\",\n",
    "    \"Данное произведение относится к направлению {}.\",\n",
    "    \"Анализ содержания позволяет отнести текст к жанру {}.\",\n",
    "    \"Этот отрывок характерен для жанра {}.\"\n",
    "]\n",
    "\n",
    "def main():\n",
    "\n",
    "    results = []\n",
    "    for model in models:\n",
    "        for dataset in datasets:\n",
    "            config = create_custom_config(model['model'], model['type'], dataset)\n",
    "            \n",
    "            \n",
    "            # Entrenar y limpiar memoria\n",
    "            torch.cuda.empty_cache()\n",
    "            result = funciones.train_and_evaluate_dataset(\n",
    "                dataset['path1'],\n",
    "                dataset['path2'],\n",
    "                config,\n",
    "                dataset['name'],\n",
    "                dataset['type']\n",
    "                \n",
    "            )\n",
    "            results.append(result) \n",
    "#             if model['type'] = 'gpt':\n",
    "                \n",
    "        \n",
    "        del model\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "        \n",
    "    \n",
    "    save_results(results, 'resultados_Step_8.json') \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd31457",
   "metadata": {},
   "outputs": [],
   "source": [
    "#batch_size=128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7dfbb89",
   "metadata": {},
   "outputs": [],
   "source": [
    "#display_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1ac659",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import IPython\n",
    "\n",
    "# Reiniciar el kernel\n",
    "IPython.display.display(IPython.display.Javascript(\"Jupyter.notebook.kernel.restart()\"))\n",
    "\n",
    "# Apagar el kernel después de reiniciar\n",
    "os._exit(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d8fee8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08043990",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Mi Entorno (Python 3.9)",
   "language": "python",
   "name": "mi_entorno"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
