{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e66a70c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34m../dataset\u001b[00m\r\n",
      "├── \u001b[01;34men_espanol\u001b[00m\r\n",
      "│   ├── docx2txt.py\r\n",
      "│   ├── Второй_жанр_исходная.txt\r\n",
      "│   └── Первый_жанр_исходная.txt\r\n",
      "├── Второй_жанр_исходная.txt\r\n",
      "├── Первый_жанр_исходная.txt\r\n",
      "├── \u001b[01;34mСокращение по частям речи\u001b[00m\r\n",
      "│   ├── 1.Первый жанр исходная выборка.txt\r\n",
      "│   ├── 2.Первый жанр без клауз, включающих наречия.txt\r\n",
      "│   ├── 3.Первый жанр без клауз, включающих глаголы.txt\r\n",
      "│   ├── 4.Первый жанр без клауз, включающих глаголы и наречия.txt\r\n",
      "│   ├── Без прилагательных второй жанр.txt\r\n",
      "│   ├── Без прилагательных первый жанр.txt\r\n",
      "│   └── Случайные выборки.txt\r\n",
      "└── \u001b[01;34mсокращение по частотности\u001b[00m\r\n",
      "    ├── 1а_ без сокращений.txt\r\n",
      "    ├── 1б_Изъяты лексемы с частотой выше 100.txt\r\n",
      "    ├── 1в_Изъяты лексемы с частотой выше 49.txt\r\n",
      "    ├── 1г_Изъяты лексемы с частотой выше 29.txt\r\n",
      "    ├── 1д_Изъяты лексемы с частотой выше 9.txt\r\n",
      "    ├── 1е_Изъяты лексемы с частотой выше 5.txt\r\n",
      "    ├── 1ё_Изъяты лексемы с частотой выше 3.txt\r\n",
      "    ├── 2а_ без сокращений.txt\r\n",
      "    ├── 2б_Изъяты лексемы с частотой выше 100.txt\r\n",
      "    ├── 2в_Изъяты лексемы с частотой выше 49.txt\r\n",
      "    ├── 2г_Изъяты лексемы с частотой выше 29.txt\r\n",
      "    ├── 2д_Изъяты лексемы с частотой выше 9.txt\r\n",
      "    ├── 2е_Изъяты лексемы с частотой выше 5.txt\r\n",
      "    └── 2ё_Изъяты лексемы с частотой выше 3.txt\r\n",
      "\r\n",
      "3 directories, 26 files\r\n"
     ]
    }
   ],
   "source": [
    "!tree ../dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "accb463f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \u001b[0m\u001b[01;34m__pycache__\u001b[0m/                          herramientas.ipynb\r\n",
      " frecuencia.png                        parte_2.png\r\n",
      " frecuencia_lineas.png                 parte_2_Step1.png\r\n",
      " frecuencia_profesional.png            partes_discurso.png\r\n",
      " frecuencia_profesional_ajustada.png   utils.py\r\n",
      " frecuencia_step_1.png                 \u001b[01;34mwandb\u001b[0m/\r\n",
      " frecuencia_test_1.png                \u001b[01;34m'Сокращение по частям речи'\u001b[0m\u001b[K/\r\n",
      " funciones.py                         \u001b[01;34m'сокращение по частотности'\u001b[0m\u001b[K/\r\n",
      " generador.ipynb                      'сокращение по частотности.ipynb'\r\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11038bb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-14 02:02:48.382645: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Failed to detect the name of this notebook. You can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mtuesta-lx\u001b[0m (\u001b[33mtuesta-lx-moscow-institute-of-physics-and-technology\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/notebooks/Carlos/fine_tunig_project/thesis/Step_8/wandb/run-20250414_020251-kg5qj777</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/tuesta-lx-moscow-institute-of-physics-and-technology/model-comparison-frecuency/runs/kg5qj777' target=\"_blank\">olive-surf-9</a></strong> to <a href='https://wandb.ai/tuesta-lx-moscow-institute-of-physics-and-technology/model-comparison-frecuency' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/tuesta-lx-moscow-institute-of-physics-and-technology/model-comparison-frecuency' target=\"_blank\">https://wandb.ai/tuesta-lx-moscow-institute-of-physics-and-technology/model-comparison-frecuency</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/tuesta-lx-moscow-institute-of-physics-and-technology/model-comparison-frecuency/runs/kg5qj777' target=\"_blank\">https://wandb.ai/tuesta-lx-moscow-institute-of-physics-and-technology/model-comparison-frecuency/runs/kg5qj777</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">olive-surf-9</strong> at: <a href='https://wandb.ai/tuesta-lx-moscow-institute-of-physics-and-technology/model-comparison-frecuency/runs/kg5qj777' target=\"_blank\">https://wandb.ai/tuesta-lx-moscow-institute-of-physics-and-technology/model-comparison-frecuency/runs/kg5qj777</a><br> View project at: <a href='https://wandb.ai/tuesta-lx-moscow-institute-of-physics-and-technology/model-comparison-frecuency' target=\"_blank\">https://wandb.ai/tuesta-lx-moscow-institute-of-physics-and-technology/model-comparison-frecuency</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250414_020251-kg5qj777/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Using a boolean value for 'reinit' is deprecated. Use 'return_previous' or 'finish_previous' instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/notebooks/Carlos/fine_tunig_project/thesis/Step_8/wandb/run-20250414_020252-cowtc5pc</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/tuesta-lx-moscow-institute-of-physics-and-technology/model-comparison/runs/cowtc5pc' target=\"_blank\">Изъяты лексемы с частотой выше 100 - distilbert-base-multilingual</a></strong> to <a href='https://wandb.ai/tuesta-lx-moscow-institute-of-physics-and-technology/model-comparison' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/tuesta-lx-moscow-institute-of-physics-and-technology/model-comparison' target=\"_blank\">https://wandb.ai/tuesta-lx-moscow-institute-of-physics-and-technology/model-comparison</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/tuesta-lx-moscow-institute-of-physics-and-technology/model-comparison/runs/cowtc5pc' target=\"_blank\">https://wandb.ai/tuesta-lx-moscow-institute-of-physics-and-technology/model-comparison/runs/cowtc5pc</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_Изъяты лексемы с частотой выше 100 - distilbert-base-multilingual.csv\n",
      "test_Изъяты лексемы с частотой выше 100 - distilbert-base-multilingual.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>avg_accuracy</td><td>▁</td></tr><tr><td>std_accuracy</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>avg_accuracy</td><td>0.60045</td></tr><tr><td>std_accuracy</td><td>0.04122</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Изъяты лексемы с частотой выше 100 - distilbert-base-multilingual</strong> at: <a href='https://wandb.ai/tuesta-lx-moscow-institute-of-physics-and-technology/model-comparison/runs/cowtc5pc' target=\"_blank\">https://wandb.ai/tuesta-lx-moscow-institute-of-physics-and-technology/model-comparison/runs/cowtc5pc</a><br> View project at: <a href='https://wandb.ai/tuesta-lx-moscow-institute-of-physics-and-technology/model-comparison' target=\"_blank\">https://wandb.ai/tuesta-lx-moscow-institute-of-physics-and-technology/model-comparison</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250414_020252-cowtc5pc/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/notebooks/Carlos/fine_tunig_project/thesis/Step_8/wandb/run-20250414_020432-93dyp6uw</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/tuesta-lx-moscow-institute-of-physics-and-technology/model-comparison/runs/93dyp6uw' target=\"_blank\">Изъяты лексемы с частотой выше 49 - distilbert-base-multilingual</a></strong> to <a href='https://wandb.ai/tuesta-lx-moscow-institute-of-physics-and-technology/model-comparison' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/tuesta-lx-moscow-institute-of-physics-and-technology/model-comparison' target=\"_blank\">https://wandb.ai/tuesta-lx-moscow-institute-of-physics-and-technology/model-comparison</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/tuesta-lx-moscow-institute-of-physics-and-technology/model-comparison/runs/93dyp6uw' target=\"_blank\">https://wandb.ai/tuesta-lx-moscow-institute-of-physics-and-technology/model-comparison/runs/93dyp6uw</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_Изъяты лексемы с частотой выше 49 - distilbert-base-multilingual.csv\n",
      "test_Изъяты лексемы с частотой выше 49 - distilbert-base-multilingual.csv\n"
     ]
    }
   ],
   "source": [
    "import funciones\n",
    "from utils import train_wrapper\n",
    "import warnings\n",
    "import os\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "from tqdm import tqdm\n",
    "from contextlib import redirect_stderr\n",
    "import multiprocessing as mp\n",
    "import numpy as np\n",
    "import wandb\n",
    "import nbformat\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import gc\n",
    "import re\n",
    "import nltk\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import BertForSequenceClassification, AdamW\n",
    "from razdel import sentenize\n",
    "import numpy as np\n",
    "\n",
    "# Suprimir warnings específicos\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "mp.set_start_method('spawn', force=True)\n",
    "\n",
    "# import funciones\n",
    "# from utils import train_wrapper\n",
    "# import warnings\n",
    "# import os\n",
    "# import torch\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # Suprimir warnings específicos\n",
    "# warnings.filterwarnings('ignore', category=UserWarning)  # Para sklearn y otros\n",
    "# warnings.filterwarnings('ignore', category=FutureWarning)  # Para huggingface y transformers\n",
    "# from concurrent.futures import ProcessPoolExecutor\n",
    "# from tqdm import tqdm\n",
    "# from contextlib import redirect_stderr\n",
    "# from concurrent.futures import ProcessPoolExecutor\n",
    "# import multiprocessing as mp\n",
    "# import numpy as np\n",
    "# mp.set_start_method('spawn', force=True)\n",
    "# #os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:128\"\n",
    "\n",
    "###############################################################################\n",
    "import wandb\n",
    "import nbformat\n",
    "# Configurar la clave de la API como variable de entorno\n",
    "os.environ[\"WANDB_API_KEY\"] = \"ca85316ed713b2425615fb3a613d7eb414c9f57f\"  # Reemplaza con tu clave\n",
    "# Iniciar wandb sin especificar entity (se detecta automáticamente)\n",
    "wandb.init(project=\"model-comparison-frecuency\")\n",
    "#os.environ[\"WANDB_NOTEBOOK_NAME\"] = \"сокращение по частотности.ipynb\"\n",
    "###############################################################################\n",
    "\n",
    "\n",
    "def train_wrapper(args):\n",
    "    dataset, config = args  # Desempaquetar los argumentos\n",
    "    result = funciones.train_and_evaluate_dataset(\n",
    "        dataset['path1'],\n",
    "        dataset['path2'],\n",
    "        config,\n",
    "        dataset['name'],\n",
    "    )\n",
    "    result['type'] = dataset['type']\n",
    "    return result\n",
    "    \"\"\"\n",
    "      return {\n",
    "        'dataset_name': dataset_name,\n",
    "        'avg_accuracy': avg_accuracy,\n",
    "        'std_accuracy': std_accuracy,\n",
    "        'accuracies': accuracies,\n",
    "        'type': type\n",
    "        }\n",
    "    \"\"\"\n",
    "\n",
    "###########################################################################\n",
    "def create_custom_config(dataset, model_name, model_type):\n",
    "    base_config = {\n",
    "        'model_name': model_name,\n",
    "        'num_repeats': 6,\n",
    "        'test_size': 0.2,\n",
    "        'threshold': 0.5,\n",
    "        'model_type': model_type\n",
    "    }\n",
    "    if model_type == 'gpt':\n",
    "        return funciones.TrainingConfig(\n",
    "            **base_config,\n",
    "            max_length=512,  # GPT models typically handle longer sequences\n",
    "            batch_size=4,    # Smaller batch size for GPT due to memory constraints\n",
    "            epochs=2,        # Fewer epochs for few-shot learning\n",
    "            learning_rate=1e-5\n",
    "        )\n",
    "    \n",
    "    if dataset.get('freq_threshold') == 100:\n",
    "        return funciones.TrainingConfig(\n",
    "            **base_config,\n",
    "            max_length=52,\n",
    "            batch_size=128,\n",
    "            epochs=3,\n",
    "            learning_rate=2e-5\n",
    "        )\n",
    "    elif dataset.get('freq_threshold') == 49:\n",
    "        return funciones.TrainingConfig(\n",
    "            **base_config,\n",
    "            max_length=60,\n",
    "            batch_size=128,\n",
    "            epochs=4,\n",
    "            learning_rate=3e-5\n",
    "        )\n",
    "    elif dataset.get('freq_threshold') == 29:\n",
    "        return funciones.TrainingConfig(\n",
    "            **base_config,\n",
    "            max_length=51,\n",
    "            batch_size=128,\n",
    "            epochs=4,\n",
    "            learning_rate=3e-5\n",
    "        )\n",
    "    elif dataset.get('freq_threshold') == 9:\n",
    "        return funciones.TrainingConfig(\n",
    "            **base_config,\n",
    "            max_length=45,\n",
    "            batch_size=128,\n",
    "            epochs=5,\n",
    "            learning_rate=4e-5\n",
    "        )\n",
    "    elif dataset.get('freq_threshold') == 5:\n",
    "        return funciones.TrainingConfig(\n",
    "            **base_config,\n",
    "            max_length=150,\n",
    "            batch_size=32,\n",
    "            epochs=6,\n",
    "            learning_rate=5e-5\n",
    "        )\n",
    "    elif dataset.get('freq_threshold') == 3:\n",
    "        return funciones.TrainingConfig(\n",
    "            **base_config,\n",
    "            max_length=150,\n",
    "            batch_size=32,\n",
    "            epochs=6,\n",
    "            learning_rate=5e-5\n",
    "        )\n",
    "    # Second dataset naming pattern\n",
    "    elif \"1\" in dataset.get('name', ''):\n",
    "        return funciones.TrainingConfig(\n",
    "            **base_config,\n",
    "            max_length=60,\n",
    "            batch_size=128,\n",
    "            epochs=6,\n",
    "            learning_rate=5e-5\n",
    "        )\n",
    "    elif \"2\" in dataset.get('name', ''):\n",
    "        return funciones.TrainingConfig(\n",
    "            **base_config,\n",
    "            max_length=60,\n",
    "            batch_size=128,\n",
    "            epochs=6,\n",
    "            learning_rate=5e-5\n",
    "        )\n",
    "    elif \"3\" in dataset.get('name', ''):\n",
    "        return funciones.TrainingConfig(\n",
    "            **base_config,\n",
    "            max_length=60,\n",
    "            batch_size=128,\n",
    "            epochs=6,\n",
    "            learning_rate=5e-5\n",
    "        )\n",
    "    elif \"4\" in dataset.get('name', ''):\n",
    "        return funciones.TrainingConfig(\n",
    "            **base_config,\n",
    "            max_length=60,\n",
    "            batch_size=128,\n",
    "            epochs=6,\n",
    "            learning_rate=5e-5\n",
    "        )\n",
    "\n",
    "    # Default configuration if no conditions match\n",
    "    return funciones.TrainingConfig(\n",
    "        **base_config,\n",
    "        max_length=60,\n",
    "        batch_size=128,\n",
    "        epochs=4,\n",
    "        learning_rate=3e-5\n",
    "    )\n",
    "        \n",
    "\n",
    "models = [\n",
    "#         {'model':'DeepPavlov/rubert-base-cased',\n",
    "#          'name':'rubert-base',\n",
    "#          'type': 'bert'},# Modelo original\n",
    "#         {'model':'bert-base-multilingual-cased',\n",
    "#          'name':'BERT multilingual',\n",
    "#          'type': 'bert'},# BERT multilingüe\n",
    "        {'model':'distilbert-base-multilingual-cased',\n",
    "         'name':'distilbert-base-multilingual',\n",
    "         'type': 'bert'},# Versión ligera de BERT\n",
    "#         {'model':'roberta-base',\n",
    "#          'name':'roberta-base', \n",
    "#         'type': 'bert'}, # RoBERTa \n",
    "        {'model': 'gpt2',\n",
    "         'name': 'gpt2',\n",
    "         'type': 'gpt'},  #  GPT model\n",
    "#         {'model': 'facebook/opt-125m',\n",
    "#          'name': 'opt-125m',\n",
    "#          'type': 'gpt'}  #  GPT model\n",
    "\n",
    "    ]\n",
    "\n",
    "datasets = [\n",
    "        {\n",
    "            'path1': '../dataset/сокращение по частотности/1б_Изъяты лексемы с частотой выше 100.txt',\n",
    "            'path2': '../dataset/сокращение по частотности/2б_Изъяты лексемы с частотой выше 100.txt',\n",
    "            'name': 'Изъяты лексемы с частотой выше 100',\n",
    "            'type': 'freq',\n",
    "            'freq': 100\n",
    "        },\n",
    "        {\n",
    "            'path1': '../dataset/сокращение по частотности/1в_Изъяты лексемы с частотой выше 49.txt',\n",
    "            'path2': '../dataset/сокращение по частотности/2в_Изъяты лексемы с частотой выше 49.txt',\n",
    "            'name': 'Изъяты лексемы с частотой выше 49',\n",
    "            'type': 'freq',\n",
    "            'freq': 49\n",
    "        },\n",
    "        {\n",
    "            'path1': '../dataset/сокращение по частотности/1г_Изъяты лексемы с частотой выше 29.txt',\n",
    "            'path2': '../dataset/сокращение по частотности/2г_Изъяты лексемы с частотой выше 29.txt',\n",
    "            'name': 'Изъяты лексемы с частотой выше 29',\n",
    "            'type': 'freq',\n",
    "            'freq': 29\n",
    "        },\n",
    "        {\n",
    "            'path1': '../dataset/сокращение по частотности/1д_Изъяты лексемы с частотой выше 9.txt',\n",
    "            'path2': '../dataset/сокращение по частотности/2д_Изъяты лексемы с частотой выше 9.txt',\n",
    "            'name': 'Изъяты лексемы с частотой выше 9',\n",
    "            'type': 'freq',\n",
    "            'freq': 9\n",
    "        },\n",
    "        {\n",
    "            'path1': '../dataset/сокращение по частотности/1е_Изъяты лексемы с частотой выше 5.txt',\n",
    "            'path2': '../dataset/сокращение по частотности/2е_Изъяты лексемы с частотой выше 5.txt',\n",
    "            'name': 'Изъяты лексемы с частотой выше 5',\n",
    "            'type': 'freq',\n",
    "            'freq': 5\n",
    "        },\n",
    "        {\n",
    "            'path1': '../dataset/сокращение по частотности/1ё_Изъяты лексемы с частотой выше 3.txt',\n",
    "            'path2': '../dataset/сокращение по частотности/2ё_Изъяты лексемы с частотой выше 3.txt',\n",
    "            'name': 'Изъяты лексемы с частотой выше 3',\n",
    "            'type': 'freq',\n",
    "            'freq': 3\n",
    "        },\n",
    "            {\n",
    "            'path1': '../dataset/Сокращение по частям речи/1.Первый жанр исходная выборка.txt',\n",
    "            'path2': '../dataset/Второй_жанр_исходная.txt',\n",
    "            'name': '1.Первый жанр исходная выборка',\n",
    "            'type': 'pos',\n",
    "            'freq': None\n",
    "\n",
    "        },\n",
    "        {\n",
    "            'path1': '../dataset/Сокращение по частям речи/2.Первый жанр без клауз, включающих наречия.txt',\n",
    "            'path2': '../dataset/Второй_жанр_исходная.txt',\n",
    "            'name': '2.Первый жанр без клауз, включающих наречия',\n",
    "            'type': 'pos',\n",
    "            'freq': None\n",
    "        },\n",
    "        {\n",
    "            'path1': '../dataset/Сокращение по частям речи/3.Первый жанр без клауз, включающих глаголы.txt',\n",
    "            'path2': '../dataset/Второй_жанр_исходная.txt',\n",
    "            'name': '3.Первый жанр без клауз, включающих глаголы',\n",
    "            'type': 'pos',\n",
    "            'freq': None\n",
    "        },\n",
    "        {\n",
    "            'path1': '../dataset/Сокращение по частям речи/4.Первый жанр без клауз, включающих глаголы и наречия.txt',\n",
    "            'path2': '../dataset/Второй_жанр_исходная.txt',\n",
    "            'name': '4.Первый жанр без клауз, включающих глаголы и наречия',\n",
    "            'type': 'pos',\n",
    "            'freq': None\n",
    "        },\n",
    "    ]\n",
    "\n",
    "def main():\n",
    "\n",
    "    results = []\n",
    "    for model in models:\n",
    "        for dataset in datasets:\n",
    "            dataset_copy = dataset.copy()\n",
    "            dataset_copy['name'] = f\"{dataset['name']} - {model['name']}\"\n",
    "            config = create_custom_config(dataset, model['model'], model['type'])\n",
    "            args = (dataset_copy, config)\n",
    "            \n",
    "            # Configurar wandb para este experimento\n",
    "            run_name = f\"{dataset['name']} - {model['name']}\"\n",
    "            wandb_run = wandb.init(\n",
    "                project=\"model-comparison\",\n",
    "                name=run_name,\n",
    "                config={\n",
    "                    \"model\": model['model'],\n",
    "                    \"dataset\": dataset['name'],\n",
    "                    \"type\": dataset['type'],\n",
    "                    \"freq\": dataset['freq'],\n",
    "                    **config.__dict__\n",
    "                },\n",
    "                reinit=True\n",
    "            )\n",
    "            \n",
    "            # Entrenar y limpiar memoria\n",
    "            torch.cuda.empty_cache()\n",
    "            result = train_wrapper(args)\n",
    "            results.append(result) \n",
    "            \n",
    "            wandb.log({\n",
    "                \"avg_accuracy\": result['avg_accuracy'],\n",
    "                \"std_accuracy\": result['std_accuracy']\n",
    "            })\n",
    "            wandb_run.finish()\n",
    "        \n",
    "    save_results(results, 'model_results.json')    \n",
    "    wandb.finish()\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    freq_datasets = [d for d in datasets if d['type'] == 'freq']\n",
    "    pos_datasets = [d for d in datasets if d['type'] == 'pos']\n",
    "    freq_results = [r for r in results if r['type'] == 'freq']\n",
    "    pos_results = [r for r in results if r['type'] == 'pos']\n",
    "    \n",
    "    if freq_datasets and freq_results:\n",
    "        funciones.plot_model_performance(\n",
    "            freq_datasets,\n",
    "            models,\n",
    "            freq_results,\n",
    "            save_path='frecuencia.png'\n",
    "        )\n",
    "    if pos_datasets and pos_results:\n",
    "        funciones.plot_model_performance(\n",
    "            pos_datasets,\n",
    "            models,\n",
    "            pos_results,\n",
    "            save_path='partes_discurso.png'\n",
    "        )\n",
    "    \n",
    "    # Resumen de resultados\n",
    "    print(\"\\nResultados de todos los experimentos:\")\n",
    "    print(\"\\n--- Frecuencia ---\")\n",
    "    for result in sorted(freq_results, key=lambda x: x['dataset_name']):\n",
    "        print(f\"{result['dataset_name']}: \"\n",
    "              f\"{result['avg_accuracy']:.4f} ± {result['std_accuracy']:.4f}\")\n",
    "    print(\"\\n--- Partes de discurso ---\")\n",
    "    for result in sorted(pos_results, key=lambda x: x['dataset_name']):\n",
    "        print(f\"{result['dataset_name']}: \"\n",
    "              f\"{result['avg_accuracy']:.4f} ± {result['std_accuracy']:.4f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd31457",
   "metadata": {},
   "outputs": [],
   "source": [
    "#batch_size=128v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7dfbb89",
   "metadata": {},
   "outputs": [],
   "source": [
    "#display_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1ac659",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import IPython\n",
    "\n",
    "# Reiniciar el kernel\n",
    "IPython.display.display(IPython.display.Javascript(\"Jupyter.notebook.kernel.restart()\"))\n",
    "\n",
    "# Apagar el kernel después de reiniciar\n",
    "os._exit(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a0cb97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "def plot_model_performance(datasets, models, results, save_path='frecuencia_profesional.png'):\n",
    "    \"\"\"\n",
    "    Genera un gráfico de barras comparando el rendimiento de modelos por dataset.\n",
    "\n",
    "    Args:\n",
    "        datasets (list): Lista de diccionarios con nombres de datasets (cada uno con clave 'name').\n",
    "        models (list): Lista de diccionarios con nombres de modelos (cada uno con clave 'name').\n",
    "        results (list): Lista de resultados con 'dataset_name', 'model_name' y 'avg_accuracy'.\n",
    "        save_path (str): Ruta donde guardar el gráfico (por defecto 'frecuencia_profesional.png').\n",
    "    \"\"\"\n",
    "    # Extraer nombres\n",
    "    dataset_names = [d['name'] for d in datasets]\n",
    "    model_names = [m['name'] for m in models]\n",
    "\n",
    "    # Crear matriz de precisiones\n",
    "    accuracies = np.zeros((len(dataset_names), len(model_names)))\n",
    "    for i, dataset_name in enumerate(dataset_names):\n",
    "        for j, model_name in enumerate(model_names):\n",
    "            for result in results:\n",
    "                if dataset_name in result['dataset_name'] and model_name in result['model_name']:\n",
    "                    accuracies[i, j] = result['avg_accuracy']\n",
    "                    break  # Salir del bucle una vez encontrada la precisión\n",
    "\n",
    "    # Configuración de estilo profesional\n",
    "    plt.style.use('seaborn-v0_8')\n",
    "\n",
    "    # Crear figura con mayor resolución\n",
    "    fig, ax = plt.subplots(figsize=(20, 8), dpi=100)\n",
    "\n",
    "    # Parámetros dinámicos según cantidad de modelos\n",
    "    n_models = len(model_names)\n",
    "    n_datasets = len(dataset_names)\n",
    "\n",
    "    # Ajustar el ancho de las barras en función del número de modelos y datasets\n",
    "    # Reducir el ancho máximo para evitar que los números se vean demasiado juntos\n",
    "    max_bar_width = 0.8 / (n_models * 1.2) if n_models > 0 else 0.15\n",
    "    bar_width = min(max_bar_width, 0.1)\n",
    "    index = np.arange(n_datasets)\n",
    "    colors = cm.Set2(np.linspace(0, 1, n_models))  # Paleta de colores profesional\n",
    "\n",
    "    # Espacio entre grupos de barras (datasets)\n",
    "    group_spacing = 0.5\n",
    "\n",
    "    # Calcular el ancho total ocupado por las barras de un dataset\n",
    "    total_bar_width_per_dataset = n_models * bar_width\n",
    "\n",
    "    # Calcular el desplazamiento para centrar el grupo de barras de cada dataset\n",
    "    group_offset = (total_bar_width_per_dataset + (n_models - 1) * 0.02) / 2 if n_models > 1 else bar_width / 2 # Añadir un pequeño espacio entre barras del mismo dataset\n",
    "\n",
    "    # Crear barras con mejoras visuales\n",
    "    for i, (model_name, color) in enumerate(zip(model_names, colors)):\n",
    "        positions = index + (i - (n_models - 1) / 2) * bar_width\n",
    "        bars = ax.bar(positions,\n",
    "                       accuracies[:, i],\n",
    "                       bar_width,\n",
    "                       label=model_name,\n",
    "                       color=color,\n",
    "                       edgecolor='black',\n",
    "                       alpha=0.8)\n",
    "\n",
    "        # Añadir valores encima de cada barra solo si no hay demasiados modelos\n",
    "        if n_models <= 10:  # Límite para evitar clutter\n",
    "            for bar in bars:\n",
    "                height = bar.get_height()\n",
    "                ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                        f'{height:.3f}',\n",
    "                        ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "    # Personalización de ejes\n",
    "    plt.xlabel('Dataset', fontsize=12, fontweight='bold')\n",
    "    plt.ylabel('Precisión Promedio', fontsize=12, fontweight='bold')\n",
    "    plt.title('Rendimiento de Modelos por Dataset', fontsize=14, fontweight='bold', pad=20)\n",
    "\n",
    "    # Ajustar marcas del eje X\n",
    "    plt.xticks(index,\n",
    "               dataset_names,\n",
    "               rotation=45,\n",
    "               ha='right',\n",
    "               fontsize=10)\n",
    "\n",
    "    # Añadir grid\n",
    "    plt.grid(True, axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "    # Mover la leyenda fuera del gráfico\n",
    "    plt.legend(title='Modelos',\n",
    "               title_fontsize=12,\n",
    "               fontsize=10,\n",
    "               loc='center left',\n",
    "               bbox_to_anchor=(1.05, 0.5),\n",
    "               frameon=True,\n",
    "               borderaxespad=0.)\n",
    "\n",
    "    # Ajustar límites del eje Y\n",
    "    plt.ylim(0, max(accuracies.max() * 1.1, 1))\n",
    "\n",
    "    # Ajustar layout para incluir la leyenda externa\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Guardar con alta calidad\n",
    "    plt.savefig(save_path,\n",
    "                dpi=300,\n",
    "                bbox_inches='tight')\n",
    "\n",
    "    # Mostrar gráfico\n",
    "    plt.show()\n",
    "\n",
    "# Ejemplo de uso:\n",
    "datasets = [{'name': 'dataset1'}, {'name': 'dataset2'}, {'name': 'dataset3'}, {'name': 'dataset4'}, {'name': 'dataset5'}]\n",
    "models = [{'name': 'model1'}, {'name': 'model2'}, {'name': 'model3'}, {'name': 'model4'}]\n",
    "results = [\n",
    "    {'dataset_name': 'dataset1', 'model_name': 'model1', 'avg_accuracy': 0.85},\n",
    "    {'dataset_name': 'dataset1', 'model_name': 'model2', 'avg_accuracy': 0.88},\n",
    "    {'dataset_name': 'dataset1', 'model_name': 'model3', 'avg_accuracy': 0.82},\n",
    "    {'dataset_name': 'dataset1', 'model_name': 'model4', 'avg_accuracy': 0.90},\n",
    "    {'dataset_name': 'dataset2', 'model_name': 'model1', 'avg_accuracy': 0.78},\n",
    "    {'dataset_name': 'dataset2', 'model_name': 'model2', 'avg_accuracy': 0.81},\n",
    "    {'dataset_name': 'dataset2', 'model_name': 'model3', 'avg_accuracy': 0.75},\n",
    "    {'dataset_name': 'dataset2', 'model_name': 'model4', 'avg_accuracy': 0.83},\n",
    "    {'dataset_name': 'dataset3', 'model_name': 'model1', 'avg_accuracy': 0.92},\n",
    "    {'dataset_name': 'dataset3', 'model_name': 'model2', 'avg_accuracy': 0.95},\n",
    "    {'dataset_name': 'dataset3', 'model_name': 'model3', 'avg_accuracy': 0.90},\n",
    "    {'dataset_name': 'dataset3', 'model_name': 'model4', 'avg_accuracy': 0.96},\n",
    "    {'dataset_name': 'dataset4', 'model_name': 'model1', 'avg_accuracy': 0.65},\n",
    "    {'dataset_name': 'dataset4', 'model_name': 'model2', 'avg_accuracy': 0.68},\n",
    "    {'dataset_name': 'dataset4', 'model_name': 'model3', 'avg_accuracy': 0.62},\n",
    "    {'dataset_name': 'dataset4', 'model_name': 'model4', 'avg_accuracy': 0.70},\n",
    "    {'dataset_name': 'dataset5', 'model_name': 'model1', 'avg_accuracy': 0.70},\n",
    "    {'dataset_name': 'dataset5', 'model_name': 'model2', 'avg_accuracy': 0.73},\n",
    "    {'dataset_name': 'dataset5', 'model_name': 'model3', 'avg_accuracy': 0.68},\n",
    "    {'dataset_name': 'dataset5', 'model_name': 'model4', 'avg_accuracy': 0.75},\n",
    "]\n",
    "plot_model_performance(datasets, models, results, save_path='frecuencia_profesional_ajustada.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1704e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Mi Entorno (Python 3.9)",
   "language": "python",
   "name": "mi_entorno"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
