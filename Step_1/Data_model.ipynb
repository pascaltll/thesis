{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97b75b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3530914",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34m../dataset\u001b[00m\r\n",
      "├── \u001b[01;34men_espanol\u001b[00m\r\n",
      "│   ├── docx2txt.py\r\n",
      "│   ├── Второй_жанр_исходная.txt\r\n",
      "│   └── Первый_жанр_исходная.txt\r\n",
      "├── Второй_жанр_исходная.txt\r\n",
      "├── Первый_жанр_исходная.txt\r\n",
      "├── \u001b[01;34mСокращение по частям речи\u001b[00m\r\n",
      "│   ├── 1.Первый жанр исходная выборка.txt\r\n",
      "│   ├── 2.Первый жанр без клауз, включающих наречия.txt\r\n",
      "│   ├── 3.Первый жанр без клауз, включающих глаголы.txt\r\n",
      "│   ├── 4. Первый жанр без клауз, включающих глаголы и наречия.txt\r\n",
      "│   ├── Без прилагательных второй жанр.txt\r\n",
      "│   ├── Без прилагательных первый жанр.txt\r\n",
      "│   └── Случайные выборки.txt\r\n",
      "└── \u001b[01;34mсокращение по частотности\u001b[00m\r\n",
      "    ├── 1а_ без сокращений.txt\r\n",
      "    ├── 1б_Изъяты лексемы с частотой выше 100.txt\r\n",
      "    ├── 1в_Изъяты лексемы с частотой выше 49.txt\r\n",
      "    ├── 1г_Изъяты лексемы с частотой выше 29.txt\r\n",
      "    ├── 1д_Изъяты лексемы с частотой выше 9.txt\r\n",
      "    ├── 2а_ без сокращений.txt\r\n",
      "    ├── 2б _ Изъяты лексемы с частотой выше 100..txt\r\n",
      "    ├── 2в_ Изъяты лексемы с частотой выше 49..txt\r\n",
      "    ├── 2г_  Изъяты лексемы с частотой выше 29.txt\r\n",
      "    └── 2д_ Изъяты лексемы с частотой выше 9.txt\r\n",
      "\r\n",
      "3 directories, 22 files\r\n"
     ]
    }
   ],
   "source": [
    "!tree ../dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "164120d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.util import ngrams\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "\n",
    "def segment_text_with_ngrams(text, n=3):  \n",
    "    \"\"\"Segmenta el texto dividiéndolo en frases, evitando dividir dentro de paréntesis.\"\"\"\n",
    "    \n",
    "    def replace_inside_parentheses(match):\n",
    "        \"\"\"Reemplaza los signos de puntuación dentro de los paréntesis para evitar segmentación incorrecta.\"\"\"\n",
    "        content = match.group(0)\n",
    "        content = content.replace(\".\", \"§\").replace(\"!\", \"§\").replace(\"?\", \"§\")\n",
    "        return content  # Devuelve el contenido modificado\n",
    "    \n",
    "    text = re.sub(r'\\([^()]*\\)', replace_inside_parentheses, text)  # Evita problemas con paréntesis anidados\n",
    "\n",
    "    sentences = sent_tokenize(text, language=\"russian\")  # Segmentar en frases correctamente\n",
    "\n",
    "    segmented_sentences = []\n",
    "    for sentence in sentences:\n",
    "        sentence = sentence.replace(\"§\", \".\")  # Restaurar puntuación dentro de paréntesis\n",
    "        words = word_tokenize(sentence, language=\"russian\")  # Tokenización de palabras\n",
    "        if words:\n",
    "            segmented_sentences.append(\" \".join(words))\n",
    "\n",
    "    return [s.strip() for s in segmented_sentences if s.strip()]\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"Elimina texto entre corchetes y caracteres innecesarios.\"\"\"\n",
    "    cleaned_text = re.sub(r'\\[.*?\\]', '', text)  # Eliminar contenido entre corchetes []\n",
    "    return cleaned_text.strip()\n",
    "\n",
    "def load_texts(filename, label):\n",
    "    with open(filename, \"r\", encoding=\"utf-8\") as f:\n",
    "        text = f.read()\n",
    "    \n",
    "    sentences = segment_text_with_ngrams(text)  \n",
    "    cleaned_sentences = [clean_text(sentence) for sentence in sentences]\n",
    "    \n",
    "    return [{\"text\": sentence, \"label\": label} for sentence in cleaned_sentences if sentence]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cfa97aac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño del conjunto completo: 908\n",
      "Tamaño del conjunto de entrenamiento: 580\n",
      "Tamaño del conjunto de validación: 146\n",
      "Tamaño del conjunto de prueba: 182\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Cargar ambos géneros\n",
    "genre1 = load_texts(\"../dataset/Первый_жанр_исходная.txt\", label=\"0\")\n",
    "genre2 = load_texts(\"../dataset/Второй_жанр_исходная.txt\", label=\"1\")\n",
    "# Combinar ambos géneros en un DataFrame\n",
    "all_texts_df = pd.DataFrame(genre1 + genre2)\n",
    "\n",
    "# Eliminar filas con valores NaN o vacíos en la columna 'text'\n",
    "all_texts_df = all_texts_df[all_texts_df['text'].notna()]\n",
    "all_texts_df = all_texts_df[all_texts_df['text'] != '']\n",
    "\n",
    "# Dividir nuevamente en train, validation y test\n",
    "train_df, test_df = train_test_split(all_texts_df, test_size=0.2, random_state=42, stratify=all_texts_df['label'])\n",
    "train_df, val_df = train_test_split(train_df, test_size=0.2, random_state=42, stratify=train_df['label'])\n",
    "\n",
    "# Guardar los conjuntos limpios\n",
    "all_texts_df.to_csv(\"data.csv\",index=False)\n",
    "train_df.to_csv(\"train.csv\", index=False)\n",
    "val_df.to_csv(\"val.csv\", index=False)\n",
    "test_df.to_csv(\"test.csv\", index=False)\n",
    "\n",
    "print(f\"Tamaño del conjunto completo: {len(all_texts_df)}\")\n",
    "print(f\"Tamaño del conjunto de entrenamiento: {len(train_df)}\")\n",
    "print(f\"Tamaño del conjunto de validación: {len(val_df)}\")\n",
    "print(f\"Tamaño del conjunto de prueba: {len(test_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cbe9fdbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos completos:\n",
      "                                                text  label\n",
      "0                  Кустарник до 1.5 метров высотой .      0\n",
      "1                           Ветви темно-коричневые .      0\n",
      "2  Годовалые побеги утолщенные , короткие , темно...      0\n",
      "3  Почки мономорфные , 4.5-9 мм длиной , яйцевидн...      0\n",
      "4  Прилистники 1.5-12 мм длиной , полусердцевидны...      0\n",
      "\n",
      "Conjunto de entrenamiento:\n",
      "                                                text  label\n",
      "0  Ведь психика – это не просто система , а супер...      1\n",
      "1                          Темя с поперечным килем .      0\n",
      "2  Цвет в образцах и зернах под бинокуляром ярко-...      0\n",
      "3  На втором членике лапок 15-24 волоска разной д...      0\n",
      "4                                            Самец .      0\n",
      "\n",
      "Conjunto de validación:\n",
      "                                                text  label\n",
      "0  Строение тела со следующими особенностями : на...      0\n",
      "1  Взаимодействие между популяциями есть прежде в...      1\n",
      "2            Спайность или отдельность не выражены .      0\n",
      "3  Продорсум , нотогастр и аногенитальная область...      0\n",
      "4                     Под микроскопом он бесцветен .      0\n",
      "\n",
      "Conjunto de prueba:\n",
      "                                                text  label\n",
      "0  В основании стебель несет светлые бледно-зелен...      0\n",
      "1  Чешуйки воротника с куполом и асимметричные 2-...      0\n",
      "2               Семена гладкие , светло-коричневые .      0\n",
      "3  речь - это движение , процесс ; Под текстом Ю....      1\n",
      "4  Глазное поле поперечное ( с трапециевидным сре...      0\n",
      "\n",
      "Información de los DataFrames:\n",
      "\n",
      "Datos completos:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 908 entries, 0 to 907\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   text    908 non-null    object\n",
      " 1   label   908 non-null    int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 14.3+ KB\n",
      "None\n",
      "\n",
      "Conjunto de entrenamiento:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 580 entries, 0 to 579\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   text    580 non-null    object\n",
      " 1   label   580 non-null    int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 9.2+ KB\n",
      "None\n",
      "\n",
      "Conjunto de validación:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 146 entries, 0 to 145\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   text    146 non-null    object\n",
      " 1   label   146 non-null    int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 2.4+ KB\n",
      "None\n",
      "\n",
      "Conjunto de prueba:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 182 entries, 0 to 181\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   text    182 non-null    object\n",
      " 1   label   182 non-null    int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 3.0+ KB\n",
      "None\n",
      "\n",
      "Estadísticas descriptivas:\n",
      "\n",
      "Datos completos:\n",
      "            label\n",
      "count  908.000000\n",
      "mean     0.365639\n",
      "std      0.481874\n",
      "min      0.000000\n",
      "25%      0.000000\n",
      "50%      0.000000\n",
      "75%      1.000000\n",
      "max      1.000000\n",
      "\n",
      "Conjunto de entrenamiento:\n",
      "            label\n",
      "count  580.000000\n",
      "mean     0.365517\n",
      "std      0.481991\n",
      "min      0.000000\n",
      "25%      0.000000\n",
      "50%      0.000000\n",
      "75%      1.000000\n",
      "max      1.000000\n",
      "\n",
      "Conjunto de validación:\n",
      "            label\n",
      "count  146.000000\n",
      "mean     0.363014\n",
      "std      0.482524\n",
      "min      0.000000\n",
      "25%      0.000000\n",
      "50%      0.000000\n",
      "75%      1.000000\n",
      "max      1.000000\n",
      "\n",
      "Conjunto de prueba:\n",
      "            label\n",
      "count  182.000000\n",
      "mean     0.368132\n",
      "std      0.483628\n",
      "min      0.000000\n",
      "25%      0.000000\n",
      "50%      0.000000\n",
      "75%      1.000000\n",
      "max      1.000000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Cargar los datos desde los archivos CSV\n",
    "all_texts_df = pd.read_csv(\"data.csv\")\n",
    "train_df = pd.read_csv(\"train.csv\")\n",
    "val_df = pd.read_csv(\"val.csv\")\n",
    "test_df = pd.read_csv(\"test.csv\")\n",
    "\n",
    "# Mostrar las primeras filas de cada DataFrame\n",
    "print(\"Datos completos:\")\n",
    "print(all_texts_df.head())\n",
    "\n",
    "print(\"\\nConjunto de entrenamiento:\")\n",
    "print(train_df.head())\n",
    "\n",
    "print(\"\\nConjunto de validación:\")\n",
    "print(val_df.head())\n",
    "\n",
    "print(\"\\nConjunto de prueba:\")\n",
    "print(test_df.head())\n",
    "\n",
    "# Mostrar información general sobre los DataFrames\n",
    "print(\"\\nInformación de los DataFrames:\")\n",
    "print(\"\\nDatos completos:\")\n",
    "print(all_texts_df.info())\n",
    "\n",
    "print(\"\\nConjunto de entrenamiento:\")\n",
    "print(train_df.info())\n",
    "\n",
    "print(\"\\nConjunto de validación:\")\n",
    "print(val_df.info())\n",
    "\n",
    "print(\"\\nConjunto de prueba:\")\n",
    "print(test_df.info())\n",
    "\n",
    "# Mostrar estadísticas descriptivas de los datos numéricos (si los hay)\n",
    "print(\"\\nEstadísticas descriptivas:\")\n",
    "print(\"\\nDatos completos:\")\n",
    "print(all_texts_df.describe())\n",
    "\n",
    "print(\"\\nConjunto de entrenamiento:\")\n",
    "print(train_df.describe())\n",
    "\n",
    "print(\"\\nConjunto de validación:\")\n",
    "print(val_df.describe())\n",
    "\n",
    "print(\"\\nConjunto de prueba:\")\n",
    "print(test_df.describe())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Mi Entorno (Python 3.9)",
   "language": "python",
   "name": "mi_entorno"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
